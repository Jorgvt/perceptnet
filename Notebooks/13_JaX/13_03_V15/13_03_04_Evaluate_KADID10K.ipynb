{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 15:16:13.886117: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 15:16:16.390409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lhome/ext/uv075/uv0752/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-04 15:16:23.110438: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "2023-12-04 15:16:23.111276: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:1: failed initializing StreamExecutor for CUDA device ordinal 1: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from typing import Any, Callable, Sequence, Union\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "import jax\n",
    "from jax import lax, random, numpy as jnp\n",
    "import flax\n",
    "from flax.core import freeze, unfreeze, FrozenDict\n",
    "from flax import linen as nn\n",
    "from flax import struct\n",
    "from flax.training import train_state\n",
    "from flax.training import orbax_utils\n",
    "\n",
    "import optax\n",
    "import orbax.checkpoint\n",
    "\n",
    "from clu import metrics\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "from einops import reduce, rearrange\n",
    "import wandb\n",
    "\n",
    "from iqadatasets.datasets import *\n",
    "from fxlayers.layers import *\n",
    "from fxlayers.layers import GaborLayerLogSigma_, GaussianLayerGamma, FreqGaussianGamma, OrientGaussianGamma\n",
    "from fxlayers.initializers import *\n",
    "from JaxPlayground.utils.constraints import *\n",
    "from JaxPlayground.utils.wandb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dst_train = TID2008(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2008/\", exclude_imgs=[25])\n",
    "# dst_val = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2013/\", exclude_imgs=[25])\n",
    "# dst_train = TID2008(\"/media/disk/databases/BBDD_video_image/Image_Quality//TID/TID2008/\", exclude_imgs=[25])\n",
    "# dst_val = TID2013(\"/media/disk/databases/BBDD_video_image/Image_Quality//TID/TID2013/\", exclude_imgs=[25])\n",
    "# dst = KADIK10K(\"/media/disk/databases/BBDD_video_image/Image_Quality/KADIK10K/\")\n",
    "# dst = PIPAL(\"/media/disk/databases/BBDD_video_image/Image_Quality/PIPAL/\")\n",
    "dst = KADIK10K(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/KADIK10K/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([384, 512, 3]), TensorShape([384, 512, 3]), TensorShape([]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, img_dist, mos = next(iter(dst.dataset))\n",
    "img.shape, img_dist.shape, mos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BATCH_SIZE: 64\n",
       "CS_KERNEL_SIZE: 21\n",
       "EPOCHS: 500\n",
       "GABOR_KERNEL_SIZE: 31\n",
       "GDN_CLIPPING: true\n",
       "LEARNING_RATE: 0.003\n",
       "NORMALIZE_ENERGY: true\n",
       "NORMALIZE_PROB: false\n",
       "N_ORIENTATIONS: 8\n",
       "N_SCALES: 4\n",
       "SEED: 42\n",
       "USE_BIAS: false\n",
       "ZERO_MEAN: true"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"EPOCHS\": 500,\n",
    "    \"LEARNING_RATE\": 3e-3,\n",
    "    \"SEED\": 42,\n",
    "    \"GDN_CLIPPING\": True,\n",
    "    \"NORMALIZE_PROB\": False,\n",
    "    \"NORMALIZE_ENERGY\": True,\n",
    "    \"ZERO_MEAN\": True,\n",
    "    \"USE_BIAS\": False,\n",
    "    \"CS_KERNEL_SIZE\": 21,\n",
    "    \"GABOR_KERNEL_SIZE\": 31,\n",
    "    \"N_SCALES\": 4,\n",
    "    \"N_ORIENTATIONS\": 8,\n",
    "}\n",
    "config = ConfigDict(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = \"8a4ra7yl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "prev_run = api.run(f\"jorgvt/PerceptNet_v15/{id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BATCH_SIZE: 64\n",
       "CS_KERNEL_SIZE: 21\n",
       "EPOCHS: 500\n",
       "GABOR_KERNEL_SIZE: 31\n",
       "GDN_CLIPPING: true\n",
       "LEARNING_RATE: 0.003\n",
       "NORMALIZE_ENERGY: true\n",
       "NORMALIZE_PROB: false\n",
       "N_ORIENTATIONS: 8\n",
       "N_SCALES: 4\n",
       "SEED: 42\n",
       "USE_BIAS: false\n",
       "ZERO_MEAN: true"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = ConfigDict(prev_run.config[\"_fields\"])\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in prev_run.files():\n",
    "    file.download(root=prev_run.dir, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: jorgvt. Use `wandb login --relogin` to force relogin\n",
      "wandb: wandb version 0.16.0 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "wandb: Tracking run with wandb version 0.15.1\n",
      "wandb: Run data is saved locally in /lhome/ext/uv075/uv0752/perceptnet/Notebooks/13_JaX/13_04_V18/wandb/run-20231205_113747-0utac608\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run DN_OG_G_Fixed_GDNSpatioFreqOrient_Symm_CSPos\n",
      "wandb:  View project at https://wandb.ai/jorgvt/PerceptNet_JaX_Eval\n",
      "wandb:  View run at https://wandb.ai/jorgvt/PerceptNet_JaX_Eval/runs/0utac608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BATCH_SIZE: 64\n",
       "CS_KERNEL_SIZE: 21\n",
       "EPOCHS: 500\n",
       "GABOR_KERNEL_SIZE: 31\n",
       "GDN_CLIPPING: true\n",
       "LEARNING_RATE: 0.003\n",
       "NORMALIZE_ENERGY: true\n",
       "NORMALIZE_PROB: false\n",
       "N_ORIENTATIONS: 8\n",
       "N_SCALES: 4\n",
       "SEED: 42\n",
       "USE_BIAS: false\n",
       "ZERO_MEAN: true"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"PerceptNet_JaX_Eval\",\n",
    "           name=prev_run.name,\n",
    "           job_type=\"evaluate\",\n",
    "           mode=\"online\",\n",
    "           )\n",
    "config = config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_rdy = dst.dataset.batch(config.BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model we're going to use\n",
    "\n",
    "> It's going to be a very simple model just for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_same_from_kernel_size(inputs, kernel_size, mode):\n",
    "    return jnp.pad(inputs,\n",
    "                   [[0,0],\n",
    "                    [(kernel_size-1)//2, (kernel_size-1)//2],\n",
    "                    [(kernel_size-1)//2, (kernel_size-1)//2],\n",
    "                    [0,0]],\n",
    "                    mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNet(nn.Module):\n",
    "    \"\"\"IQA model inspired by the visual system.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs, # Assuming fs = 128 (cpd)\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        ## (Independent) Color equilibration (Gamma correction)\n",
    "        ## Might need to be the same for each number\n",
    "        ## bias = 0.1 / kernel = 0.5\n",
    "        outputs = GDN(kernel_size=(1,1), apply_independently=True)(inputs)\n",
    "        \n",
    "        ## Color (ATD) Transformation\n",
    "        outputs = nn.Conv(features=3, kernel_size=(1,1), use_bias=False)(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        \n",
    "        ## GDN Star A - T - D [Separated]\n",
    "        outputs = GDN(kernel_size=(1,1), apply_independently=True)(outputs)\n",
    "\n",
    "        ## Center Surround (DoG)\n",
    "        ## Initialized so that 3 are positives and 3 are negatives and no interaction between channels is present\n",
    "        outputs = pad_same_from_kernel_size(outputs, kernel_size=config.CS_KERNEL_SIZE, mode=\"symmetric\")\n",
    "        outputs = CenterSurroundLogSigmaK(features=3, kernel_size=config.CS_KERNEL_SIZE, fs=21, use_bias=False, padding=\"VALID\")(outputs, **kwargs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "\n",
    "        ## GDN per channel with mean substraction in T and D (Spatial Gaussian Kernel)\n",
    "        ### fs = 32 / kernel_size = (11,11) -> 0.32 > 0.02 --> OK!\n",
    "        ## TO-DO: - Spatial Gaussian Kernel (0.02 deg) -> fs = 64/2 & 0.02*64/2 = sigma (px) = 0.69\n",
    "        outputs = GDN(kernel_size=(1,1), apply_independently=True)(outputs)\n",
    "\n",
    "        ## GaborLayer per channel with GDN mixing only same-origin-channel information\n",
    "        ### [Gaussian] sigma = 0.2 (deg) fs = 32 / kernel_size = (21,21) -> 21/32 = 0.66 --> OK!\n",
    "        outputs = pad_same_from_kernel_size(outputs, kernel_size=config.GABOR_KERNEL_SIZE, mode=\"symmetric\")\n",
    "        outputs = GaborLayerLogSigma_(n_scales=config.N_SCALES, n_orientations=config.N_ORIENTATIONS, kernel_size=config.GABOR_KERNEL_SIZE, fs=32, xmean=config.GABOR_KERNEL_SIZE/32/2, ymean=config.GABOR_KERNEL_SIZE/32/2, strides=1, padding=\"VALID\", normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY, zero_mean=config.ZERO_MEAN, use_bias=config.USE_BIAS)(outputs, **kwargs)\n",
    "        \n",
    "        ## Final GDN mixing Gabor information (?)\n",
    "        outputs = GDN(kernel_size=(1,1), apply_independently=False)(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the metrics with `clu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    \"\"\"Collection of metrics to be tracked during training.\"\"\"\n",
    "    loss: metrics.Average.from_output(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `TrainState` doesn't include metrics, but it's very easy to subclass it so that it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "    state: FrozenDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a function that initializes the `TrainState` from a module, a rng key and some optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, key, tx, input_shape):\n",
    "    \"\"\"Creates the initial `TrainState`.\"\"\"\n",
    "    variables = module.init(key, jnp.ones(input_shape))\n",
    "    state, params = variables.pop('params')\n",
    "    return TrainState.create(\n",
    "        apply_fn=module.apply,\n",
    "        params=params,\n",
    "        state=state,\n",
    "        tx=tx,\n",
    "        metrics=Metrics.empty()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_distance(*, state, batch):\n",
    "    \"\"\"Obtaining the metrics for a given batch.\"\"\"\n",
    "    img, img_dist, mos = batch\n",
    "    \n",
    "    ## Forward pass through the model\n",
    "    img_pred = state.apply_fn({\"params\": state.params, **state.state}, img, train=False)\n",
    "    img_dist_pred = state.apply_fn({\"params\": state.params, **state.state}, img_dist, train=False)\n",
    "\n",
    "    ## Calculate the distance\n",
    "    dist = ((img_pred - img_dist_pred)**2).sum(axis=(1,2,3))**(1/2)\n",
    "    \n",
    "    ## Calculate pearson correlation\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(PerceptNet(), random.PRNGKey(config.SEED), optax.adam(config.LEARNING_RATE), input_shape=(1,384,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trainable(path):\n",
    "    return False\n",
    "    # return (\"A\" in path) or (\"alpha_achrom\" in path) or (\"alpha_chrom_rg\" in path) or (\"alpha_chrom_yb\" in path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_tree = freeze(flax.traverse_util.path_aware_map(lambda path, v: \"non_trainable\" if check_trainable(path)  else \"trainable\", state.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 286)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(state.params))\n",
    "trainable_param_count = sum([w.size if t==\"trainable\" else 0 for w, t in zip(jax.tree_util.tree_leaves(state.params), jax.tree_util.tree_leaves(trainable_tree))])\n",
    "param_count, trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.summary[\"total_parameters\"] = param_count\n",
    "wandb.run.summary[\"trainable_parameters\"] = trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    \"trainable\": optax.adam(learning_rate=config.LEARNING_RATE),\n",
    "    \"non_trainable\": optax.set_to_zero(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = optax.multi_transform(optimizers, trainable_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(PerceptNet(), random.PRNGKey(config.SEED), tx, input_shape=(1,384,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before actually training the model we're going to set up the checkpointer to be able to save our trained models:\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights\n",
    "state = orbax_checkpointer.restore(os.path.join(prev_run.dir,\"model-best\"), item=state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    \"distance\": [],\n",
    "    \"mos\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 49s, sys: 24 s, total: 4min 13s\n",
      "Wall time: 42.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "0it [00:00, ?it/s]\r\n",
      "1it [00:10, 10.88s/it]\r\n",
      "3it [00:11,  2.93s/it]\r\n",
      "6it [00:11,  1.24s/it]\r\n",
      "9it [00:11,  1.47it/s]\r\n",
      "12it [00:12,  2.29it/s]\r\n",
      "14it [00:12,  2.74it/s]\r\n",
      "16it [00:12,  3.21it/s]\r\n",
      "17it [00:12,  3.47it/s]\r\n",
      "18it [00:13,  3.75it/s]\r\n",
      "19it [00:13,  4.04it/s]\r\n",
      "20it [00:14,  2.60it/s]\r\n",
      "23it [00:14,  4.77it/s]\r\n",
      "25it [00:14,  6.15it/s]\r\n",
      "27it [00:14,  6.08it/s]\r\n",
      "29it [00:15,  5.97it/s]\r\n",
      "30it [00:15,  5.93it/s]\r\n",
      "31it [00:15,  5.89it/s]\r\n",
      "32it [00:15,  5.63it/s]\r\n",
      "33it [00:15,  5.88it/s]\r\n",
      "34it [00:15,  5.84it/s]\r\n",
      "35it [00:16,  5.81it/s]\r\n",
      "36it [00:16,  5.78it/s]\r\n",
      "37it [00:16,  5.76it/s]\r\n",
      "38it [00:16,  5.49it/s]\r\n",
      "39it [00:16,  5.56it/s]\r\n",
      "40it [00:16,  5.87it/s]\r\n",
      "41it [00:17,  5.81it/s]\r\n",
      "42it [00:17,  5.77it/s]\r\n",
      "44it [00:17,  7.08it/s]\r\n",
      "45it [00:17,  5.35it/s]\r\n",
      "46it [00:18,  5.44it/s]\r\n",
      "47it [00:18,  5.49it/s]\r\n",
      "48it [00:18,  5.32it/s]\r\n",
      "49it [00:18,  5.41it/s]\r\n",
      "50it [00:18,  5.73it/s]\r\n",
      "51it [00:18,  5.70it/s]\r\n",
      "52it [00:19,  5.46it/s]\r\n",
      "53it [00:19,  5.55it/s]\r\n",
      "54it [00:19,  5.57it/s]\r\n",
      "55it [00:19,  5.64it/s]\r\n",
      "56it [00:19,  5.68it/s]\r\n",
      "57it [00:19,  5.69it/s]\r\n",
      "58it [00:20,  5.71it/s]\r\n",
      "59it [00:20,  5.70it/s]\r\n",
      "60it [00:20,  5.69it/s]\r\n",
      "61it [00:20,  5.71it/s]\r\n",
      "62it [00:20,  5.72it/s]\r\n",
      "63it [00:21,  5.73it/s]\r\n",
      "64it [00:21,  5.99it/s]\r\n",
      "65it [00:21,  5.92it/s]\r\n",
      "67it [00:21,  5.82it/s]\r\n",
      "68it [00:21,  5.77it/s]\r\n",
      "69it [00:22,  5.73it/s]\r\n",
      "70it [00:22,  5.47it/s]\r\n",
      "71it [00:22,  5.50it/s]\r\n",
      "72it [00:22,  5.81it/s]\r\n",
      "73it [00:22,  5.77it/s]\r\n",
      "74it [00:22,  5.74it/s]\r\n",
      "75it [00:23,  5.46it/s]\r\n",
      "76it [00:23,  5.54it/s]\r\n",
      "77it [00:23,  5.85it/s]\r\n",
      "78it [00:23,  5.81it/s]\r\n",
      "79it [00:23,  5.79it/s]\r\n",
      "80it [00:24,  5.50it/s]\r\n",
      "81it [00:24,  5.83it/s]\r\n",
      "82it [00:24,  5.78it/s]\r\n",
      "83it [00:24,  5.77it/s]\r\n",
      "84it [00:24,  5.75it/s]\r\n",
      "85it [00:24,  5.74it/s]\r\n",
      "86it [00:25,  5.72it/s]\r\n",
      "87it [00:25,  5.73it/s]\r\n",
      "88it [00:25,  5.72it/s]\r\n",
      "90it [00:25,  7.10it/s]\r\n",
      "91it [00:25,  5.35it/s]\r\n",
      "92it [00:26,  5.43it/s]\r\n",
      "93it [00:26,  5.48it/s]\r\n",
      "94it [00:26,  5.29it/s]\r\n",
      "95it [00:26,  5.38it/s]\r\n",
      "96it [00:26,  5.70it/s]\r\n",
      "97it [00:26,  5.69it/s]\r\n",
      "98it [00:27,  5.69it/s]\r\n",
      "99it [00:27,  5.68it/s]\r\n",
      "101it [00:27,  7.05it/s]\r\n",
      "102it [00:27,  6.65it/s]\r\n",
      "103it [00:27,  6.68it/s]\r\n",
      "104it [00:28,  6.23it/s]\r\n",
      "105it [00:28,  6.08it/s]\r\n",
      "106it [00:28,  5.83it/s]\r\n",
      "107it [00:28,  5.79it/s]\r\n",
      "108it [00:28,  4.61it/s]\r\n",
      "109it [00:29,  4.70it/s]\r\n",
      "110it [00:29,  4.95it/s]\r\n",
      "111it [00:29,  5.16it/s]\r\n",
      "112it [00:29,  5.30it/s]\r\n",
      "113it [00:29,  5.65it/s]\r\n",
      "114it [00:29,  5.65it/s]\r\n",
      "115it [00:30,  5.64it/s]\r\n",
      "116it [00:30,  5.63it/s]\r\n",
      "117it [00:30,  5.63it/s]\r\n",
      "118it [00:30,  5.63it/s]\r\n",
      "119it [00:30,  5.65it/s]\r\n",
      "120it [00:31,  5.65it/s]\r\n",
      "121it [00:31,  5.52it/s]\r\n",
      "122it [00:31,  5.44it/s]\r\n",
      "123it [00:31,  5.78it/s]\r\n",
      "124it [00:31,  5.77it/s]\r\n",
      "125it [00:31,  5.75it/s]\r\n",
      "126it [00:32,  5.74it/s]\r\n",
      "127it [00:32,  5.73it/s]\r\n",
      "128it [00:32,  5.72it/s]\r\n",
      "129it [00:32,  5.72it/s]\r\n",
      "130it [00:32,  5.71it/s]\r\n",
      "131it [00:32,  5.71it/s]\r\n",
      "132it [00:33,  5.70it/s]\r\n",
      "133it [00:33,  5.70it/s]\r\n",
      "134it [00:33,  5.71it/s]\r\n",
      "135it [00:33,  5.68it/s]\r\n",
      "136it [00:33,  5.67it/s]\r\n",
      "137it [00:34,  5.65it/s]\r\n",
      "138it [00:34,  5.63it/s]\r\n",
      "139it [00:34,  5.64it/s]\r\n",
      "140it [00:34,  5.63it/s]\r\n",
      "141it [00:34,  5.64it/s]\r\n",
      "143it [00:34,  7.02it/s]\r\n",
      "144it [00:35,  6.62it/s]\r\n",
      "145it [00:35,  6.64it/s]\r\n",
      "146it [00:35,  6.35it/s]\r\n",
      "147it [00:35,  5.86it/s]\r\n",
      "148it [00:35,  5.81it/s]\r\n",
      "149it [00:35,  5.78it/s]\r\n",
      "150it [00:36,  5.76it/s]\r\n",
      "151it [00:36,  5.75it/s]\r\n",
      "152it [00:36,  4.42it/s]\r\n",
      "153it [00:36,  4.73it/s]\r\n",
      "154it [00:37,  4.98it/s]\r\n",
      "155it [00:37,  5.18it/s]\r\n",
      "156it [00:37,  5.31it/s]\r\n",
      "157it [00:37,  5.68it/s]\r\n",
      "158it [00:37,  5.69it/s]\r\n",
      "159it [00:42,  1.46s/it]\r\n",
      "159it [00:42,  3.77it/s]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for batch in tqdm(dst_rdy.as_numpy_iterator()):\n",
    "    img, img_dist, mos = batch\n",
    "    distance = compute_distance(state=state, batch=batch)\n",
    "    metrics_history[\"distance\"].extend(distance)\n",
    "    metrics_history[\"mos\"].extend(mos)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(metrics_history[\"distance\"]) == len(dst.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PearsonRResult(statistic=-0.7619710167160694, pvalue=0.0),\n",
       " SignificanceResult(statistic=-0.7896393183160754, pvalue=0.0))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(metrics_history[\"distance\"], metrics_history[\"mos\"]), stats.spearmanr(metrics_history[\"distance\"], metrics_history[\"mos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_img</th>\n",
       "      <th>ref_img</th>\n",
       "      <th>dmos</th>\n",
       "      <th>var</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I01_01_01.png</td>\n",
       "      <td>I01.png</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I01_01_02.png</td>\n",
       "      <td>I01.png</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.869</td>\n",
       "      <td>16.907238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I01_01_03.png</td>\n",
       "      <td>I01.png</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.789</td>\n",
       "      <td>43.86259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I01_01_04.png</td>\n",
       "      <td>I01.png</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.596</td>\n",
       "      <td>76.28169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I01_01_05.png</td>\n",
       "      <td>I01.png</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.300</td>\n",
       "      <td>146.63597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dist_img  ref_img  dmos    var   Distance\n",
       "0  I01_01_01.png  I01.png  4.57  0.496        0.0\n",
       "1  I01_01_02.png  I01.png  4.33  0.869  16.907238\n",
       "2  I01_01_03.png  I01.png  2.67  0.789   43.86259\n",
       "3  I01_01_04.png  I01.png  1.67  0.596   76.28169\n",
       "4  I01_01_05.png  I01.png  1.10  0.300  146.63597"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = dst.data.copy()\n",
    "results[\"Distance\"] = metrics_history[\"distance\"]\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"KADID10K\": wandb.Table(dataframe=results),\n",
    "           \"KADID10K_pearson\": stats.pearsonr(metrics_history[\"distance\"], metrics_history[\"mos\"])[0],\n",
    "           \"KADID10K_spearman\": stats.spearmanr(metrics_history[\"distance\"], metrics_history[\"mos\"])[0],\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
