{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IQA tracking params and variables\n",
    "\n",
    "> When using parametric layers we have to be able to keep track of the parameters and the variables of the model (which are not going to be trained). We're going to play with this concept using our implementation of the functional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os; os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".99\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 14:15:52.728007: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-02 14:15:56.415030: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'AttributeError'>",
     "evalue": "partially initialized module 'jax' has no attribute 'version' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Sequence, Union\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lax, random, numpy \u001b[38;5;28;01mas\u001b[39;00m jnp\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m freeze, unfreeze, FrozenDict\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.8/site-packages/jax/__init__.py:35\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _cloud_tpu_init\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Confusingly there are two things named \"config\": the module and the class.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# We want the exported object to be the class, so we first import the module\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# to make sure a later import doesn't overwrite the class.\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m _config_module\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _config_module\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Force early import, allowing use of `jax.core` after importing `jax`.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.8/site-packages/jax/config.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2018 The JAX Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# TODO(phawkins): fix users of this alias and delete this file.\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.8/site-packages/jax/_src/config.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, List, Callable, Hashable, NamedTuple, Iterator, Optional\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lib\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jax_jit\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transfer_guard_lib\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.8/site-packages/jax/_src/lib/__init__.py:74\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _jaxlib_version\n\u001b[1;32m     72\u001b[0m version_str \u001b[38;5;241m=\u001b[39m jaxlib\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m     73\u001b[0m version \u001b[38;5;241m=\u001b[39m check_jaxlib_version(\n\u001b[0;32m---> 74\u001b[0m   jax_version\u001b[38;5;241m=\u001b[39m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241m.\u001b[39m__version__,\n\u001b[1;32m     75\u001b[0m   jaxlib_version\u001b[38;5;241m=\u001b[39mjaxlib\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39m__version__,\n\u001b[1;32m     76\u001b[0m   minimum_jaxlib_version\u001b[38;5;241m=\u001b[39mjax\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39m_minimum_jaxlib_version)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Before importing any C compiled modules from jaxlib, first import the CPU\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# feature guard module to verify that jaxlib was compiled in a way that only\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# uses instructions that are present on this machine.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjaxlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpu_feature_guard\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcpu_feature_guard\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'jax' has no attribute 'version' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "from typing import Any, Callable, Sequence, Union\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "from jax import lax, random, numpy as jnp\n",
    "from flax.core import freeze, unfreeze, FrozenDict\n",
    "from flax import linen as nn\n",
    "from flax import struct\n",
    "from flax.training import train_state\n",
    "\n",
    "import optax\n",
    "\n",
    "from clu import metrics\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "from einops import reduce\n",
    "\n",
    "from iqadatasets.datasets import *\n",
    "from fxlayers.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "> We're going to employ `iqadatasets` to ease the loading of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'TID2008' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dst_train \u001b[38;5;241m=\u001b[39m \u001b[43mTID2008\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2008/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m dst_val \u001b[38;5;241m=\u001b[39m TID2013(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2013/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TID2008' is not defined"
     ]
    }
   ],
   "source": [
    "dst_train = TID2008(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2008/\")\n",
    "dst_val = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2013/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'dst_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img, img_dist, mos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mdst_train\u001b[49m\u001b[38;5;241m.\u001b[39mdataset))\n\u001b[1;32m      2\u001b[0m img\u001b[38;5;241m.\u001b[39mshape, img_dist\u001b[38;5;241m.\u001b[39mshape, mos\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dst_train' is not defined"
     ]
    }
   ],
   "source": [
    "img, img_dist, mos = next(iter(dst_train.dataset))\n",
    "img.shape, img_dist.shape, mos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'dst_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img, img_dist, mos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mdst_val\u001b[49m\u001b[38;5;241m.\u001b[39mdataset))\n\u001b[1;32m      2\u001b[0m img\u001b[38;5;241m.\u001b[39mshape, img_dist\u001b[38;5;241m.\u001b[39mshape, mos\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dst_val' is not defined"
     ]
    }
   ],
   "source": [
    "img, img_dist, mos = next(iter(dst_val.dataset))\n",
    "img.shape, img_dist.shape, mos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'ConfigDict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBATCH_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCHS\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLEARNING_RATE\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3e-4\u001b[39m,\n\u001b[1;32m      5\u001b[0m }\n\u001b[0;32m----> 6\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mConfigDict\u001b[49m(config)\n\u001b[1;32m      7\u001b[0m config\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ConfigDict' is not defined"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"EPOCHS\": 500,\n",
    "    \"LEARNING_RATE\": 3e-4,\n",
    "}\n",
    "config = ConfigDict(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerceptNet_JaX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m            name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGaborLast\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m            job_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m            config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m      5\u001b[0m            mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m            )\n\u001b[1;32m      7\u001b[0m config \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m      8\u001b[0m config\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"PerceptNet_JaX\",\n",
    "           name=\"GaborLast\",\n",
    "           job_type=\"training\",\n",
    "           config=config,\n",
    "           mode=\"online\",\n",
    "           )\n",
    "config = config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'dst_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dst_train_rdy \u001b[38;5;241m=\u001b[39m \u001b[43mdst_train\u001b[49m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mbatch(config\u001b[38;5;241m.\u001b[39mBATCH_SIZE, drop_remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m dst_val_rdy \u001b[38;5;241m=\u001b[39m dst_val\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mbatch(config\u001b[38;5;241m.\u001b[39mBATCH_SIZE, drop_remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dst_train' is not defined"
     ]
    }
   ],
   "source": [
    "dst_train_rdy = dst_train.dataset.batch(config.BATCH_SIZE, drop_remainder=True)\n",
    "dst_val_rdy = dst_val.dataset.batch(config.BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model we're going to use\n",
    "\n",
    "> It's going to be a very simple model just for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGDN\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\"Generalized Divisive Normalization.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     kernel_size: Union[\u001b[38;5;28mint\u001b[39m, Sequence[\u001b[38;5;28mint\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class GDN(nn.Module):\n",
    "    \"\"\"Generalized Divisive Normalization.\"\"\"\n",
    "    kernel_size: Union[int, Sequence[int]]\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    apply_independently: bool = False\n",
    "    # feature_group_count: int = 1\n",
    "    kernel_init: Callable = nn.initializers.lecun_normal()\n",
    "    bias_init: Callable = nn.initializers.ones_init()\n",
    "    alpha: float = 2.\n",
    "    epsilon: float = 1/2 # Exponential of the denominator\n",
    "    eps: float = 1e-6 # Numerical stability in the denominator\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 ):\n",
    "        denom = nn.Conv(features=inputs.shape[-1], # Same output channels as input\n",
    "                        kernel_size=self.kernel_size if isinstance(self.kernel_size, Sequence) else [self.kernel_size]*2, \n",
    "                        strides=self.strides, \n",
    "                        padding=self.padding,\n",
    "                        # feature_group_count=self.feature_group_count,\n",
    "                        feature_group_count=inputs.shape[-1] if self.apply_independently else 1,\n",
    "                        kernel_init=self.kernel_init, \n",
    "                        bias_init=self.bias_init)(inputs**self.alpha)\n",
    "        denom = nn.relu(denom)\n",
    "        return inputs / (denom**self.epsilon + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPerceptNet\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\"IQA model inspired by the visual system.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;129m@nn\u001b[39m\u001b[38;5;241m.\u001b[39mcompact\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m      6\u001b[0m                  inputs,\n\u001b[1;32m      7\u001b[0m                  \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m      8\u001b[0m                  ):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class PerceptNet(nn.Module):\n",
    "    \"\"\"IQA model inspired by the visual system.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=True)(inputs)\n",
    "        outputs = nn.Conv(features=3, kernel_size=(1,1), strides=1, padding=\"SAME\")(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        outputs = nn.Conv(features=6, kernel_size=(5,5), strides=1, padding=\"SAME\")(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        outputs = GaborLayer(features=128, kernel_size=21, strides=1, padding=\"SAME\", fs=21)(outputs, **kwargs)\n",
    "        # outputs = nn.Conv(features=128, kernel_size=(5,5), strides=1, padding=\"SAME\")(outputs)\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the metrics with `clu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'struct' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;129m@struct\u001b[39m\u001b[38;5;241m.\u001b[39mdataclass\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMetrics\u001b[39;00m(metrics\u001b[38;5;241m.\u001b[39mCollection):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124;03m\"\"\"Collection of metrics to be tracked during training.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     loss: metrics\u001b[38;5;241m.\u001b[39mAverage\u001b[38;5;241m.\u001b[39mfrom_output(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'struct' is not defined"
     ]
    }
   ],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    \"\"\"Collection of metrics to be tracked during training.\"\"\"\n",
    "    loss: metrics.Average.from_output(\"loss\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `TrainState` doesn't include metrics, but it's very easy to subclass it so that it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'train_state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTrainState\u001b[39;00m(\u001b[43mtrain_state\u001b[49m\u001b[38;5;241m.\u001b[39mTrainState):\n\u001b[1;32m      2\u001b[0m     metrics: Metrics\n\u001b[1;32m      3\u001b[0m     state: FrozenDict\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_state' is not defined"
     ]
    }
   ],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "    state: FrozenDict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a function that initializes the `TrainState` from a module, a rng key and some optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, key, tx, input_shape):\n",
    "    \"\"\"Creates the initial `TrainState`.\"\"\"\n",
    "    variables = module.init(key, jnp.ones(input_shape))\n",
    "    state, params = variables.pop('params')\n",
    "    return TrainState.create(\n",
    "        apply_fn=module.apply,\n",
    "        params=params,\n",
    "        state=state,\n",
    "        tx=tx,\n",
    "        metrics=Metrics.empty()\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the training step\n",
    "\n",
    "> We want to write a function that takes the `TrainState` and a batch of data can performs an optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation(vec1, vec2):\n",
    "    vec1 = vec1.squeeze()\n",
    "    vec2 = vec2.squeeze()\n",
    "    vec1_mean = vec1.mean()\n",
    "    vec2_mean = vec2.mean()\n",
    "    num = vec1-vec1_mean\n",
    "    num *= vec2-vec2_mean\n",
    "    num = num.sum()\n",
    "    denom = jnp.sqrt(jnp.sum((vec1-vec1_mean)**2))\n",
    "    denom *= jnp.sqrt(jnp.sum((vec2-vec2_mean)**2))\n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'jax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(state, batch):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124;03m\"\"\"Train for a single step.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     img, img_dist, mos \u001b[38;5;241m=\u001b[39m batch\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jax' is not defined"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    img, img_dist, mos = batch\n",
    "    def loss_fn(params):\n",
    "        ## Forward pass through the model\n",
    "        img_pred, updated_state = state.apply_fn({\"params\": params, **state.state}, img, mutable=list(state.state.keys()), train=True)\n",
    "        img_dist_pred, updated_state = state.apply_fn({\"params\": params, **state.state}, img_dist, mutable=list(state.state.keys()), train=True)\n",
    "\n",
    "        ## Calculate the distance\n",
    "        dist = ((img_pred - img_dist_pred)**2).sum(axis=(1,2,3))**(1/2)\n",
    "        \n",
    "        ## Calculate pearson correlation\n",
    "        return pearson_correlation(dist, mos), updated_state\n",
    "    \n",
    "    (loss, updated_state), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics_updates = state.metrics.single_from_model_output(loss=loss)\n",
    "    metrics = state.metrics.merge(metrics_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    state = state.replace(state=updated_state)\n",
    "    return state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In their example, they don't calculate the metrics at the same time. I think it is kind of a waste because it means having to perform a new forward pass, but we'll follow as of now. Let's define a function to perform metric calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'jax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics\u001b[39m(\u001b[38;5;241m*\u001b[39m, state, batch):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124;03m\"\"\"Obtaining the metrics for a given batch.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     img, img_dist, mos \u001b[38;5;241m=\u001b[39m batch\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jax' is not defined"
     ]
    }
   ],
   "source": [
    "@jax.jit\n",
    "def compute_metrics(*, state, batch):\n",
    "    \"\"\"Obtaining the metrics for a given batch.\"\"\"\n",
    "    img, img_dist, mos = batch\n",
    "    def loss_fn(params):\n",
    "        ## Forward pass through the model\n",
    "        img_pred, updated_state = state.apply_fn({\"params\": params, **state.state}, img, mutable=list(state.state.keys()), train=True)\n",
    "        img_dist_pred, updated_state = state.apply_fn({\"params\": params, **state.state}, img_dist, mutable=list(state.state.keys()), train=True)\n",
    "\n",
    "        ## Calculate the distance\n",
    "        dist = ((img_pred - img_dist_pred)**2).sum(axis=(1,2,3))**(1/2)\n",
    "        \n",
    "        ## Calculate pearson correlation\n",
    "        return pearson_correlation(dist, mos)\n",
    "    \n",
    "    metrics_updates = state.metrics.single_from_model_output(loss=loss_fn(state.params))\n",
    "    metrics = state.metrics.merge(metrics_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'PerceptNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state \u001b[38;5;241m=\u001b[39m create_train_state(\u001b[43mPerceptNet\u001b[49m(), random\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m), optax\u001b[38;5;241m.\u001b[39madam(config\u001b[38;5;241m.\u001b[39mLEARNING_RATE), input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m384\u001b[39m,\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PerceptNet' is not defined"
     ]
    }
   ],
   "source": [
    "state = create_train_state(PerceptNet(), random.PRNGKey(0), optax.adam(config.LEARNING_RATE), input_shape=(1,384,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'AttributeError'>",
     "evalue": "'dict' object has no attribute 'EPOCHS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'EPOCHS'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(config.EPOCHS):\n",
    "    ## Training\n",
    "    for batch in dst_train_rdy.as_numpy_iterator():\n",
    "        state = train_step(state, batch)\n",
    "        # state = compute_metrics(state=state, batch=batch)\n",
    "        # break\n",
    "\n",
    "    ## Log the metrics\n",
    "    for name, value in state.metrics.compute().items():\n",
    "        metrics_history[f\"train_{name}\"].append(value)\n",
    "    \n",
    "    ## Empty the metrics\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "\n",
    "    ## Evaluation\n",
    "    for batch in dst_val_rdy.as_numpy_iterator():\n",
    "        state = compute_metrics(state=state, batch=batch)\n",
    "        # break\n",
    "    for name, value in state.metrics.compute().items():\n",
    "        metrics_history[f\"val_{name}\"].append(value)\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "    \n",
    "    wandb.log({\"epoch\": epoch+1, **{name:values[-1] for name, values in metrics_history.items()}})\n",
    "    print(f'Epoch {epoch} -> [Train] Loss: {metrics_history[\"train_loss\"][-1]} [Val] Loss: {metrics_history[\"val_loss\"][-1]}')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241m.\u001b[39mfinish()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filters \u001b[38;5;241m=\u001b[39m rearrange(\u001b[43mstate\u001b[49m\u001b[38;5;241m.\u001b[39mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecalc_filter\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGaborLayer_0\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkx ky cin cout -> (cin cout) kx ky\u001b[39m\u001b[38;5;124m\"\u001b[39m)[:\u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m      2\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(filters))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(filters, axes\u001b[38;5;241m.\u001b[39mravel()):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "filters = rearrange(state.state[\"precalc_filter\"][\"GaborLayer_0\"][\"kernel\"], \"kx ky cin cout -> (cin cout) kx ky\")[:10]\n",
    "fig, axes = plt.subplots(1,len(filters))\n",
    "for k, ax in zip(filters, axes.ravel()):\n",
    "    ax.imshow(k)\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
