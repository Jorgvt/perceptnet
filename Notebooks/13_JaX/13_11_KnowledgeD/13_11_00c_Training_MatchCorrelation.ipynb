{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IQA tracking params and variables\n",
    "\n",
    "> When using parametric layers we have to be able to keep track of the parameters and the variables of the model (which are not going to be trained). We're going to play with this concept using our implementation of the functional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os; os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".99\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 17:06:09.440698: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-28 17:06:13.236137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-06-28 17:06:30.532636: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:1: failed initializing StreamExecutor for CUDA device ordinal 1: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "2024-06-28 17:06:30.532703: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "from typing import Any, Callable, Sequence, Union\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "import jax\n",
    "from jax import lax, random, numpy as jnp\n",
    "import flax\n",
    "from flax.core import freeze, unfreeze, FrozenDict\n",
    "from flax import linen as nn\n",
    "from flax import struct\n",
    "from flax.training import train_state\n",
    "from flax.training import orbax_utils\n",
    "\n",
    "import optax\n",
    "import orbax.checkpoint\n",
    "\n",
    "from clu import metrics\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "from einops import reduce, rearrange, repeat\n",
    "import wandb\n",
    "from iqadatasets.datasets import *\n",
    "from fxlayers.layers import *\n",
    "from fxlayers.layers import GaussianLayerGamma, FreqGaussianGamma, OrientGaussianGamma, GaborLayerGamma_, GaborLayerGammaRepeat\n",
    "from fxlayers.initializers import *\n",
    "from JaxPlayground.utils.constraints import *\n",
    "from JaxPlayground.utils.wandb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jax.config.update(\"jax_debug_nans\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "> We're going to employ `iqadatasets` to ease the loading of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'FileNotFoundError'>",
     "evalue": "[Errno 2] No such file or directory: '/lustre/ific.uv.es/ml/uv075/Databases/IQA/TID/TID2008/image_pairs_mos.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dst_train \u001b[38;5;241m=\u001b[39m \u001b[43mTID2008\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2008/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_imgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# dst_train = KADIK10K(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/KADIK10K/\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m dst_val \u001b[38;5;241m=\u001b[39m TID2013(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2013/\u001b[39m\u001b[38;5;124m\"\u001b[39m, exclude_imgs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m25\u001b[39m])\n",
      "File \u001b[0;32m~/LoadingLIVE/iqadatasets/datasets/tid2008.py:29\u001b[0m, in \u001b[0;36mTID2008.__init__\u001b[0;34m(self, path, exclude_imgs, exclude_dist, exclude_ints, num_parallel_calls)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_root\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistorted_images\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_root\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_pairs_mos.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_dist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_ints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpaths_ref \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_ref\u001b[38;5;241m/\u001b[39mp) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReference\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpaths_dist \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_dist\u001b[38;5;241m/\u001b[39mp) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistorted\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m~/LoadingLIVE/iqadatasets/datasets/tid2008.py:62\u001b[0m, in \u001b[0;36mTID2008.load_data\u001b[0;34m(self, path, exclude_imgs, exclude_dist, exclude_ints)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     57\u001b[0m               path,\n\u001b[1;32m     58\u001b[0m               exclude_imgs,\n\u001b[1;32m     59\u001b[0m               exclude_dist,\n\u001b[1;32m     60\u001b[0m               exclude_ints,\n\u001b[1;32m     61\u001b[0m               ):\n\u001b[0;32m---> 62\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m~\u001b[39mdata\u001b[38;5;241m.\u001b[39mReference_ID\u001b[38;5;241m.\u001b[39misin(exclude_imgs)] \u001b[38;5;28;01mif\u001b[39;00m exclude_imgs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m data\n\u001b[1;32m     64\u001b[0m     data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m~\u001b[39mdata\u001b[38;5;241m.\u001b[39mReference_ID\u001b[38;5;241m.\u001b[39misin(exclude_dist)] \u001b[38;5;28;01mif\u001b[39;00m exclude_dist \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/deep_gpu_tf/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deep_gpu_tf/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/deep_gpu_tf/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deep_gpu_tf/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/deep_gpu_tf/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/lustre/ific.uv.es/ml/uv075/Databases/IQA/TID/TID2008/image_pairs_mos.csv'"
     ]
    }
   ],
   "source": [
    "# dst_train = TID2008(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2008/\", exclude_imgs=[25])\n",
    "# dst_train = KADIK10K(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/KADIK10K/\")\n",
    "# dst_val = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2013/\", exclude_imgs=[25])\n",
    "dst_train = TID2008(\"/media/disk/vista/BBDD_video_image/Image_Quality//TID/TID2008/\", exclude_imgs=[25])\n",
    "dst_val = TID2013(\"/media/disk/vista/BBDD_video_image/Image_Quality//TID/TID2013/\", exclude_imgs=[25])\n",
    "# dst_train = TID2008(\"/media/databases/IQA/TID/TID2008/\", exclude_imgs=[25])\n",
    "# dst_val = TID2013(\"/media/databases/IQA/TID/TID2013/\", exclude_imgs=[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'dst_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img, img_dist, mos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mdst_train\u001b[49m\u001b[38;5;241m.\u001b[39mdataset))\n\u001b[1;32m      2\u001b[0m img\u001b[38;5;241m.\u001b[39mshape, img_dist\u001b[38;5;241m.\u001b[39mshape, mos\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dst_train' is not defined"
     ]
    }
   ],
   "source": [
    "img, img_dist, mos = next(iter(dst_train.dataset))\n",
    "img.shape, img_dist.shape, mos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'dst_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img, img_dist, mos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mdst_val\u001b[49m\u001b[38;5;241m.\u001b[39mdataset))\n\u001b[1;32m      2\u001b[0m img\u001b[38;5;241m.\u001b[39mshape, img_dist\u001b[38;5;241m.\u001b[39mshape, mos\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dst_val' is not defined"
     ]
    }
   ],
   "source": [
    "img, img_dist, mos = next(iter(dst_val.dataset))\n",
    "img.shape, img_dist.shape, mos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A_GABOR: false\n",
       "A_GDNSPATIOFREQORIENT: false\n",
       "BATCH_SIZE: 64\n",
       "CS_KERNEL_SIZE: 21\n",
       "EPOCHS: 500\n",
       "GABOR_KERNEL_SIZE: 31\n",
       "GDNGAUSSIAN_KERNEL_SIZE: 11\n",
       "GDNSPATIOFREQ_KERNEL_SIZE: 11\n",
       "GDN_CLIPPING: true\n",
       "INIT_GABOR: true\n",
       "INIT_JH: true\n",
       "LEARNER_LR: 0.0003\n",
       "NORMALIZE_ENERGY: true\n",
       "NORMALIZE_PROB: false\n",
       "N_GABORS: 128\n",
       "N_ORIENTATIONS: 16\n",
       "N_SCALES: 4\n",
       "SEED: 42\n",
       "TRAIN_CS: false\n",
       "TRAIN_GABOR: false\n",
       "TRAIN_JH: false\n",
       "TRAIN_ONLY_LAST_GDN: true\n",
       "USE_BIAS: false\n",
       "USE_GAMMA: true\n",
       "ZERO_MEAN: true"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"EPOCHS\": 500,\n",
    "    \"LEARNER_LR\": 3e-4,\n",
    "    # \"INITIAL_LR\": 1e-2,\n",
    "    # \"PEAK_LR\": 4e-2,\n",
    "    # \"END_LR\": 5e-3,\n",
    "    # \"WARMUP_EPOCHS\": 15,\n",
    "    \"SEED\": 42,\n",
    "    \"GDN_CLIPPING\": True,\n",
    "    \"NORMALIZE_PROB\": False,\n",
    "    \"NORMALIZE_ENERGY\": True,\n",
    "    \"ZERO_MEAN\": True,\n",
    "    \"USE_BIAS\": False,\n",
    "    \"CS_KERNEL_SIZE\": 21,\n",
    "    \"GDNGAUSSIAN_KERNEL_SIZE\": 11,\n",
    "    \"GDNSPATIOFREQ_KERNEL_SIZE\": 11,\n",
    "    \"GABOR_KERNEL_SIZE\": 31,\n",
    "    \"N_SCALES\": 4,\n",
    "    \"N_ORIENTATIONS\": 16,\n",
    "    \"N_GABORS\": 128,\n",
    "    \"USE_GAMMA\": True,\n",
    "    \"INIT_JH\": True,\n",
    "    \"INIT_GABOR\": True,\n",
    "    \"TRAIN_JH\": False,\n",
    "    \"TRAIN_CS\": False,\n",
    "    \"TRAIN_GABOR\": False,\n",
    "    \"A_GABOR\": False,\n",
    "    \"A_GDNSPATIOFREQORIENT\": False,\n",
    "    \"TRAIN_ONLY_LAST_GDN\": True,\n",
    "}\n",
    "config = ConfigDict(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: jorgvt. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/disk/users/vitojor/perceptnet/Notebooks/13_JaX/13_11_KnowledgeD/wandb/run-20240708_173752-lnvkxmdh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jorgvt/ParametricKnowledgeDistillation/runs/lnvkxmdh' target=\"_blank\">FinalModel_to_Baseline_Correlation</a></strong> to <a href='https://wandb.ai/jorgvt/ParametricKnowledgeDistillation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jorgvt/ParametricKnowledgeDistillation' target=\"_blank\">https://wandb.ai/jorgvt/ParametricKnowledgeDistillation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jorgvt/ParametricKnowledgeDistillation/runs/lnvkxmdh' target=\"_blank\">https://wandb.ai/jorgvt/ParametricKnowledgeDistillation/runs/lnvkxmdh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "A_GABOR: false\n",
       "A_GDNSPATIOFREQORIENT: false\n",
       "BATCH_SIZE: 64\n",
       "CS_KERNEL_SIZE: 21\n",
       "EPOCHS: 500\n",
       "GABOR_KERNEL_SIZE: 31\n",
       "GDNGAUSSIAN_KERNEL_SIZE: 11\n",
       "GDNSPATIOFREQ_KERNEL_SIZE: 11\n",
       "GDN_CLIPPING: true\n",
       "INIT_GABOR: true\n",
       "INIT_JH: true\n",
       "LEARNER_LR: 0.0003\n",
       "NORMALIZE_ENERGY: true\n",
       "NORMALIZE_PROB: false\n",
       "N_GABORS: 128\n",
       "N_ORIENTATIONS: 16\n",
       "N_SCALES: 4\n",
       "SEED: 42\n",
       "TRAIN_CS: false\n",
       "TRAIN_GABOR: false\n",
       "TRAIN_JH: false\n",
       "TRAIN_ONLY_LAST_GDN: true\n",
       "USE_BIAS: false\n",
       "USE_GAMMA: true\n",
       "ZERO_MEAN: true"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"ParametricKnowledgeDistillation\",\n",
    "           name=\"FinalModel_to_Baseline_Correlation\",\n",
    "           job_type=\"training\",\n",
    "           config=config,\n",
    "           mode=\"online\",\n",
    "           )\n",
    "config = config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'dst_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dst_train_rdy \u001b[38;5;241m=\u001b[39m \u001b[43mdst_train\u001b[49m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      2\u001b[0m                                       reshuffle_each_iteration\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m                                       seed\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mSEED)\\\n\u001b[1;32m      4\u001b[0m                                  \u001b[38;5;241m.\u001b[39mbatch(config\u001b[38;5;241m.\u001b[39mBATCH_SIZE, drop_remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m dst_val_rdy \u001b[38;5;241m=\u001b[39m dst_val\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mbatch(config\u001b[38;5;241m.\u001b[39mBATCH_SIZE, drop_remainder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dst_train' is not defined"
     ]
    }
   ],
   "source": [
    "dst_train_rdy = dst_train.dataset.shuffle(buffer_size=100,\n",
    "                                      reshuffle_each_iteration=True,\n",
    "                                      seed=config.SEED)\\\n",
    "                                 .batch(config.BATCH_SIZE, drop_remainder=True)\n",
    "dst_val_rdy = dst_val.dataset.batch(config.BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model we're going to use\n",
    "\n",
    "> It's going to be a very simple model just for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class ChromaFreqOrientGaussianGamma(nn.Module):\n",
    "    \"\"\"(1D) Gaussian interaction between gamma_fuencies and orientations optimizing gamma = 1/sigma instead of sigma.\"\"\"\n",
    "    use_bias: bool = False\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    bias_init: Callable = nn.initializers.zeros_init()\n",
    "    n_scales: Sequence[int] = jnp.array([4, 2, 2], dtype=jnp.int32)\n",
    "    n_orientations: Sequence[int] = jnp.array([8, 8, 8], dtype=jnp.int32)\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 fmean,\n",
    "                 theta_mean,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "\n",
    "        gamma_f_a = self.param(\"gamma_f_a\",\n",
    "                             k_array(1/0.4, arr=jnp.array([2.,4.,8.,16.])),\n",
    "                             (self.n_scales[0],))\n",
    "        gamma_theta_a = self.param(\"gamma_theta_a\",\n",
    "                                 nn.initializers.ones_init(),\n",
    "                                #  (self.n_orientations[0],))\n",
    "                                 (8,))\n",
    "\n",
    "        gamma_f_t = self.param(\"gamma_f_t\",\n",
    "                             k_array(1/0.4, arr=jnp.array([3.,6.])),\n",
    "                             (self.n_scales[1],))\n",
    "        gamma_theta_t = self.param(\"gamma_theta_t\",\n",
    "                                 nn.initializers.ones_init(),\n",
    "                                #  (self.n_orientations[1],))\n",
    "                                 (8,))\n",
    "        \n",
    "        gamma_f_d = self.param(\"gamma_f_d\",\n",
    "                             k_array(1/0.4, arr=jnp.array([3.,6.])),\n",
    "                             (self.n_scales[2],))\n",
    "        gamma_theta_d = self.param(\"gamma_theta_d\",\n",
    "                                 nn.initializers.ones_init(),\n",
    "                                #  (self.n_orientations[2],))\n",
    "                                 (8,))\n",
    "\n",
    "        H_cc = self.param(\"H_cc\",\n",
    "                          nn.initializers.ones_init(),\n",
    "                          (3,3))\n",
    "\n",
    "        if self.use_bias: bias = self.param(\"bias\",\n",
    "                                            self.bias_init,\n",
    "                                            (len(fmean),))\n",
    "        else: bias = 0.\n",
    "        # n_groups = inputs.shape[-1] // len(fmean)\n",
    "\n",
    "        ## Repeat gammas\n",
    "        gamma_f = jnp.concatenate([jnp.tile(f, reps=len(t)) for f,t in zip([gamma_f_a, gamma_f_t, gamma_f_d], [gamma_theta_a, gamma_theta_t, gamma_theta_d])])\n",
    "        gamma_f = jnp.tile(gamma_f, reps=2)\n",
    "        gamma_theta = jnp.concatenate([jnp.tile(t, reps=len(f)) for f,t in zip([gamma_f_a, gamma_f_t, gamma_f_d], [gamma_theta_a, gamma_theta_t, gamma_theta_d])])\n",
    "        gamma_theta = jnp.tile(gamma_theta, reps=2)\n",
    "\n",
    "        ## Repeating\n",
    "        cc = jnp.array([0,1,2])\n",
    "        cc = jnp.repeat(cc, repeats=jnp.array([64,32,32]), total_repeat_length=len(fmean))\n",
    "\n",
    "        kernel = jax.vmap(self.gaussian, in_axes=(None,None,0,0,0,0,None,0,None,None), out_axes=1)(fmean, theta_mean, fmean, theta_mean, gamma_f, gamma_theta, cc, cc, H_cc, 1)\n",
    "        kernel = kernel[None,None,:,:]\n",
    "\n",
    "        ## Add the batch dim if the input is a single element\n",
    "        if jnp.ndim(inputs) < 4: inputs = inputs[None,:]; had_batch = False\n",
    "        else: had_batch = True\n",
    "        outputs = lax.conv_general_dilated(\n",
    "                jnp.transpose(inputs,[0,3,1,2]),    # lhs = NCHW image tensor\n",
    "                jnp.transpose(kernel,[3,2,0,1]), # rhs = OIHW conv kernel tensor\n",
    "                (self.strides, self.strides),\n",
    "                self.padding)\n",
    "        ## Move the channels back to the last dim\n",
    "        outputs = jnp.transpose(outputs, (0,2,3,1))\n",
    "        if not had_batch: outputs = outputs[0]\n",
    "        return outputs + bias\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian(f, theta, fmean, theta_mean, gamma_f, gamma_theta, c_1, c_2, H_cc, A=1):\n",
    "        return H_cc[c_1,c_2]*A*jnp.exp(-((gamma_f**2)*(f-fmean)**2)/(2))*jnp.exp(-((gamma_theta**2)*(theta-theta_mean)**2)/(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDNSpatioChromaFreqOrient(nn.Module):\n",
    "    \"\"\"Generalized Divisive Normalization.\"\"\"\n",
    "    kernel_size: Union[int, Sequence[int]]\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    # inputs_star: float = 1.\n",
    "    # outputs_star: Union[None, float] = None\n",
    "    fs: int = 1\n",
    "    apply_independently: bool = False\n",
    "    bias_init: Callable = nn.initializers.ones_init()\n",
    "    alpha: float = 2.\n",
    "    epsilon: float = 1/2 # Exponential of the denominator\n",
    "    eps: float = 1e-6 # Numerical stability in the denominator\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 fmean,\n",
    "                 theta_mean,\n",
    "                 train=False,\n",
    "                 ):\n",
    "        b, h, w, c = inputs.shape\n",
    "        bias = self.param(\"bias\",\n",
    "                          #equal_to(inputs_star/10),\n",
    "                          self.bias_init,\n",
    "                          (c,))\n",
    "        # is_initialized = self.has_variable(\"batch_stats\", \"inputs_star\")\n",
    "        # inputs_star = self.variable(\"batch_stats\", \"inputs_star\", lambda x: jnp.ones(x)*self.inputs_star, (len(self.inputs_star),))\n",
    "        # inputs_star_ = jnp.ones_like(inputs)*inputs_star.value\n",
    "        GL = GaussianLayerGamma(features=c, kernel_size=self.kernel_size, strides=self.strides, padding=\"VALID\", fs=self.fs, xmean=self.kernel_size/self.fs/2, ymean=self.kernel_size/self.fs/2, normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY, use_bias=False, feature_group_count=c)\n",
    "        FOG = ChromaFreqOrientGaussianGamma()\n",
    "        outputs = GL(pad_same_from_kernel_size(inputs, kernel_size=self.kernel_size, mode=self.padding)**self.alpha, train=train)#/(self.kernel_size**2)\n",
    "        outputs = FOG(outputs, fmean=fmean, theta_mean=theta_mean)\n",
    "\n",
    "        ## Coef\n",
    "        # coef = GL(inputs_star_**self.alpha, train=train)#/(self.kernel_size**2)\n",
    "        # coef = FG(coef, fmean=fmean)\n",
    "        # coef = rearrange(coef, \"b h w (phase theta f) -> b h w (phase f theta)\", b=b, h=h, w=w, phase=2, f=config.N_SCALES, theta=config.N_ORIENTATIONS)\n",
    "        # coef = OG(coef, theta_mean=theta_mean) + bias\n",
    "        # coef = rearrange(coef, \"b h w (phase f theta) -> b h w (phase theta f)\", b=b, h=h, w=w, phase=2, f=config.N_SCALES, theta=config.N_ORIENTATIONS)\n",
    "        # coef = jnp.clip(coef+bias, a_min=1e-5)**self.epsilon\n",
    "        # # coef = inputs_star.value * coef\n",
    "        # if self.outputs_star is not None: coef = coef/inputs_star.value*self.outputs_star\n",
    "\n",
    "        # if is_initialized and train:\n",
    "        #     inputs_star.value = (inputs_star.value + jnp.quantile(jnp.abs(inputs), q=0.95, axis=(0,1,2)))/2\n",
    "        # return coef * inputs / (jnp.clip(denom+bias, a_min=1e-5)**self.epsilon + self.eps)\n",
    "        return inputs / (jnp.clip(outputs+bias, a_min=1e-5)**self.epsilon + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaborLayerGammaHumanLike_(nn.Module):\n",
    "    \"\"\"Parametric Gabor layer with particular initialization.\"\"\"\n",
    "    n_scales: Sequence[int] # [A, T, D]\n",
    "    n_orientations: Sequence[int] # [A, T, D]\n",
    "\n",
    "    kernel_size: Union[int, Sequence[int]]\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    feature_group_count: int = 1\n",
    "\n",
    "    use_bias: bool = False\n",
    "    xmean: float = 0.5\n",
    "    ymean: float = 0.5\n",
    "    fs: float = 1 # Sampling frequency\n",
    "    phase = jnp.array([0., jnp.pi/2.])\n",
    "\n",
    "    normalize_prob: bool = True\n",
    "    normalize_energy: bool = False\n",
    "    zero_mean: bool = False\n",
    "    train_A: bool = False\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 train=False,\n",
    "                 return_freq=False,\n",
    "                 return_theta=False,\n",
    "                 ):\n",
    "        total_scales = jnp.sum(jnp.array(self.n_scales))\n",
    "        total_orientations = jnp.sum(jnp.array(self.n_orientations))\n",
    "        features = jnp.sum(jnp.array([s*o*len(self.phase) for s, o in zip(self.n_scales, self.n_orientations)]))\n",
    "\n",
    "        is_initialized = self.has_variable(\"precalc_filter\", \"kernel\")\n",
    "        precalc_filters = self.variable(\"precalc_filter\",\n",
    "                                        \"kernel\",\n",
    "                                        jnp.zeros,\n",
    "                                        (self.kernel_size, self.kernel_size, inputs.shape[-1], features))\n",
    "        freq_a = self.param(\"freq_a\",\n",
    "                           freq_scales_init(n_scales=self.n_scales[0], fs=self.fs),\n",
    "                           (self.n_scales[0],))\n",
    "        gammax_a = self.param(\"gammax_a\",\n",
    "                           k_array(k=0.4, arr=1/(freq_a**0.8)),\n",
    "                           (self.n_scales[0],))\n",
    "        gammay_a = self.param(\"gammay_a\",\n",
    "                            equal_to(gammax_a*0.8),\n",
    "                            (self.n_scales[0],))\n",
    "        theta_a = self.param(\"theta_a\",\n",
    "                           linspace(start=0, stop=jnp.pi, num=self.n_orientations[0]),\n",
    "                           (self.n_orientations[0],))\n",
    "        sigma_theta_a = self.param(\"sigma_theta_a\",\n",
    "                                  equal_to(theta_a),\n",
    "                                  (self.n_orientations[0],))\n",
    "\n",
    "        freq_t = self.param(\"freq_t\",\n",
    "                           freq_scales_init(n_scales=self.n_scales[1], fs=self.fs),\n",
    "                           (self.n_scales[1],))\n",
    "        gammax_t = self.param(\"gammax_t\",\n",
    "                           k_array(k=0.4, arr=1/(freq_t**0.8)),\n",
    "                           (self.n_scales[1],))\n",
    "        gammay_t = self.param(\"gammay_t\",\n",
    "                            equal_to(gammax_t*0.8),\n",
    "                            (self.n_scales[1],))\n",
    "        theta_t = self.param(\"theta_t\",\n",
    "                           linspace(start=0, stop=jnp.pi, num=self.n_orientations[1]),\n",
    "                           (self.n_orientations[1],))\n",
    "        sigma_theta_t = self.param(\"sigma_theta_t\",\n",
    "                                  equal_to(theta_t),\n",
    "                                  (self.n_orientations[1],))\n",
    "\n",
    "        freq_d = self.param(\"freq_d\",\n",
    "                           freq_scales_init(n_scales=self.n_scales[2], fs=self.fs),\n",
    "                           (self.n_scales[2],))\n",
    "        gammax_d = self.param(\"gammax_d\",\n",
    "                           k_array(k=0.4, arr=1/(freq_d**0.8)),\n",
    "                           (self.n_scales[2],))\n",
    "        gammay_d = self.param(\"gammay_d\",\n",
    "                            equal_to(gammax_d*0.8),\n",
    "                            (self.n_scales[2],))\n",
    "        theta_d = self.param(\"theta_d\",\n",
    "                           linspace(start=0, stop=jnp.pi, num=self.n_orientations[2]),\n",
    "                           (self.n_orientations[2],))\n",
    "        sigma_theta_d = self.param(\"sigma_theta_d\",\n",
    "                                  equal_to(theta_d),\n",
    "                                  (self.n_orientations[2],))\n",
    "\n",
    "        # A = self.param(\"A\",\n",
    "        #                nn.initializers.ones_init(),\n",
    "        #                (inputs.shape[-1], features)) if self.train_A else jnp.ones(shape=(inputs.shape[-1], features))\n",
    "        A = self.param(\"A\",\n",
    "                       nn.initializers.ones_init(),\n",
    "                       (inputs.shape[-1], 128))\n",
    "        if self.use_bias: bias = self.param(\"bias\",\n",
    "                                            self.bias_init,\n",
    "                                            (features,))\n",
    "        else: bias = 0.\n",
    "\n",
    "        if is_initialized and not train: \n",
    "            kernel = precalc_filters.value\n",
    "        elif is_initialized and train: \n",
    "            x, y = self.generate_dominion()\n",
    "            ## A\n",
    "            kernel_a = jax.vmap(self.gabor, in_axes=(None,None,None,None,0,0,0,None,None,None,None,None,None,None), out_axes=0)\n",
    "            kernel_a = jax.vmap(kernel_a, in_axes=(None,None,None,None,None,None,None,0,0,None,None,None,None,None), out_axes=0)\n",
    "            kernel_a = jax.vmap(kernel_a, in_axes=(None,None,None,None,None,None,None,None,None,0,None,None,None,None), out_axes=0)(x, y, self.xmean, self.ymean, gammax_a, gammay_a, freq_a, theta_a, sigma_theta_a, self.phase, 1, self.normalize_prob, self.normalize_energy, self.zero_mean)\n",
    "            kernel_a = rearrange(kernel_a, \"phases rots fs_sigmas kx ky -> kx ky (phases rots fs_sigmas)\")\n",
    "            kernel_a = repeat(kernel_a, \"kx ky c_out -> kx ky c_in c_out\", c_in=inputs.shape[-1], c_out=kernel_a.shape[-1])\n",
    "\n",
    "            ## T\n",
    "            kernel_t = jax.vmap(self.gabor, in_axes=(None,None,None,None,0,0,0,None,None,None,None,None,None,None), out_axes=0)\n",
    "            kernel_t = jax.vmap(kernel_t, in_axes=(None,None,None,None,None,None,None,0,0,None,None,None,None,None), out_axes=0)\n",
    "            kernel_t = jax.vmap(kernel_t, in_axes=(None,None,None,None,None,None,None,None,None,0,None,None,None,None), out_axes=0)(x, y, self.xmean, self.ymean, gammax_t, gammay_t, freq_t, theta_t, sigma_theta_t, self.phase, 1, self.normalize_prob, self.normalize_energy, self.zero_mean)\n",
    "            kernel_t = rearrange(kernel_t, \"phases rots fs_sigmas kx ky -> kx ky (phases rots fs_sigmas)\")\n",
    "            kernel_t = repeat(kernel_t, \"kx ky c_out -> kx ky c_in c_out\", c_in=inputs.shape[-1], c_out=kernel_t.shape[-1])\n",
    "\n",
    "            ## D\n",
    "            kernel_d = jax.vmap(self.gabor, in_axes=(None,None,None,None,0,0,0,None,None,None,None,None,None,None), out_axes=0)\n",
    "            kernel_d = jax.vmap(kernel_d, in_axes=(None,None,None,None,None,None,None,0,0,None,None,None,None,None), out_axes=0)\n",
    "            kernel_d = jax.vmap(kernel_d, in_axes=(None,None,None,None,None,None,None,None,None,0,None,None,None,None), out_axes=0)(x, y, self.xmean, self.ymean, gammax_d, gammay_d, freq_d, theta_d, sigma_theta_d, self.phase, 1, self.normalize_prob, self.normalize_energy, self.zero_mean)\n",
    "            kernel_d = rearrange(kernel_d, \"phases rots fs_sigmas kx ky -> kx ky (phases rots fs_sigmas)\")\n",
    "            kernel_d = repeat(kernel_d, \"kx ky c_out -> kx ky c_in c_out\", c_in=inputs.shape[-1], c_out=kernel_d.shape[-1])\n",
    "\n",
    "            ## Concat all of them\n",
    "            kernel = jnp.concatenate([kernel_a, kernel_t, kernel_d], axis=-1)\n",
    "            kernel = kernel * A[None,None,:,:]\n",
    "            precalc_filters.value = kernel\n",
    "        else:\n",
    "            kernel = precalc_filters.value\n",
    "\n",
    "        ## Add the batch dim if the input is a single element\n",
    "        if jnp.ndim(inputs) < 4: inputs = inputs[None,:]; had_batch = False\n",
    "        else: had_batch = True\n",
    "        outputs = lax.conv(jnp.transpose(inputs,[0,3,1,2]),    # lhs = NCHW image tensor\n",
    "               jnp.transpose(kernel,[3,2,0,1]), # rhs = OIHW conv kernel tensor\n",
    "               (self.strides, self.strides),\n",
    "               self.padding)\n",
    "        ## Move the channels back to the last dim\n",
    "        outputs = jnp.transpose(outputs, (0,2,3,1))\n",
    "        fmean = jnp.concatenate([jnp.tile(f, reps=len(t)) for f,t in zip([freq_a, freq_t, freq_d], [theta_a, theta_t, theta_d])])\n",
    "        fmean = jnp.tile(fmean, reps=2)\n",
    "        theta_mean = jnp.concatenate([jnp.tile(t, reps=len(f)) for f,t in zip([freq_a, freq_t, freq_d], [theta_a, theta_t, theta_d])])\n",
    "        theta_mean = jnp.tile(theta_mean, reps=2)\n",
    "\n",
    "        if not had_batch: outputs = outputs[0]\n",
    "        if return_freq and return_theta:\n",
    "            return outputs + bias, fmean, theta_mean \n",
    "        elif return_freq and not return_theta:\n",
    "            return outputs + bias, fmean\n",
    "        elif not return_freq and return_theta:\n",
    "            return outputs + bias, theta_mean\n",
    "        else:\n",
    "            return outputs + bias\n",
    "\n",
    "    @staticmethod\n",
    "    def gabor(x, y, xmean, ymean, gammax, gammay, freq, theta, sigma_theta, phase, A=1, normalize_prob=True, normalize_energy=False, zero_mean=False):\n",
    "        x, y = x-xmean, y-ymean\n",
    "        ## Obtain the normalization coeficient\n",
    "        gamma_vector = jnp.array([gammax, gammay])\n",
    "        inv_cov_matrix = jnp.diag(gamma_vector)**2\n",
    "        # det_cov_matrix = 1/jnp.linalg.det(cov_matrix)\n",
    "        # # A_norm = 1/(2*jnp.pi*jnp.sqrt(det_cov_matrix)) if normalize_prob else 1.\n",
    "        # A_norm = jnp.where(normalize_prob, 1/(2*jnp.pi*jnp.sqrt(det_cov_matrix)), 1.)\n",
    "        A_norm = 1.\n",
    "        \n",
    "        ## Rotate the sinusoid\n",
    "        rotation_matrix = jnp.array([[jnp.cos(sigma_theta), -jnp.sin(sigma_theta)],\n",
    "                                     [jnp.sin(sigma_theta), jnp.cos(sigma_theta)]])\n",
    "        rotated_covariance = rotation_matrix @ inv_cov_matrix @ jnp.transpose(rotation_matrix)\n",
    "        x_r_1 = rotated_covariance[0,0] * x + rotated_covariance[0,1] * y\n",
    "        y_r_1 = rotated_covariance[1,0] * x + rotated_covariance[1,1] * y\n",
    "        distance = x * x_r_1 + y * y_r_1\n",
    "        g = A_norm*jnp.exp(-distance/2) * jnp.cos(2*jnp.pi*freq*(x*jnp.cos(theta)+y*jnp.sin(theta)) + phase)\n",
    "        g = jnp.where(zero_mean, g - g.mean(), g)\n",
    "        E_norm = jnp.where(normalize_energy, jnp.sqrt(jnp.sum(g**2)), 1.)\n",
    "        return A*g/E_norm\n",
    "\n",
    "    def return_kernel(self, params, c_in=3):\n",
    "        x, y = self.generate_dominion()\n",
    "        sigmax, sigmay = jnp.exp(params[\"sigmax\"]), jnp.exp(params[\"sigmay\"])\n",
    "        kernel = jax.vmap(self.gabor, in_axes=(None,None,None,None,0,0,None,None,None,None,None,None,None), out_axes=0)\n",
    "        kernel = jax.vmap(kernel, in_axes=(None,None,None,None,None,None,0,None,None,None,None,None,None), out_axes=0)\n",
    "        kernel = jax.vmap(kernel, in_axes=(None,None,None,None,None,None,None,0,0,0,None,None,None), out_axes=0)(x, y, self.xmean, self.ymean, params[\"sigmax\"], params[\"sigmay\"], params[\"freq\"], params[\"theta\"], params[\"sigma_theta\"], self.phase, 1, self.normalize_prob, self.normalize_energy)\n",
    "        # kernel = rearrange(kernel, \"(c_in c_out) kx ky -> kx ky c_in c_out\", c_in=inputs.shape[-1], c_out=self.features)\n",
    "        kernel = rearrange(kernel, \"rots fs sigmas kx ky -> kx ky (rots fs sigmas)\")\n",
    "        kernel = repeat(kernel, \"kx ky c_out -> kx ky c_in c_out\", c_in=c_in, c_out=kernel.shape[-1])\n",
    "        return kernel\n",
    "    \n",
    "    def generate_dominion(self):\n",
    "        return jnp.meshgrid(jnp.linspace(0,self.kernel_size/self.fs,num=self.kernel_size), jnp.linspace(0,self.kernel_size/self.fs,num=self.kernel_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNet(nn.Module):\n",
    "    \"\"\"IQA model inspired by the visual system.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs, # Assuming fs = 128 (cpd)\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        ## (Independent) Color equilibration (Gamma correction)\n",
    "        ## Might need to be the same for each number\n",
    "        ## bias = 0.1 / kernel = 0.5\n",
    "        if config.USE_GAMMA: outputs = GDNGamma()(inputs)\n",
    "        else: outputs = GDN(kernel_size=(1,1), apply_independently=True)(inputs)\n",
    "        \n",
    "        ## Color (ATD) Transformation\n",
    "        outputs = nn.Conv(features=3, kernel_size=(1,1), use_bias=False, name=\"Color\")(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        \n",
    "        ## GDN Star A - T - D [Separated]\n",
    "        outputs = GDN(kernel_size=(1,1), apply_independently=True)(outputs)\n",
    "\n",
    "        ## Center Surround (DoG)\n",
    "        ## Initialized so that 3 are positives and 3 are negatives and no interaction between channels is present\n",
    "        outputs = pad_same_from_kernel_size(outputs, kernel_size=config.CS_KERNEL_SIZE, mode=\"symmetric\")\n",
    "        outputs = CenterSurroundLogSigmaK(features=3, kernel_size=config.CS_KERNEL_SIZE, fs=21, use_bias=False, padding=\"VALID\")(outputs, **kwargs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "\n",
    "        ## GDN per channel with mean substraction in T and D (Spatial Gaussian Kernel)\n",
    "        ### fs = 32 / kernel_size = (11,11) -> 0.32 > 0.02 --> OK!\n",
    "        ## TO-DO: - Spatial Gaussian Kernel (0.02 deg) -> fs = 64/2 & 0.02*64/2 = sigma (px) = 0.69\n",
    "        outputs = GDNGaussian(kernel_size=config.GDNGAUSSIAN_KERNEL_SIZE, apply_independently=True, fs=32, padding=\"symmetric\", normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY)(outputs, **kwargs)\n",
    "\n",
    "        ## GaborLayer per channel with GDN mixing only same-origin-channel information\n",
    "        ### [Gaussian] sigma = 0.2 (deg) fs = 32 / kernel_size = (21,21) -> 21/32 = 0.66 --> OK!\n",
    "        outputs = pad_same_from_kernel_size(outputs, kernel_size=config.GABOR_KERNEL_SIZE, mode=\"symmetric\")\n",
    "        # outputs, fmean, theta_mean = GaborLayerGamma_(n_scales=4+2+2, n_orientations=8*3, kernel_size=config.GABOR_KERNEL_SIZE, fs=32, xmean=config.GABOR_KERNEL_SIZE/32/2, ymean=config.GABOR_KERNEL_SIZE/32/2, strides=1, padding=\"VALID\", normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY, zero_mean=config.ZERO_MEAN, use_bias=config.USE_BIAS, train_A=config.A_GABOR)(outputs, return_freq=True, return_theta=True, **kwargs)\n",
    "        outputs, fmean, theta_mean = GaborLayerGammaHumanLike_(n_scales=[4,2,2], n_orientations=[8,8,8], kernel_size=config.GABOR_KERNEL_SIZE, fs=32, xmean=config.GABOR_KERNEL_SIZE/32/2, ymean=config.GABOR_KERNEL_SIZE/32/2, strides=1, padding=\"VALID\", normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY, zero_mean=config.ZERO_MEAN, use_bias=config.USE_BIAS, train_A=config.A_GABOR)(outputs, return_freq=True, return_theta=True, **kwargs)\n",
    "        \n",
    "        ## Final GDN mixing Gabor information (?)\n",
    "        outputs = GDNSpatioChromaFreqOrient(kernel_size=21, strides=1, padding=\"symmetric\", fs=32, apply_independently=False)(outputs, fmean=fmean, theta_mean=theta_mean, **kwargs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNetBaseline(nn.Module):\n",
    "    \"\"\"IQA model inspired by the visual system.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=True)(inputs)\n",
    "        outputs = nn.Conv(features=3, kernel_size=(1,1), strides=1, padding=\"SAME\")(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        outputs = nn.Conv(features=6, kernel_size=(config.CS_KERNEL_SIZE,config.CS_KERNEL_SIZE), strides=1, padding=\"SAME\")(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = GDN(kernel_size=config.GDNGAUSSIAN_KERNEL_SIZE, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        outputs = nn.Conv(features=config.N_GABORS, kernel_size=(config.GABOR_KERNEL_SIZE,config.GABOR_KERNEL_SIZE), strides=1, padding=\"SAME\")(outputs)\n",
    "        outputs = GDN(kernel_size=config.GDNSPATIOFREQ_KERNEL_SIZE, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the metrics with `clu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    \"\"\"Collection of metrics to be tracked during training.\"\"\"\n",
    "    loss: metrics.Average.from_output(\"loss\")\n",
    "    correlation_l: metrics.Average.from_output(\"correlation_l\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `TrainState` doesn't include metrics, but it's very easy to subclass it so that it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "    state: FrozenDict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a function that initializes the `TrainState` from a module, a rng key and some optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, key, tx, input_shape):\n",
    "    \"\"\"Creates the initial `TrainState`.\"\"\"\n",
    "    variables = module.init(key, jnp.ones(input_shape))\n",
    "    state, params = variables.pop('params')\n",
    "    return TrainState.create(\n",
    "        apply_fn=module.apply,\n",
    "        params=params,\n",
    "        state=state,\n",
    "        tx=tx,\n",
    "        metrics=Metrics.empty()\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the training step\n",
    "\n",
    "> We want to write a function that takes the `TrainState` and a batch of data can performs an optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation(vec1, vec2):\n",
    "    vec1 = vec1.squeeze()\n",
    "    vec2 = vec2.squeeze()\n",
    "    vec1_mean = vec1.mean()\n",
    "    vec2_mean = vec2.mean()\n",
    "    num = vec1-vec1_mean\n",
    "    num *= vec2-vec2_mean\n",
    "    num = num.sum()\n",
    "    denom = jnp.sqrt(jnp.sum((vec1-vec1_mean)**2))\n",
    "    denom *= jnp.sqrt(jnp.sum((vec2-vec2_mean)**2))\n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnums=3)\n",
    "def train_step(state, state_t, batch, return_grads=False):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    img, img_dist, mos = batch\n",
    "    def loss_fn(params):\n",
    "        ## Forward pass through the teacher model\n",
    "        img_pred_t = state_t.apply_fn({\"params\": state_t.params, **state_t.state}, img)\n",
    "        img_dist_pred_t = state_t.apply_fn({\"params\": state_t.params, **state_t.state}, img_dist)\n",
    "\n",
    "        ## Forward pass through the learner model\n",
    "        img_pred = state.apply_fn({\"params\": params, **state.state}, img)\n",
    "        img_dist_pred = state.apply_fn({\"params\": params, **state.state}, img_dist)\n",
    "\n",
    "        dist_l = ((img_pred - img_dist_pred)**2).sum(axis=(1,2,3))**(1/2)\n",
    "        dist_t = ((img_pred_t - img_dist_pred_t)**2).sum(axis=(1,2,3))**(1/2)\n",
    "\n",
    "        ## Optimize so that the correlations are the same\n",
    "        correlation_l = pearson_correlation(dist_l, mos)\n",
    "        correlation_t = pearson_correlation(dist_t, mos)\n",
    "        loss = jnp.abs(jnp.abs(correlation_l) - jnp.abs(correlation_t))\n",
    "\n",
    "        ## Return the distillation loss and the correlation of the learner\n",
    "        return loss, correlation_l\n",
    "    \n",
    "    (loss, correlation_l), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics_updates = state.metrics.single_from_model_output(loss=loss, correlation_l=correlation_l)\n",
    "    metrics = state.metrics.merge(metrics_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    if return_grads: return state, grads\n",
    "    else: return state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In their example, they don't calculate the metrics at the same time. I think it is kind of a waste because it means having to perform a new forward pass, but we'll follow as of now. Let's define a function to perform metric calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_metrics(*, state, state_t, batch):\n",
    "    \"\"\"Obtaining the metrics for a given batch.\"\"\"\n",
    "    img, img_dist, mos = batch\n",
    "    def loss_fn(params):\n",
    "        ## Forward pass through the teacher model\n",
    "        img_pred_t = state_t.apply_fn({\"params\": state_t.params, **state_t.state}, img)\n",
    "        img_dist_pred_t = state_t.apply_fn({\"params\": state_t.params, **state_t.state}, img_dist)\n",
    "\n",
    "        ## Forward pass through the learner model\n",
    "        img_pred = state.apply_fn({\"params\": params, **state.state}, img)\n",
    "        img_dist_pred = state.apply_fn({\"params\": params, **state.state}, img_dist)\n",
    "\n",
    "        ## Calculate the distance\n",
    "        dist_img = ((img_pred_t - img_pred)**2).sum(axis=(1,2,3))**(1/2)\n",
    "        dist_img_dist = ((img_dist_pred_t - img_dist_pred)**2).sum(axis=(1,2,3))**(1/2)\n",
    "\n",
    "        ## Optimize so that the distances are the same as the parametric model\n",
    "        loss = (dist_img.mean() + dist_img_dist.mean()).mean()\n",
    "\n",
    "        dist_l = ((img_pred - img_dist_pred)**2).sum(axis=(1,2,3))**(1/2)\n",
    "\n",
    "        ## Return the distillation loss and the correlation of the learner\n",
    "        return loss, pearson_correlation(dist_l, mos)\n",
    "    loss, correlation_l = loss_fn(state.params) \n",
    "    metrics_updates = state.metrics.single_from_model_output(loss=loss, correlation_l=correlation_l)\n",
    "    metrics = state.metrics.merge(metrics_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(PerceptNet(), random.PRNGKey(config.SEED), optax.adam(config.LEARNER_LR), input_shape=(1,384,512,3))\n",
    "state = state.replace(params=clip_layer(state.params, \"GDN\", a_min=0))\n",
    "state = state.replace(params=clip_param(state.params, \"A\", a_min=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozen_dict_keys(['GDNGamma_0', 'Color', 'GDN_0', 'CenterSurroundLogSigmaK_0', 'GDNGaussian_0', 'GaborLayerGammaHumanLike__0', 'GDNSpatioChromaFreqOrient_0'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, _ = state.apply_fn({\"params\": state.params, **state.state}, jnp.ones(shape=(1,384,512,3)), train=True, mutable=list(state.state.keys()))\n",
    "state = state.replace(state=_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trainable(path):\n",
    "    if not config.A_GDNSPATIOFREQORIENT:\n",
    "        if (\"GDNSpatioChromaFreqOrient_0\" in path) and (\"A\" in path):\n",
    "            return True\n",
    "    if \"Color\" in path:\n",
    "        if not config.TRAIN_JH:\n",
    "            return True\n",
    "    if \"CenterSurroundLogSigmaK_0\" in path:\n",
    "        if not config.TRAIN_CS:\n",
    "            return True\n",
    "    if \"Gabor\" in \"\".join(path):\n",
    "        if not config.TRAIN_GABOR:\n",
    "            return True\n",
    "    if \"GDNSpatioChromaFreqOrient_0\" not in path and config.TRAIN_ONLY_LAST_GDN:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    GDNGamma_0: {\n",
       "        kernel: 'non_trainable',\n",
       "        bias: 'non_trainable',\n",
       "    },\n",
       "    Color: {\n",
       "        kernel: 'non_trainable',\n",
       "    },\n",
       "    GDN_0: {\n",
       "        Conv_0: {\n",
       "            kernel: 'non_trainable',\n",
       "            bias: 'non_trainable',\n",
       "        },\n",
       "    },\n",
       "    CenterSurroundLogSigmaK_0: {\n",
       "        logsigma: 'non_trainable',\n",
       "        K: 'non_trainable',\n",
       "        A: 'non_trainable',\n",
       "    },\n",
       "    GDNGaussian_0: {\n",
       "        GaussianLayerGamma_0: {\n",
       "            gamma: 'non_trainable',\n",
       "            A: 'non_trainable',\n",
       "            bias: 'non_trainable',\n",
       "        },\n",
       "    },\n",
       "    GaborLayerGammaHumanLike__0: {\n",
       "        freq_a: 'non_trainable',\n",
       "        gammax_a: 'non_trainable',\n",
       "        gammay_a: 'non_trainable',\n",
       "        theta_a: 'non_trainable',\n",
       "        sigma_theta_a: 'non_trainable',\n",
       "        freq_t: 'non_trainable',\n",
       "        gammax_t: 'non_trainable',\n",
       "        gammay_t: 'non_trainable',\n",
       "        theta_t: 'non_trainable',\n",
       "        sigma_theta_t: 'non_trainable',\n",
       "        freq_d: 'non_trainable',\n",
       "        gammax_d: 'non_trainable',\n",
       "        gammay_d: 'non_trainable',\n",
       "        theta_d: 'non_trainable',\n",
       "        sigma_theta_d: 'non_trainable',\n",
       "        A: 'non_trainable',\n",
       "    },\n",
       "    GDNSpatioChromaFreqOrient_0: {\n",
       "        bias: 'non_trainable',\n",
       "        GaussianLayerGamma_0: {\n",
       "            gamma: 'non_trainable',\n",
       "            A: 'non_trainable',\n",
       "        },\n",
       "        ChromaFreqOrientGaussianGamma_0: {\n",
       "            gamma_f_a: 'non_trainable',\n",
       "            gamma_theta_a: 'non_trainable',\n",
       "            gamma_f_t: 'non_trainable',\n",
       "            gamma_theta_t: 'non_trainable',\n",
       "            gamma_f_d: 'non_trainable',\n",
       "            gamma_theta_d: 'non_trainable',\n",
       "            H_cc: 'non_trainable',\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainable_tree = freeze(flax.traverse_util.path_aware_map(lambda path, v: \"non_trainable\" if check_trainable(path)  else \"trainable\", state.params))\n",
    "trainable_tree = freeze(flax.traverse_util.path_aware_map(lambda path, v: \"non_trainable\", state.params))\n",
    "trainable_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    \"trainable\": optax.adam(learning_rate=3e-3),\n",
    "    \"non_trainable\": optax.set_to_zero(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = optax.multi_transform(optimizers, trainable_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_t = create_train_state(PerceptNet(), random.PRNGKey(config.SEED), tx, input_shape=(1,384,512,3))\n",
    "state_t = state_t.replace(params=clip_layer(state_t.params, \"GDN\", a_min=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_count = sum(x.size for x in jax.tree_util.tree_leaves(state.params))\n",
    "# trainable_param_count = sum([w.size if t==\"trainable\" else 0 for w, t in zip(jax.tree_util.tree_leaves(state.params), jax.tree_util.tree_leaves(trainable_tree))])\n",
    "# param_count, trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.run.summary[\"total_parameters\"] = param_count\n",
    "# wandb.run.summary[\"trainable_parameters\"] = trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_t = state_t.replace(params=unfreeze(state_t.params))\n",
    "\n",
    "# ## DN 0 (Gamma)\n",
    "if config.USE_GAMMA:\n",
    "    state_t.params[\"GDNGamma_0\"][\"bias\"] = jnp.ones_like(state_t.params[\"GDNGamma_0\"][\"bias\"])*0.1\n",
    "    state_t.params[\"GDNGamma_0\"][\"kernel\"] = jnp.ones_like(state_t.params[\"GDNGamma_0\"][\"kernel\"])*0.5\n",
    "else:\n",
    "    state_t.params[\"GDN_0\"][\"Conv_0\"][\"bias\"] = jnp.ones_like(state_t.params[\"GDN_0\"][\"Conv_0\"][\"bias\"])*0.1\n",
    "    state_t.params[\"GDN_0\"][\"Conv_0\"][\"kernel\"] = jnp.ones_like(state_t.params[\"GDN_0\"][\"Conv_0\"][\"kernel\"])*0.5\n",
    "\n",
    "## Opponent color channel transformation\n",
    "if config.INIT_JH:\n",
    "    state_t.params[\"Color\"][\"kernel\"] = jnp.array([[39.0454,30.1207,14.27948],\n",
    "                                                  [115.8404,-63.3502,41.26816],\n",
    "                                                  [16.3118,30.2934,-61.51888]])[None,None,:,:]/163.5217\n",
    "\n",
    "## Center Surround\n",
    "state_t.params[\"CenterSurroundLogSigmaK_0\"][\"logsigma\"] = jnp.array([-1.9,-1.9,-1.9,\n",
    "                                                                   -1.76,-1.76,-1.76,\n",
    "                                                                   -1.76,-1.76,-1.76])\n",
    "state_t.params[\"CenterSurroundLogSigmaK_0\"][\"K\"] = jnp.array([1.1,1.1,1.1,\n",
    "                                                            5.0,5.0,5.0,\n",
    "                                                            5.0,5.0,5.0])\n",
    "state_t.params[\"CenterSurroundLogSigmaK_0\"][\"A\"] = jnp.array([1.,0.,0.,\n",
    "                                                            0.,1.,0.,\n",
    "                                                            0.,0.,1.])\n",
    "\n",
    "## GDNGaussian\n",
    "state_t.params[\"GDNGaussian_0\"][\"GaussianLayerGamma_0\"][\"gamma\"] = jnp.ones_like(state_t.params[\"GDNGaussian_0\"][\"GaussianLayerGamma_0\"][\"gamma\"])*(1./0.04)\n",
    "state_t.params[\"GDNGaussian_0\"][\"GaussianLayerGamma_0\"][\"bias\"] = jnp.ones_like(state_t.params[\"GDNGaussian_0\"][\"GaussianLayerGamma_0\"][\"bias\"])*0.1\n",
    "\n",
    "## Gabor\n",
    "if config.INIT_GABOR:\n",
    "    state_t.params[\"GaborLayerGammaHumanLike__0\"][\"freq_a\"] = jnp.array([2.,4.,8.,16.]) \n",
    "    state_t.params[\"GaborLayerGammaHumanLike__0\"][\"freq_t\"] = jnp.array([3.,6.]) \n",
    "    state_t.params[\"GaborLayerGammaHumanLike__0\"][\"freq_d\"] = jnp.array([3.,6.])\n",
    "\n",
    "    state_t.params[\"GaborLayerGammaHumanLike__0\"][\"gammax_a\"] = state_t.params[\"GaborLayerGammaHumanLike__0\"][\"freq_a\"]**0.9\n",
    "    state_t.params[\"GaborLayerGammaHumanLike__0\"][\"gammay_a\"] = 0.8*state_t.params[\"GaborLayerGammaHumanLike__0\"][\"gammax_a\"]\n",
    "\n",
    "    state_t.params[\"GaborLayerGammaHumanLike__0\"][\"gammax_t\"] = state_t.params[\"GaborLayerGammaHumanLike__0\"][\"freq_t\"]**0.9\n",
    "    state_t.params[\"GaborLayerGammaHumanLike__0\"][\"gammay_t\"] = 0.8*state_t.params[\"GaborLayerGammaHumanLike__0\"][\"gammax_t\"]\n",
    "\n",
    "    state_t.params[\"GaborLayerGammaHumanLike__0\"][\"gammax_d\"] = state_t.params[\"GaborLayerGammaHumanLike__0\"][\"freq_d\"]**0.9\n",
    "    state_t.params[\"GaborLayerGammaHumanLike__0\"][\"gammay_d\"] = 0.8*state_t.params[\"GaborLayerGammaHumanLike__0\"][\"gammax_d\"]\n",
    "    # state_t.params[\"GaborLayerGammaHumanLike__0\"][\"theta_a\"] = jnp.tile(jnp.linspace(0., jnp.pi, num=16), reps=128//16)\n",
    "    # state_t.params[\"GaborLayerGammaHumanLike__0\"][\"sigma_theta_a\"] = state_t.params[\"GaborLayerGammaHumanLike__0\"][\"theta_a\"]\n",
    "    # state_t.params[\"GaborLayerGammaHumanLike__0\"][\"phase_a\"] = jnp.repeat(jnp.array([0., 90.]), repeats=64)    \n",
    "\n",
    "    A_a = jnp.zeros(shape=(3,64), dtype=jnp.float32)\n",
    "    A_a = A_a.at[0,:].set(1.)\n",
    "    A_t = jnp.zeros(shape=(3,32), dtype=jnp.float32)\n",
    "    A_t = A_t.at[1,:].set(1.)\n",
    "    A_d = jnp.zeros(shape=(3,32), dtype=jnp.float32)\n",
    "    A_d = A_d.at[2,:].set(1.)\n",
    "    state_t.params[\"GaborLayerGammaHumanLike__0\"][\"A\"] = jnp.concatenate([A_a, A_t, A_d], axis=-1)\n",
    "\n",
    "## GDNSpatioChromaFreqOrient\n",
    "# state_t.params[\"GDNSpatioChromaFreqOrient_0\"][\"GaussianLayerGamma_0\"][\"gamma\"] = jnp.ones_like(state_t.params[\"GDNSpatioChromaFreqOrient_0\"][\"GaussianLayerGamma_0\"][\"gamma\"])*(1./0.1)\n",
    "# state_t.params[\"GDNSpatioChromaFreqOrient_0\"][\"OrientGaussianGamma_0\"][\"gamma\"] = jnp.ones_like(state_t.params[\"GDNSpatioChromaFreqOrient_0\"][\"OrientGaussianGamma_0\"][\"gamma\"])*(1/20)\n",
    "# state_t.params[\"GDNSpatioChromaFreqOrient_0\"][\"bias\"] = jnp.tile(jnp.array([0.001, 0.002, 0.0035, 0.01])/100, reps=config.N_ORIENTATIONS*2)\n",
    "state_t.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"H_cc\"] = jnp.eye(3,3)\n",
    "state_t.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"gamma_theta_a\"] = jnp.ones_like(state_t.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"gamma_theta_a\"])*(1/20)\n",
    "state_t.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"gamma_theta_t\"] = jnp.ones_like(state_t.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"gamma_theta_t\"])*(1/20)\n",
    "state_t.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"gamma_theta_d\"] = jnp.ones_like(state_t.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"gamma_theta_d\"])*(1/20)\n",
    "\n",
    "\n",
    "state_t = state_t.replace(params=freeze(state_t.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, _ = state_t.apply_fn({\"params\": state_t.params, **state_t.state}, jnp.ones(shape=(1,384,512,3)), train=True, mutable=list(state_t.state.keys()))\n",
    "state_t = state_t.replace(state=_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_vars = {\"params\": state_t.params, **state_t.state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = optax.adam(learning_rate=config.LEARNER_LR)\n",
    "state = create_train_state(PerceptNetBaseline(), random.PRNGKey(config.SEED), tx, input_shape=(1,384,512,3))\n",
    "state = state.replace(params=clip_layer(state.params, \"GDN\", a_min=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before actually training the model we're going to set up the checkpointer to be able to save our trained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbax_checkpointer.save(os.path.join(wandb.run.dir, \"model-0\"), state, save_args=save_args, force=True) # force=True means allow overwritting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_correlation_l\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_correlation_l\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "batch = next(iter(dst_train_rdy.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def forward(state, inputs):\n",
    "    return state.apply_fn({\"params\": state.params, **state.state}, inputs, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def forward_intermediates(state, inputs):\n",
    "    return state.apply_fn({\"params\": state.params, **state.state}, inputs, train=False, capture_intermediates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs = forward(state, batch[0])\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "%%time\n",
    "s1, grads = train_step(state, state_t, batch, return_grads=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jax.config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_extra(extra):\n",
    "    def filter_intermediates(path, x):\n",
    "        path = \"/\".join(path)\n",
    "        if \"Gabor\" in path:\n",
    "            return (x[0][0],)\n",
    "        else: \n",
    "            return x\n",
    "    extra = unfreeze(extra)\n",
    "    extra[\"intermediates\"] = flax.traverse_util.path_aware_map(filter_intermediates, extra[\"intermediates\"])\n",
    "    return freeze(extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'dst_train_rdy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dst_train_rdy' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "step = 0\n",
    "for epoch in range(config.EPOCHS):\n",
    "    ## Training\n",
    "    for batch in dst_train_rdy.as_numpy_iterator():\n",
    "        state, grads = train_step(state, state_t, batch, return_grads=True)\n",
    "        state = state.replace(params=clip_layer(state.params, \"GDN\", a_min=0))\n",
    "        state = state.replace(params=clip_param(state.params, \"A\", a_min=0))\n",
    "        state = state.replace(params=clip_param(state.params, \"K\", a_min=1+1e-5))\n",
    "        wandb.log({f\"{k}_grad\": wandb.Histogram(v) for k, v in flatten_params(grads).items()}, commit=False)\n",
    "        step += 1\n",
    "        # state = compute_metrics(state=state, batch=batch)\n",
    "        # break\n",
    "\n",
    "    ## Log the metrics\n",
    "    for name, value in state.metrics.compute().items():\n",
    "        metrics_history[f\"train_{name}\"].append(value)\n",
    "    \n",
    "    ## Empty the metrics\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "\n",
    "    ## Evaluation\n",
    "    for batch in dst_val_rdy.as_numpy_iterator():\n",
    "        state = compute_metrics(state=state, state_t=state_t, batch=batch)\n",
    "        # break\n",
    "    for name, value in state.metrics.compute().items():\n",
    "        metrics_history[f\"val_{name}\"].append(value)\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "    \n",
    "    ## Obtain activations of last validation batch\n",
    "    _, extra = forward_intermediates(state, batch[0])\n",
    "    extra = filter_extra(extra) ## Needed because the Gabor layer has multiple outputs\n",
    "    \n",
    "    ## Checkpointing\n",
    "    if metrics_history[\"val_loss\"][-1] <= min(metrics_history[\"val_loss\"]):\n",
    "        orbax_checkpointer.save(os.path.join(wandb.run.dir, \"model-best\"), state, save_args=save_args, force=True) # force=True means allow overwritting.\n",
    "    # orbax_checkpointer.save(os.path.join(wandb.run.dir, f\"model-{epoch+1}\"), state, save_args=save_args, force=False) # force=True means allow overwritting.\n",
    "\n",
    "    wandb.log({f\"{k}\": wandb.Histogram(v) for k, v in flatten_params(state.params).items()}, commit=False)\n",
    "    wandb.log({f\"{k}\": wandb.Histogram(v) for k, v in flatten_params(extra[\"intermediates\"]).items()}, commit=False)\n",
    "    # wandb.log({\"epoch\": epoch+1, \"learning_rate\": schedule_lr(step), **{name:values[-1] for name, values in metrics_history.items()}})\n",
    "    wandb.log({\"epoch\": epoch+1, **{name:values[-1] for name, values in metrics_history.items()}})\n",
    "    print(f'Epoch {epoch} -> [Train] Loss: {metrics_history[\"train_loss\"][-1]} [Val] Loss: {metrics_history[\"val_loss\"][-1]}')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the final model as well in case we want to keep training from it or whatever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbax_checkpointer.save(os.path.join(wandb.run.dir, \"model-final\"), state, save_args=save_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa251b27e61431187926b7b3f7c44fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 62.568 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=8.41669…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">FinalModel_to_Baseline_Correlation</strong> at: <a href='https://wandb.ai/jorgvt/ParametricKnowledgeDistillation/runs/lnvkxmdh' target=\"_blank\">https://wandb.ai/jorgvt/ParametricKnowledgeDistillation/runs/lnvkxmdh</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240708_173752-lnvkxmdh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
