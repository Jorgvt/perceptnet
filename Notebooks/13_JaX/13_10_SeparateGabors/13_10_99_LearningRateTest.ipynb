{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IQA tracking params and variables\n",
    "\n",
    "> When using parametric layers we have to be able to keep track of the parameters and the variables of the model (which are not going to be trained). We're going to play with this concept using our implementation of the functional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os; os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\".99\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 11:59:43.939062: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-27 11:59:47.852284: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-06-27 12:00:01.647246: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:1: failed initializing StreamExecutor for CUDA device ordinal 1: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "2024-06-27 12:00:01.647283: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "from typing import Any, Callable, Sequence, Union\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "import jax\n",
    "from jax import lax, random, numpy as jnp\n",
    "import flax\n",
    "from flax.core import freeze, unfreeze, FrozenDict\n",
    "from flax import linen as nn\n",
    "from flax import struct\n",
    "from flax.training import train_state\n",
    "from flax.training import orbax_utils\n",
    "\n",
    "import optax\n",
    "import orbax.checkpoint\n",
    "\n",
    "from clu import metrics\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "from einops import reduce, rearrange, repeat\n",
    "import wandb\n",
    "from iqadatasets.datasets import *\n",
    "from fxlayers.layers import *\n",
    "from fxlayers.layers import GaussianLayerGamma, FreqGaussianGamma, OrientGaussianGamma, GaborLayerGamma_, GaborLayerGammaRepeat\n",
    "from fxlayers.initializers import *\n",
    "from JaxPlayground.utils.constraints import *\n",
    "from JaxPlayground.utils.wandb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jax.config.update(\"jax_debug_nans\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "> We're going to employ `iqadatasets` to ease the loading of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train = TID2008(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2008/\", exclude_imgs=[25])\n",
    "# dst_train = KADIK10K(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/KADIK10K/\")\n",
    "dst_val = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2013/\", exclude_imgs=[25])\n",
    "# dst_train = TID2008(\"/media/disk/databases/BBDD_video_image/Image_Quality//TID/TID2008/\", exclude_imgs=[25])\n",
    "# dst_val = TID2013(\"/media/disk/databases/BBDD_video_image/Image_Quality//TID/TID2013/\", exclude_imgs=[25])\n",
    "# dst_train = TID2008(\"/media/databases/IQA/TID/TID2008/\", exclude_imgs=[25])\n",
    "# dst_val = TID2013(\"/media/databases/IQA/TID/TID2013/\", exclude_imgs=[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 12:00:02.753537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype double and shape [1632]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([384, 512, 3]), TensorShape([384, 512, 3]), TensorShape([]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, img_dist, mos = next(iter(dst_train.dataset))\n",
    "img.shape, img_dist.shape, mos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 12:00:03.062481: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype double and shape [2880]\n",
      "\t [[{{node Placeholder/_2}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([384, 512, 3]), TensorShape([384, 512, 3]), TensorShape([]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, img_dist, mos = next(iter(dst_val.dataset))\n",
    "img.shape, img_dist.shape, mos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A_GABOR: false\n",
       "A_GDNSPATIOFREQORIENT: false\n",
       "BATCH_SIZE: 64\n",
       "CS_KERNEL_SIZE: 21\n",
       "EPOCHS: 500\n",
       "GABOR_KERNEL_SIZE: 31\n",
       "GDNGAUSSIAN_KERNEL_SIZE: 11\n",
       "GDN_CLIPPING: true\n",
       "INIT_GABOR: true\n",
       "INIT_JH: true\n",
       "LEARNING_RATE: 0.003\n",
       "NORMALIZE_ENERGY: true\n",
       "NORMALIZE_PROB: false\n",
       "N_ORIENTATIONS: 16\n",
       "N_SCALES: 4\n",
       "SEED: 42\n",
       "TRAIN_CS: false\n",
       "TRAIN_GABOR: false\n",
       "TRAIN_JH: false\n",
       "TRAIN_ONLY_LAST_GDN: true\n",
       "USE_BIAS: false\n",
       "USE_GAMMA: true\n",
       "ZERO_MEAN: true"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"EPOCHS\": 500,\n",
    "    \"LEARNING_RATE\": 3e-3,\n",
    "    \"SEED\": 42,\n",
    "    \"GDN_CLIPPING\": True,\n",
    "    \"NORMALIZE_PROB\": False,\n",
    "    \"NORMALIZE_ENERGY\": True,\n",
    "    \"ZERO_MEAN\": True,\n",
    "    \"USE_BIAS\": False,\n",
    "    \"CS_KERNEL_SIZE\": 21,\n",
    "    \"GDNGAUSSIAN_KERNEL_SIZE\": 11,\n",
    "    \"GABOR_KERNEL_SIZE\": 31,\n",
    "    \"N_SCALES\": 4,\n",
    "    \"N_ORIENTATIONS\": 16,\n",
    "    # \"N_GABORS\": 128,\n",
    "    \"USE_GAMMA\": True,\n",
    "    \"INIT_JH\": True,\n",
    "    \"INIT_GABOR\": True,\n",
    "    \"TRAIN_JH\": False,\n",
    "    \"TRAIN_CS\": False,\n",
    "    \"TRAIN_GABOR\": False,\n",
    "    \"A_GABOR\": False,\n",
    "    \"A_GDNSPATIOFREQORIENT\": False,\n",
    "    \"TRAIN_ONLY_LAST_GDN\": True,\n",
    "}\n",
    "config = ConfigDict(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "A_GABOR: false\n",
       "A_GDNSPATIOFREQORIENT: false\n",
       "BATCH_SIZE: 64\n",
       "CS_KERNEL_SIZE: 21\n",
       "EPOCHS: 500\n",
       "GABOR_KERNEL_SIZE: 31\n",
       "GDNGAUSSIAN_KERNEL_SIZE: 11\n",
       "GDN_CLIPPING: true\n",
       "INIT_GABOR: true\n",
       "INIT_JH: true\n",
       "LEARNING_RATE: 0.003\n",
       "NORMALIZE_ENERGY: true\n",
       "NORMALIZE_PROB: false\n",
       "N_ORIENTATIONS: 16\n",
       "N_SCALES: 4\n",
       "SEED: 42\n",
       "TRAIN_CS: false\n",
       "TRAIN_GABOR: false\n",
       "TRAIN_JH: false\n",
       "TRAIN_ONLY_LAST_GDN: true\n",
       "USE_BIAS: false\n",
       "USE_GAMMA: true\n",
       "ZERO_MEAN: true"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"PerceptNet_v15\",\n",
    "           name=\"FinalModel_OnlyLast\",\n",
    "           job_type=\"training\",\n",
    "           config=config,\n",
    "           mode=\"disabled\",\n",
    "           )\n",
    "config = config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train_rdy = dst_train.dataset.shuffle(buffer_size=100,\n",
    "                                      reshuffle_each_iteration=True,\n",
    "                                      seed=config.SEED)\\\n",
    "                                 .batch(config.BATCH_SIZE, drop_remainder=True)\n",
    "dst_val_rdy = dst_val.dataset.batch(config.BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model we're going to use\n",
    "\n",
    "> It's going to be a very simple model just for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class ChromaFreqOrientGaussianGamma(nn.Module):\n",
    "    \"\"\"(1D) Gaussian interaction between gamma_fuencies and orientations optimizing gamma = 1/sigma instead of sigma.\"\"\"\n",
    "    use_bias: bool = False\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    bias_init: Callable = nn.initializers.zeros_init()\n",
    "    n_scales: Sequence[int] = jnp.array([4, 2, 2], dtype=jnp.int32)\n",
    "    n_orientations: Sequence[int] = jnp.array([8, 8, 8], dtype=jnp.int32)\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 fmean,\n",
    "                 theta_mean,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "\n",
    "        gamma_f_a = self.param(\"gamma_f_a\",\n",
    "                             k_array(1/0.4, arr=jnp.array([2.,4.,8.,16.])),\n",
    "                             (self.n_scales[0],))\n",
    "        gamma_theta_a = self.param(\"gamma_theta_a\",\n",
    "                                 nn.initializers.ones_init(),\n",
    "                                #  (self.n_orientations[0],))\n",
    "                                 (8,))\n",
    "\n",
    "        gamma_f_t = self.param(\"gamma_f_t\",\n",
    "                             k_array(1/0.4, arr=jnp.array([3.,6.])),\n",
    "                             (self.n_scales[1],))\n",
    "        gamma_theta_t = self.param(\"gamma_theta_t\",\n",
    "                                 nn.initializers.ones_init(),\n",
    "                                #  (self.n_orientations[1],))\n",
    "                                 (8,))\n",
    "        \n",
    "        gamma_f_d = self.param(\"gamma_f_d\",\n",
    "                             k_array(1/0.4, arr=jnp.array([3.,6.])),\n",
    "                             (self.n_scales[2],))\n",
    "        gamma_theta_d = self.param(\"gamma_theta_d\",\n",
    "                                 nn.initializers.ones_init(),\n",
    "                                #  (self.n_orientations[2],))\n",
    "                                 (8,))\n",
    "\n",
    "        H_cc = self.param(\"H_cc\",\n",
    "                          nn.initializers.ones_init(),\n",
    "                          (3,3))\n",
    "\n",
    "        if self.use_bias: bias = self.param(\"bias\",\n",
    "                                            self.bias_init,\n",
    "                                            (len(fmean),))\n",
    "        else: bias = 0.\n",
    "        # n_groups = inputs.shape[-1] // len(fmean)\n",
    "\n",
    "        ## Repeat gammas\n",
    "        gamma_f = jnp.concatenate([jnp.tile(f, reps=len(t)) for f,t in zip([gamma_f_a, gamma_f_t, gamma_f_d], [gamma_theta_a, gamma_theta_t, gamma_theta_d])])\n",
    "        gamma_f = jnp.tile(gamma_f, reps=2)\n",
    "        gamma_theta = jnp.concatenate([jnp.tile(t, reps=len(f)) for f,t in zip([gamma_f_a, gamma_f_t, gamma_f_d], [gamma_theta_a, gamma_theta_t, gamma_theta_d])])\n",
    "        gamma_theta = jnp.tile(gamma_theta, reps=2)\n",
    "\n",
    "        ## Repeating\n",
    "        cc = jnp.array([0,1,2])\n",
    "        cc = jnp.repeat(cc, repeats=jnp.array([64,32,32]), total_repeat_length=len(fmean))\n",
    "\n",
    "        kernel = jax.vmap(self.gaussian, in_axes=(None,None,0,0,0,0,None,0,None,None), out_axes=1)(fmean, theta_mean, fmean, theta_mean, gamma_f, gamma_theta, cc, cc, H_cc, 1)\n",
    "        kernel = kernel[None,None,:,:]\n",
    "\n",
    "        ## Add the batch dim if the input is a single element\n",
    "        if jnp.ndim(inputs) < 4: inputs = inputs[None,:]; had_batch = False\n",
    "        else: had_batch = True\n",
    "        outputs = lax.conv_general_dilated(\n",
    "                jnp.transpose(inputs,[0,3,1,2]),    # lhs = NCHW image tensor\n",
    "                jnp.transpose(kernel,[3,2,0,1]), # rhs = OIHW conv kernel tensor\n",
    "                (self.strides, self.strides),\n",
    "                self.padding)\n",
    "        ## Move the channels back to the last dim\n",
    "        outputs = jnp.transpose(outputs, (0,2,3,1))\n",
    "        if not had_batch: outputs = outputs[0]\n",
    "        return outputs + bias\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian(f, theta, fmean, theta_mean, gamma_f, gamma_theta, c_1, c_2, H_cc, A=1):\n",
    "        return H_cc[c_1,c_2]*A*jnp.exp(-((gamma_f**2)*(f-fmean)**2)/(2))*jnp.exp(-((gamma_theta**2)*(theta-theta_mean)**2)/(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDNSpatioChromaFreqOrient(nn.Module):\n",
    "    \"\"\"Generalized Divisive Normalization.\"\"\"\n",
    "    kernel_size: Union[int, Sequence[int]]\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    # inputs_star: float = 1.\n",
    "    # outputs_star: Union[None, float] = None\n",
    "    fs: int = 1\n",
    "    apply_independently: bool = False\n",
    "    bias_init: Callable = nn.initializers.ones_init()\n",
    "    alpha: float = 2.\n",
    "    epsilon: float = 1/2 # Exponential of the denominator\n",
    "    eps: float = 1e-6 # Numerical stability in the denominator\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 fmean,\n",
    "                 theta_mean,\n",
    "                 train=False,\n",
    "                 ):\n",
    "        b, h, w, c = inputs.shape\n",
    "        bias = self.param(\"bias\",\n",
    "                          #equal_to(inputs_star/10),\n",
    "                          self.bias_init,\n",
    "                          (c,))\n",
    "        # is_initialized = self.has_variable(\"batch_stats\", \"inputs_star\")\n",
    "        # inputs_star = self.variable(\"batch_stats\", \"inputs_star\", lambda x: jnp.ones(x)*self.inputs_star, (len(self.inputs_star),))\n",
    "        # inputs_star_ = jnp.ones_like(inputs)*inputs_star.value\n",
    "        GL = GaussianLayerGamma(features=c, kernel_size=self.kernel_size, strides=self.strides, padding=\"VALID\", fs=self.fs, xmean=self.kernel_size/self.fs/2, ymean=self.kernel_size/self.fs/2, normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY, use_bias=False, feature_group_count=c)\n",
    "        FOG = ChromaFreqOrientGaussianGamma()\n",
    "        outputs = GL(pad_same_from_kernel_size(inputs, kernel_size=self.kernel_size, mode=self.padding)**self.alpha, train=train)#/(self.kernel_size**2)\n",
    "        outputs = FOG(outputs, fmean=fmean, theta_mean=theta_mean)\n",
    "\n",
    "        ## Coef\n",
    "        # coef = GL(inputs_star_**self.alpha, train=train)#/(self.kernel_size**2)\n",
    "        # coef = FG(coef, fmean=fmean)\n",
    "        # coef = rearrange(coef, \"b h w (phase theta f) -> b h w (phase f theta)\", b=b, h=h, w=w, phase=2, f=config.N_SCALES, theta=config.N_ORIENTATIONS)\n",
    "        # coef = OG(coef, theta_mean=theta_mean) + bias\n",
    "        # coef = rearrange(coef, \"b h w (phase f theta) -> b h w (phase theta f)\", b=b, h=h, w=w, phase=2, f=config.N_SCALES, theta=config.N_ORIENTATIONS)\n",
    "        # coef = jnp.clip(coef+bias, a_min=1e-5)**self.epsilon\n",
    "        # # coef = inputs_star.value * coef\n",
    "        # if self.outputs_star is not None: coef = coef/inputs_star.value*self.outputs_star\n",
    "\n",
    "        # if is_initialized and train:\n",
    "        #     inputs_star.value = (inputs_star.value + jnp.quantile(jnp.abs(inputs), q=0.95, axis=(0,1,2)))/2\n",
    "        # return coef * inputs / (jnp.clip(denom+bias, a_min=1e-5)**self.epsilon + self.eps)\n",
    "        return inputs / (jnp.clip(outputs+bias, a_min=1e-5)**self.epsilon + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaborLayerGammaHumanLike_(nn.Module):\n",
    "    \"\"\"Parametric Gabor layer with particular initialization.\"\"\"\n",
    "    n_scales: Sequence[int] # [A, T, D]\n",
    "    n_orientations: Sequence[int] # [A, T, D]\n",
    "\n",
    "    kernel_size: Union[int, Sequence[int]]\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    feature_group_count: int = 1\n",
    "\n",
    "    use_bias: bool = False\n",
    "    xmean: float = 0.5\n",
    "    ymean: float = 0.5\n",
    "    fs: float = 1 # Sampling frequency\n",
    "    phase = jnp.array([0., jnp.pi/2.])\n",
    "\n",
    "    normalize_prob: bool = True\n",
    "    normalize_energy: bool = False\n",
    "    zero_mean: bool = False\n",
    "    train_A: bool = False\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 train=False,\n",
    "                 return_freq=False,\n",
    "                 return_theta=False,\n",
    "                 ):\n",
    "        total_scales = jnp.sum(jnp.array(self.n_scales))\n",
    "        total_orientations = jnp.sum(jnp.array(self.n_orientations))\n",
    "        features = jnp.sum(jnp.array([s*o*len(self.phase) for s, o in zip(self.n_scales, self.n_orientations)]))\n",
    "\n",
    "        is_initialized = self.has_variable(\"precalc_filter\", \"kernel\")\n",
    "        precalc_filters = self.variable(\"precalc_filter\",\n",
    "                                        \"kernel\",\n",
    "                                        jnp.zeros,\n",
    "                                        (self.kernel_size, self.kernel_size, inputs.shape[-1], features))\n",
    "        freq_a = self.param(\"freq_a\",\n",
    "                           freq_scales_init(n_scales=self.n_scales[0], fs=self.fs),\n",
    "                           (self.n_scales[0],))\n",
    "        gammax_a = self.param(\"gammax_a\",\n",
    "                           k_array(k=0.4, arr=1/(freq_a**0.8)),\n",
    "                           (self.n_scales[0],))\n",
    "        gammay_a = self.param(\"gammay_a\",\n",
    "                            equal_to(gammax_a*0.8),\n",
    "                            (self.n_scales[0],))\n",
    "        theta_a = self.param(\"theta_a\",\n",
    "                           linspace(start=0, stop=jnp.pi, num=self.n_orientations[0]),\n",
    "                           (self.n_orientations[0],))\n",
    "        sigma_theta_a = self.param(\"sigma_theta_a\",\n",
    "                                  equal_to(theta_a),\n",
    "                                  (self.n_orientations[0],))\n",
    "\n",
    "        freq_t = self.param(\"freq_t\",\n",
    "                           freq_scales_init(n_scales=self.n_scales[1], fs=self.fs),\n",
    "                           (self.n_scales[1],))\n",
    "        gammax_t = self.param(\"gammax_t\",\n",
    "                           k_array(k=0.4, arr=1/(freq_t**0.8)),\n",
    "                           (self.n_scales[1],))\n",
    "        gammay_t = self.param(\"gammay_t\",\n",
    "                            equal_to(gammax_t*0.8),\n",
    "                            (self.n_scales[1],))\n",
    "        theta_t = self.param(\"theta_t\",\n",
    "                           linspace(start=0, stop=jnp.pi, num=self.n_orientations[1]),\n",
    "                           (self.n_orientations[1],))\n",
    "        sigma_theta_t = self.param(\"sigma_theta_t\",\n",
    "                                  equal_to(theta_t),\n",
    "                                  (self.n_orientations[1],))\n",
    "\n",
    "        freq_d = self.param(\"freq_d\",\n",
    "                           freq_scales_init(n_scales=self.n_scales[2], fs=self.fs),\n",
    "                           (self.n_scales[2],))\n",
    "        gammax_d = self.param(\"gammax_d\",\n",
    "                           k_array(k=0.4, arr=1/(freq_d**0.8)),\n",
    "                           (self.n_scales[2],))\n",
    "        gammay_d = self.param(\"gammay_d\",\n",
    "                            equal_to(gammax_d*0.8),\n",
    "                            (self.n_scales[2],))\n",
    "        theta_d = self.param(\"theta_d\",\n",
    "                           linspace(start=0, stop=jnp.pi, num=self.n_orientations[2]),\n",
    "                           (self.n_orientations[2],))\n",
    "        sigma_theta_d = self.param(\"sigma_theta_d\",\n",
    "                                  equal_to(theta_d),\n",
    "                                  (self.n_orientations[2],))\n",
    "\n",
    "        # A = self.param(\"A\",\n",
    "        #                nn.initializers.ones_init(),\n",
    "        #                (inputs.shape[-1], features)) if self.train_A else jnp.ones(shape=(inputs.shape[-1], features))\n",
    "        A = self.param(\"A\",\n",
    "                       nn.initializers.ones_init(),\n",
    "                       (inputs.shape[-1], 128))\n",
    "        if self.use_bias: bias = self.param(\"bias\",\n",
    "                                            self.bias_init,\n",
    "                                            (features,))\n",
    "        else: bias = 0.\n",
    "\n",
    "        if is_initialized and not train: \n",
    "            kernel = precalc_filters.value\n",
    "        elif is_initialized and train: \n",
    "            x, y = self.generate_dominion()\n",
    "            ## A\n",
    "            kernel_a = jax.vmap(self.gabor, in_axes=(None,None,None,None,0,0,0,None,None,None,None,None,None,None), out_axes=0)\n",
    "            kernel_a = jax.vmap(kernel_a, in_axes=(None,None,None,None,None,None,None,0,0,None,None,None,None,None), out_axes=0)\n",
    "            kernel_a = jax.vmap(kernel_a, in_axes=(None,None,None,None,None,None,None,None,None,0,None,None,None,None), out_axes=0)(x, y, self.xmean, self.ymean, gammax_a, gammay_a, freq_a, theta_a, sigma_theta_a, self.phase, 1, self.normalize_prob, self.normalize_energy, self.zero_mean)\n",
    "            kernel_a = rearrange(kernel_a, \"phases rots fs_sigmas kx ky -> kx ky (phases rots fs_sigmas)\")\n",
    "            kernel_a = repeat(kernel_a, \"kx ky c_out -> kx ky c_in c_out\", c_in=inputs.shape[-1], c_out=kernel_a.shape[-1])\n",
    "\n",
    "            ## T\n",
    "            kernel_t = jax.vmap(self.gabor, in_axes=(None,None,None,None,0,0,0,None,None,None,None,None,None,None), out_axes=0)\n",
    "            kernel_t = jax.vmap(kernel_t, in_axes=(None,None,None,None,None,None,None,0,0,None,None,None,None,None), out_axes=0)\n",
    "            kernel_t = jax.vmap(kernel_t, in_axes=(None,None,None,None,None,None,None,None,None,0,None,None,None,None), out_axes=0)(x, y, self.xmean, self.ymean, gammax_t, gammay_t, freq_t, theta_t, sigma_theta_t, self.phase, 1, self.normalize_prob, self.normalize_energy, self.zero_mean)\n",
    "            kernel_t = rearrange(kernel_t, \"phases rots fs_sigmas kx ky -> kx ky (phases rots fs_sigmas)\")\n",
    "            kernel_t = repeat(kernel_t, \"kx ky c_out -> kx ky c_in c_out\", c_in=inputs.shape[-1], c_out=kernel_t.shape[-1])\n",
    "\n",
    "            ## D\n",
    "            kernel_d = jax.vmap(self.gabor, in_axes=(None,None,None,None,0,0,0,None,None,None,None,None,None,None), out_axes=0)\n",
    "            kernel_d = jax.vmap(kernel_d, in_axes=(None,None,None,None,None,None,None,0,0,None,None,None,None,None), out_axes=0)\n",
    "            kernel_d = jax.vmap(kernel_d, in_axes=(None,None,None,None,None,None,None,None,None,0,None,None,None,None), out_axes=0)(x, y, self.xmean, self.ymean, gammax_d, gammay_d, freq_d, theta_d, sigma_theta_d, self.phase, 1, self.normalize_prob, self.normalize_energy, self.zero_mean)\n",
    "            kernel_d = rearrange(kernel_d, \"phases rots fs_sigmas kx ky -> kx ky (phases rots fs_sigmas)\")\n",
    "            kernel_d = repeat(kernel_d, \"kx ky c_out -> kx ky c_in c_out\", c_in=inputs.shape[-1], c_out=kernel_d.shape[-1])\n",
    "\n",
    "            ## Concat all of them\n",
    "            kernel = jnp.concatenate([kernel_a, kernel_t, kernel_d], axis=-1)\n",
    "            kernel = kernel * A[None,None,:,:]\n",
    "            precalc_filters.value = kernel\n",
    "        else:\n",
    "            kernel = precalc_filters.value\n",
    "\n",
    "        ## Add the batch dim if the input is a single element\n",
    "        if jnp.ndim(inputs) < 4: inputs = inputs[None,:]; had_batch = False\n",
    "        else: had_batch = True\n",
    "        outputs = lax.conv(jnp.transpose(inputs,[0,3,1,2]),    # lhs = NCHW image tensor\n",
    "               jnp.transpose(kernel,[3,2,0,1]), # rhs = OIHW conv kernel tensor\n",
    "               (self.strides, self.strides),\n",
    "               self.padding)\n",
    "        ## Move the channels back to the last dim\n",
    "        outputs = jnp.transpose(outputs, (0,2,3,1))\n",
    "        fmean = jnp.concatenate([jnp.tile(f, reps=len(t)) for f,t in zip([freq_a, freq_t, freq_d], [theta_a, theta_t, theta_d])])\n",
    "        fmean = jnp.tile(fmean, reps=2)\n",
    "        theta_mean = jnp.concatenate([jnp.tile(t, reps=len(f)) for f,t in zip([freq_a, freq_t, freq_d], [theta_a, theta_t, theta_d])])\n",
    "        theta_mean = jnp.tile(theta_mean, reps=2)\n",
    "\n",
    "        if not had_batch: outputs = outputs[0]\n",
    "        if return_freq and return_theta:\n",
    "            return outputs + bias, fmean, theta_mean \n",
    "        elif return_freq and not return_theta:\n",
    "            return outputs + bias, fmean\n",
    "        elif not return_freq and return_theta:\n",
    "            return outputs + bias, theta_mean\n",
    "        else:\n",
    "            return outputs + bias\n",
    "\n",
    "    @staticmethod\n",
    "    def gabor(x, y, xmean, ymean, gammax, gammay, freq, theta, sigma_theta, phase, A=1, normalize_prob=True, normalize_energy=False, zero_mean=False):\n",
    "        x, y = x-xmean, y-ymean\n",
    "        ## Obtain the normalization coeficient\n",
    "        gamma_vector = jnp.array([gammax, gammay])\n",
    "        inv_cov_matrix = jnp.diag(gamma_vector)**2\n",
    "        # det_cov_matrix = 1/jnp.linalg.det(cov_matrix)\n",
    "        # # A_norm = 1/(2*jnp.pi*jnp.sqrt(det_cov_matrix)) if normalize_prob else 1.\n",
    "        # A_norm = jnp.where(normalize_prob, 1/(2*jnp.pi*jnp.sqrt(det_cov_matrix)), 1.)\n",
    "        A_norm = 1.\n",
    "        \n",
    "        ## Rotate the sinusoid\n",
    "        rotation_matrix = jnp.array([[jnp.cos(sigma_theta), -jnp.sin(sigma_theta)],\n",
    "                                     [jnp.sin(sigma_theta), jnp.cos(sigma_theta)]])\n",
    "        rotated_covariance = rotation_matrix @ inv_cov_matrix @ jnp.transpose(rotation_matrix)\n",
    "        x_r_1 = rotated_covariance[0,0] * x + rotated_covariance[0,1] * y\n",
    "        y_r_1 = rotated_covariance[1,0] * x + rotated_covariance[1,1] * y\n",
    "        distance = x * x_r_1 + y * y_r_1\n",
    "        g = A_norm*jnp.exp(-distance/2) * jnp.cos(2*jnp.pi*freq*(x*jnp.cos(theta)+y*jnp.sin(theta)) + phase)\n",
    "        g = jnp.where(zero_mean, g - g.mean(), g)\n",
    "        E_norm = jnp.where(normalize_energy, jnp.sqrt(jnp.sum(g**2)), 1.)\n",
    "        return A*g/E_norm\n",
    "\n",
    "    def return_kernel(self, params, c_in=3):\n",
    "        x, y = self.generate_dominion()\n",
    "        sigmax, sigmay = jnp.exp(params[\"sigmax\"]), jnp.exp(params[\"sigmay\"])\n",
    "        kernel = jax.vmap(self.gabor, in_axes=(None,None,None,None,0,0,None,None,None,None,None,None,None), out_axes=0)\n",
    "        kernel = jax.vmap(kernel, in_axes=(None,None,None,None,None,None,0,None,None,None,None,None,None), out_axes=0)\n",
    "        kernel = jax.vmap(kernel, in_axes=(None,None,None,None,None,None,None,0,0,0,None,None,None), out_axes=0)(x, y, self.xmean, self.ymean, params[\"sigmax\"], params[\"sigmay\"], params[\"freq\"], params[\"theta\"], params[\"sigma_theta\"], self.phase, 1, self.normalize_prob, self.normalize_energy)\n",
    "        # kernel = rearrange(kernel, \"(c_in c_out) kx ky -> kx ky c_in c_out\", c_in=inputs.shape[-1], c_out=self.features)\n",
    "        kernel = rearrange(kernel, \"rots fs sigmas kx ky -> kx ky (rots fs sigmas)\")\n",
    "        kernel = repeat(kernel, \"kx ky c_out -> kx ky c_in c_out\", c_in=c_in, c_out=kernel.shape[-1])\n",
    "        return kernel\n",
    "    \n",
    "    def generate_dominion(self):\n",
    "        return jnp.meshgrid(jnp.linspace(0,self.kernel_size/self.fs,num=self.kernel_size), jnp.linspace(0,self.kernel_size/self.fs,num=self.kernel_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNet(nn.Module):\n",
    "    \"\"\"IQA model inspired by the visual system.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs, # Assuming fs = 128 (cpd)\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        ## (Independent) Color equilibration (Gamma correction)\n",
    "        ## Might need to be the same for each number\n",
    "        ## bias = 0.1 / kernel = 0.5\n",
    "        if config.USE_GAMMA: outputs = GDNGamma()(inputs)\n",
    "        else: outputs = GDN(kernel_size=(1,1), apply_independently=True)(inputs)\n",
    "        \n",
    "        ## Color (ATD) Transformation\n",
    "        outputs = nn.Conv(features=3, kernel_size=(1,1), use_bias=False, name=\"Color\")(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        \n",
    "        ## GDN Star A - T - D [Separated]\n",
    "        outputs = GDN(kernel_size=(1,1), apply_independently=True)(outputs)\n",
    "\n",
    "        ## Center Surround (DoG)\n",
    "        ## Initialized so that 3 are positives and 3 are negatives and no interaction between channels is present\n",
    "        outputs = pad_same_from_kernel_size(outputs, kernel_size=config.CS_KERNEL_SIZE, mode=\"symmetric\")\n",
    "        outputs = CenterSurroundLogSigmaK(features=3, kernel_size=config.CS_KERNEL_SIZE, fs=21, use_bias=False, padding=\"VALID\")(outputs, **kwargs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "\n",
    "        ## GDN per channel with mean substraction in T and D (Spatial Gaussian Kernel)\n",
    "        ### fs = 32 / kernel_size = (11,11) -> 0.32 > 0.02 --> OK!\n",
    "        ## TO-DO: - Spatial Gaussian Kernel (0.02 deg) -> fs = 64/2 & 0.02*64/2 = sigma (px) = 0.69\n",
    "        outputs = GDNGaussian(kernel_size=config.GDNGAUSSIAN_KERNEL_SIZE, apply_independently=True, fs=32, padding=\"symmetric\", normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY)(outputs, **kwargs)\n",
    "\n",
    "        ## GaborLayer per channel with GDN mixing only same-origin-channel information\n",
    "        ### [Gaussian] sigma = 0.2 (deg) fs = 32 / kernel_size = (21,21) -> 21/32 = 0.66 --> OK!\n",
    "        outputs = pad_same_from_kernel_size(outputs, kernel_size=config.GABOR_KERNEL_SIZE, mode=\"symmetric\")\n",
    "        # outputs, fmean, theta_mean = GaborLayerGamma_(n_scales=4+2+2, n_orientations=8*3, kernel_size=config.GABOR_KERNEL_SIZE, fs=32, xmean=config.GABOR_KERNEL_SIZE/32/2, ymean=config.GABOR_KERNEL_SIZE/32/2, strides=1, padding=\"VALID\", normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY, zero_mean=config.ZERO_MEAN, use_bias=config.USE_BIAS, train_A=config.A_GABOR)(outputs, return_freq=True, return_theta=True, **kwargs)\n",
    "        outputs, fmean, theta_mean = GaborLayerGammaHumanLike_(n_scales=[4,2,2], n_orientations=[8,8,8], kernel_size=config.GABOR_KERNEL_SIZE, fs=32, xmean=config.GABOR_KERNEL_SIZE/32/2, ymean=config.GABOR_KERNEL_SIZE/32/2, strides=1, padding=\"VALID\", normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY, zero_mean=config.ZERO_MEAN, use_bias=config.USE_BIAS, train_A=config.A_GABOR)(outputs, return_freq=True, return_theta=True, **kwargs)\n",
    "        \n",
    "        ## Final GDN mixing Gabor information (?)\n",
    "        outputs = GDNSpatioChromaFreqOrient(kernel_size=21, strides=1, padding=\"symmetric\", fs=32, apply_independently=False)(outputs, fmean=fmean, theta_mean=theta_mean, **kwargs)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the metrics with `clu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    \"\"\"Collection of metrics to be tracked during training.\"\"\"\n",
    "    loss: metrics.Average.from_output(\"loss\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `TrainState` doesn't include metrics, but it's very easy to subclass it so that it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "    state: FrozenDict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a function that initializes the `TrainState` from a module, a rng key and some optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, key, tx, input_shape):\n",
    "    \"\"\"Creates the initial `TrainState`.\"\"\"\n",
    "    variables = module.init(key, jnp.ones(input_shape))\n",
    "    state, params = variables.pop('params')\n",
    "    return TrainState.create(\n",
    "        apply_fn=module.apply,\n",
    "        params=params,\n",
    "        state=state,\n",
    "        tx=tx,\n",
    "        metrics=Metrics.empty()\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the training step\n",
    "\n",
    "> We want to write a function that takes the `TrainState` and a batch of data can performs an optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation(vec1, vec2):\n",
    "    vec1 = vec1.squeeze()\n",
    "    vec2 = vec2.squeeze()\n",
    "    vec1_mean = vec1.mean()\n",
    "    vec2_mean = vec2.mean()\n",
    "    num = vec1-vec1_mean\n",
    "    num *= vec2-vec2_mean\n",
    "    num = num.sum()\n",
    "    denom = jnp.sqrt(jnp.sum((vec1-vec1_mean)**2))\n",
    "    denom *= jnp.sqrt(jnp.sum((vec2-vec2_mean)**2))\n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit)\n",
    "def train_step(state, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    img, img_dist, mos = batch\n",
    "    def loss_fn(params):\n",
    "        ## Forward pass through the model\n",
    "        img_pred, updated_state = state.apply_fn({\"params\": params, **state.state}, img, mutable=list(state.state.keys()), train=True)\n",
    "        img_dist_pred, updated_state = state.apply_fn({\"params\": params, **state.state}, img_dist, mutable=list(state.state.keys()), train=True)\n",
    "\n",
    "        ## Calculate the distance\n",
    "        dist = ((img_pred - img_dist_pred)**2).sum(axis=(1,2,3))**(1/2)\n",
    "        \n",
    "        ## Calculate pearson correlation\n",
    "        return pearson_correlation(dist, mos), updated_state\n",
    "    \n",
    "    (loss, updated_state), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(PerceptNet(), random.PRNGKey(config.SEED), optax.adam(config.LEARNING_RATE), input_shape=(1,384,512,3))\n",
    "state = state.replace(params=clip_layer(state.params, \"GDN\", a_min=0))\n",
    "state = state.replace(params=clip_param(state.params, \"A\", a_min=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozen_dict_keys(['GDNGamma_0', 'Color', 'GDN_0', 'CenterSurroundLogSigmaK_0', 'GDNGaussian_0', 'GaborLayerGammaHumanLike__0', 'GDNSpatioChromaFreqOrient_0'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, _ = state.apply_fn({\"params\": state.params, **state.state}, jnp.ones(shape=(1,384,512,3)), train=True, mutable=list(state.state.keys()))\n",
    "state = state.replace(state=_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trainable(path):\n",
    "    if not config.A_GDNSPATIOFREQORIENT:\n",
    "        if (\"GDNSpatioChromaFreqOrient_0\" in path) and (\"A\" in path):\n",
    "            return True\n",
    "    if \"Color\" in path:\n",
    "        if not config.TRAIN_JH:\n",
    "            return True\n",
    "    if \"CenterSurroundLogSigmaK_0\" in path:\n",
    "        if not config.TRAIN_CS:\n",
    "            return True\n",
    "    if \"Gabor\" in \"\".join(path):\n",
    "        if not config.TRAIN_GABOR:\n",
    "            return True\n",
    "    if \"GDNSpatioChromaFreqOrient_0\" not in path and config.TRAIN_ONLY_LAST_GDN:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict({\n",
       "    GDNGamma_0: {\n",
       "        kernel: 'non_trainable',\n",
       "        bias: 'non_trainable',\n",
       "    },\n",
       "    Color: {\n",
       "        kernel: 'non_trainable',\n",
       "    },\n",
       "    GDN_0: {\n",
       "        Conv_0: {\n",
       "            kernel: 'non_trainable',\n",
       "            bias: 'non_trainable',\n",
       "        },\n",
       "    },\n",
       "    CenterSurroundLogSigmaK_0: {\n",
       "        logsigma: 'non_trainable',\n",
       "        K: 'non_trainable',\n",
       "        A: 'non_trainable',\n",
       "    },\n",
       "    GDNGaussian_0: {\n",
       "        GaussianLayerGamma_0: {\n",
       "            gamma: 'non_trainable',\n",
       "            A: 'non_trainable',\n",
       "            bias: 'non_trainable',\n",
       "        },\n",
       "    },\n",
       "    GaborLayerGammaHumanLike__0: {\n",
       "        freq_a: 'non_trainable',\n",
       "        gammax_a: 'non_trainable',\n",
       "        gammay_a: 'non_trainable',\n",
       "        theta_a: 'non_trainable',\n",
       "        sigma_theta_a: 'non_trainable',\n",
       "        freq_t: 'non_trainable',\n",
       "        gammax_t: 'non_trainable',\n",
       "        gammay_t: 'non_trainable',\n",
       "        theta_t: 'non_trainable',\n",
       "        sigma_theta_t: 'non_trainable',\n",
       "        freq_d: 'non_trainable',\n",
       "        gammax_d: 'non_trainable',\n",
       "        gammay_d: 'non_trainable',\n",
       "        theta_d: 'non_trainable',\n",
       "        sigma_theta_d: 'non_trainable',\n",
       "        A: 'non_trainable',\n",
       "    },\n",
       "    GDNSpatioChromaFreqOrient_0: {\n",
       "        bias: 'trainable',\n",
       "        GaussianLayerGamma_0: {\n",
       "            gamma: 'trainable',\n",
       "            A: 'non_trainable',\n",
       "        },\n",
       "        ChromaFreqOrientGaussianGamma_0: {\n",
       "            gamma_f_a: 'trainable',\n",
       "            gamma_theta_a: 'trainable',\n",
       "            gamma_f_t: 'trainable',\n",
       "            gamma_theta_t: 'trainable',\n",
       "            gamma_f_d: 'trainable',\n",
       "            gamma_theta_d: 'trainable',\n",
       "            H_cc: 'trainable',\n",
       "        },\n",
       "    },\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_tree = freeze(flax.traverse_util.path_aware_map(lambda path, v: \"non_trainable\" if check_trainable(path)  else \"trainable\", state.params))\n",
    "trainable_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a schedule (linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_schedule(step, start_lr, end_lr, n_iters):\n",
    "    return start_lr*(end_lr/start_lr)**(step/n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_schedule(step, start_lr, end_lr, n_iters):\n",
    "    return start_lr + (end_lr-start_lr)*(step/n_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_iters = 100\n",
    "start_lr, end_lr = 1e-10, 1\n",
    "steps = jnp.arange(start=0, stop=n_iters)\n",
    "plt.plot(steps, exponential_schedule(steps, start_lr, end_lr, n_iters))\n",
    "plt.plot(steps, linear_schedule(steps, start_lr, end_lr, n_iters))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sch = optax.linear_schedule(init_value=1e-10, end_value=1., transition_steps=100)\n",
    "steps = jnp.arange(1000)\n",
    "plt.plot(steps, sch(steps))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 20\n",
    "lr_scheduler = optax.linear_schedule(init_value=1e-10, end_value=1., transition_steps=n_iters)\n",
    "optimizers = {\n",
    "    \"trainable\": optax.adam(learning_rate=lr_scheduler),\n",
    "    \"non_trainable\": optax.set_to_zero(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = optax.multi_transform(optimizers, trainable_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(PerceptNet(), random.PRNGKey(config.SEED), tx, input_shape=(1,384,512,3))\n",
    "state = state.replace(params=clip_layer(state.params, \"GDN\", a_min=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(934, 297)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(state.params))\n",
    "trainable_param_count = sum([w.size if t==\"trainable\" else 0 for w, t in zip(jax.tree_util.tree_leaves(state.params), jax.tree_util.tree_leaves(trainable_tree))])\n",
    "param_count, trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.summary[\"total_parameters\"] = param_count\n",
    "wandb.run.summary[\"trainable_parameters\"] = trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = state.replace(params=unfreeze(state.params))\n",
    "\n",
    "# ## DN 0 (Gamma)\n",
    "if config.USE_GAMMA:\n",
    "    state.params[\"GDNGamma_0\"][\"bias\"] = jnp.ones_like(state.params[\"GDNGamma_0\"][\"bias\"])*0.1\n",
    "    state.params[\"GDNGamma_0\"][\"kernel\"] = jnp.ones_like(state.params[\"GDNGamma_0\"][\"kernel\"])*0.5\n",
    "else:\n",
    "    state.params[\"GDN_0\"][\"Conv_0\"][\"bias\"] = jnp.ones_like(state.params[\"GDN_0\"][\"Conv_0\"][\"bias\"])*0.1\n",
    "    state.params[\"GDN_0\"][\"Conv_0\"][\"kernel\"] = jnp.ones_like(state.params[\"GDN_0\"][\"Conv_0\"][\"kernel\"])*0.5\n",
    "\n",
    "## Opponent color channel transformation\n",
    "if config.INIT_JH:\n",
    "    state.params[\"Color\"][\"kernel\"] = jnp.array([[39.0454,30.1207,14.27948],\n",
    "                                                  [115.8404,-63.3502,41.26816],\n",
    "                                                  [16.3118,30.2934,-61.51888]])[None,None,:,:]/163.5217\n",
    "\n",
    "## Center Surround\n",
    "state.params[\"CenterSurroundLogSigmaK_0\"][\"logsigma\"] = jnp.array([-1.9,-1.9,-1.9,\n",
    "                                                                   -1.76,-1.76,-1.76,\n",
    "                                                                   -1.76,-1.76,-1.76])\n",
    "state.params[\"CenterSurroundLogSigmaK_0\"][\"K\"] = jnp.array([1.1,1.1,1.1,\n",
    "                                                            5.0,5.0,5.0,\n",
    "                                                            5.0,5.0,5.0])\n",
    "state.params[\"CenterSurroundLogSigmaK_0\"][\"A\"] = jnp.array([1.,0.,0.,\n",
    "                                                            0.,1.,0.,\n",
    "                                                            0.,0.,1.])\n",
    "\n",
    "## GDNGaussian\n",
    "state.params[\"GDNGaussian_0\"][\"GaussianLayerGamma_0\"][\"gamma\"] = jnp.ones_like(state.params[\"GDNGaussian_0\"][\"GaussianLayerGamma_0\"][\"gamma\"])*(1./0.04)\n",
    "state.params[\"GDNGaussian_0\"][\"GaussianLayerGamma_0\"][\"bias\"] = jnp.ones_like(state.params[\"GDNGaussian_0\"][\"GaussianLayerGamma_0\"][\"bias\"])*0.1\n",
    "\n",
    "## Gabor\n",
    "if config.INIT_GABOR:\n",
    "    state.params[\"GaborLayerGammaHumanLike__0\"][\"freq_a\"] = jnp.array([2.,4.,8.,16.]) \n",
    "    state.params[\"GaborLayerGammaHumanLike__0\"][\"freq_t\"] = jnp.array([3.,6.]) \n",
    "    state.params[\"GaborLayerGammaHumanLike__0\"][\"freq_d\"] = jnp.array([3.,6.])\n",
    "\n",
    "    state.params[\"GaborLayerGammaHumanLike__0\"][\"gammax_a\"] = state.params[\"GaborLayerGammaHumanLike__0\"][\"freq_a\"]**0.9\n",
    "    state.params[\"GaborLayerGammaHumanLike__0\"][\"gammay_a\"] = 0.8*state.params[\"GaborLayerGammaHumanLike__0\"][\"gammax_a\"]\n",
    "\n",
    "    state.params[\"GaborLayerGammaHumanLike__0\"][\"gammax_t\"] = state.params[\"GaborLayerGammaHumanLike__0\"][\"freq_t\"]**0.9\n",
    "    state.params[\"GaborLayerGammaHumanLike__0\"][\"gammay_t\"] = 0.8*state.params[\"GaborLayerGammaHumanLike__0\"][\"gammax_t\"]\n",
    "\n",
    "    state.params[\"GaborLayerGammaHumanLike__0\"][\"gammax_d\"] = state.params[\"GaborLayerGammaHumanLike__0\"][\"freq_d\"]**0.9\n",
    "    state.params[\"GaborLayerGammaHumanLike__0\"][\"gammay_d\"] = 0.8*state.params[\"GaborLayerGammaHumanLike__0\"][\"gammax_d\"]\n",
    "    # state.params[\"GaborLayerGammaHumanLike__0\"][\"theta_a\"] = jnp.tile(jnp.linspace(0., jnp.pi, num=16), reps=128//16)\n",
    "    # state.params[\"GaborLayerGammaHumanLike__0\"][\"sigma_theta_a\"] = state.params[\"GaborLayerGammaHumanLike__0\"][\"theta_a\"]\n",
    "    # state.params[\"GaborLayerGammaHumanLike__0\"][\"phase_a\"] = jnp.repeat(jnp.array([0., 90.]), repeats=64)    \n",
    "\n",
    "    A_a = jnp.zeros(shape=(3,64), dtype=jnp.float32)\n",
    "    A_a = A_a.at[0,:].set(1.)\n",
    "    A_t = jnp.zeros(shape=(3,32), dtype=jnp.float32)\n",
    "    A_t = A_t.at[1,:].set(1.)\n",
    "    A_d = jnp.zeros(shape=(3,32), dtype=jnp.float32)\n",
    "    A_d = A_d.at[2,:].set(1.)\n",
    "    state.params[\"GaborLayerGammaHumanLike__0\"][\"A\"] = jnp.concatenate([A_a, A_t, A_d], axis=-1)\n",
    "\n",
    "## GDNSpatioChromaFreqOrient\n",
    "# state.params[\"GDNSpatioChromaFreqOrient_0\"][\"GaussianLayerGamma_0\"][\"gamma\"] = jnp.ones_like(state.params[\"GDNSpatioChromaFreqOrient_0\"][\"GaussianLayerGamma_0\"][\"gamma\"])*(1./0.1)\n",
    "# state.params[\"GDNSpatioChromaFreqOrient_0\"][\"OrientGaussianGamma_0\"][\"gamma\"] = jnp.ones_like(state.params[\"GDNSpatioChromaFreqOrient_0\"][\"OrientGaussianGamma_0\"][\"gamma\"])*(1/20)\n",
    "# state.params[\"GDNSpatioChromaFreqOrient_0\"][\"bias\"] = jnp.tile(jnp.array([0.001, 0.002, 0.0035, 0.01])/100, reps=config.N_ORIENTATIONS*2)\n",
    "state.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"H_cc\"] = jnp.eye(3,3)\n",
    "state.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"gamma_theta_a\"] = jnp.ones_like(state.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"gamma_theta_a\"])*(1/20)\n",
    "state.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"gamma_theta_t\"] = jnp.ones_like(state.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"gamma_theta_t\"])*(1/20)\n",
    "state.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"gamma_theta_d\"] = jnp.ones_like(state.params[\"GDNSpatioChromaFreqOrient_0\"][\"ChromaFreqOrientGaussianGamma_0\"][\"gamma_theta_d\"])*(1/20)\n",
    "\n",
    "\n",
    "state = state.replace(params=freeze(state.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, _ = state.apply_fn({\"params\": state.params, **state.state}, jnp.ones(shape=(1,384,512,3)), train=True, mutable=list(state.state.keys()))\n",
    "state = state.replace(state=_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 12:00:27.179072: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype double and shape [1632]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2024-06-27 12:00:27.382006: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150994944 exceeds 10% of free system memory.\n",
      "2024-06-27 12:00:27.382382: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150994944 exceeds 10% of free system memory.\n",
      "2024-06-27 12:00:27.440494: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150994944 exceeds 10% of free system memory.\n",
      "2024-06-27 12:00:27.440557: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150994944 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dst_train_rdy.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57min 28s, sys: 1min 2s, total: 58min 30s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s1, loss = train_step(state, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jax.config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 12:42:50.077051: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype double and shape [1632]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2024-06-27 12:42:50.078019: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1632]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m losses, lrs \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dst_train_rdy\u001b[38;5;241m.\u001b[39mrepeat()\u001b[38;5;241m.\u001b[39mas_numpy_iterator(), start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m## 1. Perform an optimization step\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     state, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mreplace(params\u001b[38;5;241m=\u001b[39mclip_layer(state\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGDN\u001b[39m\u001b[38;5;124m\"\u001b[39m, a_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      8\u001b[0m     state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mreplace(params\u001b[38;5;241m=\u001b[39mclip_param(state\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m, a_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/flax/core/frozen_dict.py:162\u001b[0m, in \u001b[0;36mFrozenDict.tree_unflatten\u001b[0;34m(cls, keys, values)\u001b[0m\n\u001b[1;32m    157\u001b[0m   sorted_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict)\n\u001b[1;32m    158\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    159\u001b[0m       [(jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mDictKey(k), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict[k]) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m sorted_keys]\n\u001b[1;32m    160\u001b[0m   ), \u001b[38;5;28mtuple\u001b[39m(sorted_keys)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_unflatten\u001b[39m(\u001b[38;5;28mcls\u001b[39m, keys, values):\n\u001b[1;32m    164\u001b[0m   \u001b[38;5;66;03m# data is already deep copied due to tree map mechanism\u001b[39;00m\n\u001b[1;32m    165\u001b[0m   \u001b[38;5;66;03m# we can skip the deep copy in the constructor\u001b[39;00m\n\u001b[1;32m    166\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m({k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(keys, values)}, __unsafe_skip_copy__\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iters = 20\n",
    "losses, lrs = [], []\n",
    "\n",
    "for step, batch in enumerate(dst_train_rdy.repeat().as_numpy_iterator(), start=1):\n",
    "    ## 1. Perform an optimization step\n",
    "    state, loss = train_step(state, batch)\n",
    "    state = state.replace(params=clip_layer(state.params, \"GDN\", a_min=0))\n",
    "    state = state.replace(params=clip_param(state.params, \"A\", a_min=0))\n",
    "    state = state.replace(params=clip_param(state.params, \"K\", a_min=1+1e-5))\n",
    "\n",
    "    ## 2. Store loss and lr\n",
    "    losses.append(jax.device_put(loss, jax.devices(\"cpu\")[0]))\n",
    "    lrs = lr_scheduler(step)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Array(-0.44779968, dtype=float32)], Array(0., dtype=float32, weak_type=True))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses, lrs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
