{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 15:17:03.040225: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 15:17:05.443441: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lhome/ext/uv075/uv0752/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-04 15:17:11.419960: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "2023-12-04 15:17:11.420310: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:1: failed initializing StreamExecutor for CUDA device ordinal 1: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from typing import Any, Callable, Sequence, Union\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "import jax\n",
    "from jax import lax, random, numpy as jnp\n",
    "import flax\n",
    "from flax.core import freeze, unfreeze, FrozenDict\n",
    "from flax import linen as nn\n",
    "from flax import struct\n",
    "from flax.training import train_state\n",
    "from flax.training import orbax_utils\n",
    "\n",
    "import optax\n",
    "import orbax.checkpoint\n",
    "\n",
    "from clu import metrics\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "from einops import reduce, rearrange\n",
    "import wandb\n",
    "\n",
    "from iqadatasets.datasets import *\n",
    "from fxlayers.layers import *\n",
    "from fxlayers.layers import GaborLayerLogSigma_, GaussianLayerGamma, FreqGaussianGamma, OrientGaussianGamma\n",
    "from fxlayers.initializers import *\n",
    "from JaxPlayground.utils.constraints import *\n",
    "from JaxPlayground.utils.wandb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dst_train = TID2008(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2008/\", exclude_imgs=[25])\n",
    "# dst_val = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2013/\", exclude_imgs=[25])\n",
    "# dst_train = TID2008(\"/media/disk/databases/BBDD_video_image/Image_Quality//TID/TID2008/\", exclude_imgs=[25])\n",
    "# dst_val = TID2013(\"/media/disk/databases/BBDD_video_image/Image_Quality//TID/TID2013/\", exclude_imgs=[25])\n",
    "# dst = KADIK10K(\"/media/disk/databases/BBDD_video_image/Image_Quality/KADIK10K/\")\n",
    "# dst = PIPAL(\"/media/disk/databases/BBDD_video_image/Image_Quality/PIPAL/\")\n",
    "dst = PIPAL(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/PIPAL/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([288, 288, 3]), TensorShape([288, 288, 3]), TensorShape([]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, img_dist, mos = next(iter(dst.dataset))\n",
    "img.shape, img_dist.shape, mos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = \"6rhldh50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "prev_run = api.run(f\"jorgvt/PerceptNet_v15/{id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A_GABOR: true\n",
       "A_GDNSPATIOFREQORIENT: true\n",
       "BATCH_SIZE: 64\n",
       "CS_KERNEL_SIZE: 21\n",
       "EPOCHS: 500\n",
       "GABOR_KERNEL_SIZE: 31\n",
       "GDNGAUSSIAN_KERNEL_SIZE: 11\n",
       "GDN_CLIPPING: true\n",
       "INIT_JH: true\n",
       "LEARNING_RATE: 0.003\n",
       "NORMALIZE_ENERGY: true\n",
       "NORMALIZE_PROB: false\n",
       "N_GABORS: 128\n",
       "SEED: 42\n",
       "TRAIN_CS: true\n",
       "TRAIN_JH: true\n",
       "USE_BIAS: false\n",
       "USE_GAMMA: true\n",
       "ZERO_MEAN: true"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = ConfigDict(prev_run.config[\"_fields\"])\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in prev_run.files():\n",
    "    file.download(root=prev_run.dir, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: jorgvt. Use `wandb login --relogin` to force relogin\n",
      "wandb: wandb version 0.16.4 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "wandb: Tracking run with wandb version 0.15.1\n",
      "wandb: Run data is saved locally in /lhome/ext/uv075/uv0752/perceptnet/Notebooks/13_JaX/13_08_Skip/wandb/run-20240306_153905-iztkekbe\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run V19_128GaborFree_A_Skip\n",
      "wandb:  View project at https://wandb.ai/jorgvt/PerceptNet_JaX_Eval\n",
      "wandb:  View run at https://wandb.ai/jorgvt/PerceptNet_JaX_Eval/runs/iztkekbe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "A_GABOR: true\n",
       "A_GDNSPATIOFREQORIENT: true\n",
       "BATCH_SIZE: 64\n",
       "CS_KERNEL_SIZE: 21\n",
       "EPOCHS: 500\n",
       "GABOR_KERNEL_SIZE: 31\n",
       "GDNGAUSSIAN_KERNEL_SIZE: 11\n",
       "GDN_CLIPPING: true\n",
       "INIT_JH: true\n",
       "LEARNING_RATE: 0.003\n",
       "NORMALIZE_ENERGY: true\n",
       "NORMALIZE_PROB: false\n",
       "N_GABORS: 128\n",
       "SEED: 42\n",
       "TRAIN_CS: true\n",
       "TRAIN_JH: true\n",
       "USE_BIAS: false\n",
       "USE_GAMMA: true\n",
       "ZERO_MEAN: true"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"PerceptNet_JaX_Eval\",\n",
    "           name=prev_run.name,\n",
    "           job_type=\"evaluate\",\n",
    "           mode=\"online\",\n",
    "           )\n",
    "config = config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_rdy = dst.dataset.batch(config.BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model we're going to use\n",
    "\n",
    "> It's going to be a very simple model just for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class FreqOrientGaussianGamma(nn.Module):\n",
    "    \"\"\"(1D) Gaussian interaction between frequencies and orientations optimizing gamma = 1/sigma instead of sigma.\"\"\"\n",
    "    use_bias: bool = False\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    bias_init: Callable = nn.initializers.zeros_init()\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 fmean,\n",
    "                 theta_mean,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        gamma_f = self.param(\"gamma_f\",\n",
    "                             k_array(1/0.4, arr=fmean),\n",
    "                             (inputs.shape[-1],))\n",
    "        gamma_theta = self.param(\"gamma_theta\",\n",
    "                                 equal_to(jnp.ones(shape=(len(theta_mean),)) * 20),\n",
    "                                 (inputs.shape[-1],))\n",
    "        if self.use_bias: bias = self.param(\"bias\",\n",
    "                                            self.bias_init,\n",
    "                                            (len(fmean),))\n",
    "        else: bias = 0.\n",
    "        # n_groups = inputs.shape[-1] // len(fmean)\n",
    "        kernel = jax.vmap(self.gaussian, in_axes=(None,None,0,0,0,0,None), out_axes=1)(fmean, theta_mean, fmean, theta_mean, gamma_f, gamma_theta, 1)\n",
    "        kernel = kernel[None,None,:,:]\n",
    "        # kernel = jnp.tile(kernel, reps=n_groups)\n",
    "\n",
    "        ## Add the batch dim if the input is a single element\n",
    "        if jnp.ndim(inputs) < 4: inputs = inputs[None,:]; had_batch = False\n",
    "        else: had_batch = True\n",
    "        outputs = lax.conv_general_dilated(\n",
    "                jnp.transpose(inputs,[0,3,1,2]),    # lhs = NCHW image tensor\n",
    "                jnp.transpose(kernel,[3,2,0,1]), # rhs = OIHW conv kernel tensor\n",
    "                (self.strides, self.strides),\n",
    "                self.padding)\n",
    "        ## Move the channels back to the last dim\n",
    "        outputs = jnp.transpose(outputs, (0,2,3,1))\n",
    "        if not had_batch: outputs = outputs[0]\n",
    "        return outputs + bias\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian(f, theta, fmean, theta_mean, gamma_f, gamma_theta, A=1):\n",
    "        return A*jnp.exp(-((gamma_f**2)*(f-fmean)**2)/(2))*jnp.exp(-((gamma_theta**2)*(theta-theta_mean)**2)/(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDNSpatioFreqOrient(nn.Module):\n",
    "    \"\"\"Generalized Divisive Normalization.\"\"\"\n",
    "    kernel_size: Union[int, Sequence[int]]\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    # inputs_star: float = 1.\n",
    "    # outputs_star: Union[None, float] = None\n",
    "    fs: int = 1\n",
    "    apply_independently: bool = False\n",
    "    bias_init: Callable = nn.initializers.ones_init()\n",
    "    alpha: float = 2.\n",
    "    epsilon: float = 1/2 # Exponential of the denominator\n",
    "    eps: float = 1e-6 # Numerical stability in the denominator\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 fmean,\n",
    "                 theta_mean,\n",
    "                 train=False,\n",
    "                 ):\n",
    "        b, h, w, c = inputs.shape\n",
    "        bias = self.param(\"bias\",\n",
    "                          #equal_to(inputs_star/10),\n",
    "                          self.bias_init,\n",
    "                          (c,))\n",
    "        # is_initialized = self.has_variable(\"batch_stats\", \"inputs_star\")\n",
    "        # inputs_star = self.variable(\"batch_stats\", \"inputs_star\", lambda x: jnp.ones(x)*self.inputs_star, (len(self.inputs_star),))\n",
    "        # inputs_star_ = jnp.ones_like(inputs)*inputs_star.value\n",
    "        GL = GaussianLayerGamma(features=c, kernel_size=self.kernel_size, strides=self.strides, padding=\"VALID\", fs=self.fs, xmean=self.kernel_size/self.fs/2, ymean=self.kernel_size/self.fs/2, normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY, use_bias=False, feature_group_count=c)\n",
    "        FOG = FreqOrientGaussianGamma()\n",
    "        outputs = GL(pad_same_from_kernel_size(inputs, kernel_size=self.kernel_size, mode=self.padding)**self.alpha, train=train)#/(self.kernel_size**2)\n",
    "        outputs = FOG(outputs, fmean=fmean, theta_mean=theta_mean)\n",
    "\n",
    "        ## Coef\n",
    "        # coef = GL(inputs_star_**self.alpha, train=train)#/(self.kernel_size**2)\n",
    "        # coef = FG(coef, fmean=fmean)\n",
    "        # coef = rearrange(coef, \"b h w (phase theta f) -> b h w (phase f theta)\", b=b, h=h, w=w, phase=2, f=config.N_SCALES, theta=config.N_ORIENTATIONS)\n",
    "        # coef = OG(coef, theta_mean=theta_mean) + bias\n",
    "        # coef = rearrange(coef, \"b h w (phase f theta) -> b h w (phase theta f)\", b=b, h=h, w=w, phase=2, f=config.N_SCALES, theta=config.N_ORIENTATIONS)\n",
    "        # coef = jnp.clip(coef+bias, a_min=1e-5)**self.epsilon\n",
    "        # # coef = inputs_star.value * coef\n",
    "        # if self.outputs_star is not None: coef = coef/inputs_star.value*self.outputs_star\n",
    "\n",
    "        # if is_initialized and train:\n",
    "        #     inputs_star.value = (inputs_star.value + jnp.quantile(jnp.abs(inputs), q=0.95, axis=(0,1,2)))/2\n",
    "        # return coef * inputs / (jnp.clip(denom+bias, a_min=1e-5)**self.epsilon + self.eps)\n",
    "        return inputs / (jnp.clip(outputs+bias, a_min=1e-5)**self.epsilon + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNet(nn.Module):\n",
    "    \"\"\"IQA model inspired by the visual system.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs, # Assuming fs = 128 (cpd)\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        ## (Independent) Color equilibration (Gamma correction)\n",
    "        ## Might need to be the same for each number\n",
    "        ## bias = 0.1 / kernel = 0.5\n",
    "        if config.USE_GAMMA: outputs, c0 = GDNGamma(return_coef=True)(inputs)\n",
    "        else: outputs, c0 = GDN(kernel_size=(1,1), apply_independently=True, return_coef=True)(inputs)        \n",
    "        \n",
    "        ## Color (ATD) Transformation\n",
    "        outputs = nn.Conv(features=3, kernel_size=(1,1), use_bias=False, name=\"Color\")(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        \n",
    "        ## GDN Star A - T - D [Separated]\n",
    "        outputs, c1 = GDN(kernel_size=(1,1), apply_independently=True, return_coef=True)(outputs)\n",
    "\n",
    "        ## Center Surround (DoG)\n",
    "        ## Initialized so that 3 are positives and 3 are negatives and no interaction between channels is present\n",
    "        outputs = pad_same_from_kernel_size(outputs, kernel_size=config.CS_KERNEL_SIZE, mode=\"symmetric\")\n",
    "        outputs = CenterSurroundLogSigmaK(features=3, kernel_size=config.CS_KERNEL_SIZE, fs=21, use_bias=False, padding=\"VALID\")(outputs, **kwargs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "\n",
    "        ## GDN per channel with mean substraction in T and D (Spatial Gaussian Kernel)\n",
    "        ### fs = 32 / kernel_size = (11,11) -> 0.32 > 0.02 --> OK!\n",
    "        ## TO-DO: - Spatial Gaussian Kernel (0.02 deg) -> fs = 64/2 & 0.02*64/2 = sigma (px) = 0.69\n",
    "        outputs, c2 = GDNGaussian(kernel_size=config.GDNGAUSSIAN_KERNEL_SIZE, apply_independently=True, fs=32, padding=\"symmetric\", normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY, return_coef=True)(outputs, **kwargs)\n",
    "\n",
    "        ## GaborLayer per channel with GDN mixing only same-origin-channel information\n",
    "        ### [Gaussian] sigma = 0.2 (deg) fs = 32 / kernel_size = (21,21) -> 21/32 = 0.66 --> OK!\n",
    "        outputs = pad_same_from_kernel_size(outputs, kernel_size=config.GABOR_KERNEL_SIZE, mode=\"symmetric\")\n",
    "        outputs, fmean, theta_mean = GaborLayerGammaRepeat(features=config.N_GABORS, kernel_size=config.GABOR_KERNEL_SIZE, fs=32, xmean=config.GABOR_KERNEL_SIZE/32/2, ymean=config.GABOR_KERNEL_SIZE/32/2, strides=1, padding=\"VALID\", normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY, zero_mean=config.ZERO_MEAN, use_bias=config.USE_BIAS, train_A=config.A_GABOR)(outputs, return_freq=True, return_theta=True, **kwargs)\n",
    "        \n",
    "        ## Final GDN mixing Gabor information (?)\n",
    "        outputs = GDNSpatioFreqOrient(kernel_size=21, strides=1, padding=\"symmetric\", fs=32, apply_independently=False)(outputs, fmean=fmean, theta_mean=theta_mean, **kwargs)\n",
    "\n",
    "        return outputs, c0, c1, c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def setup(self):\n",
    "        self.perceptnet = PerceptNet()\n",
    "        self.coefs = self.param(\"coefs\",\n",
    "                           nn.initializers.ones_init(),\n",
    "                           (4,))\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 img,\n",
    "                 img_dist,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        \n",
    "\n",
    "        outputs, c0, c1, c2 = self.perceptnet(img, **kwargs)\n",
    "        outputs_dist, c0_dist, c1_dist, c2_dist = self.perceptnet(img_dist, **kwargs)\n",
    "\n",
    "        d = self.distance(outputs, outputs_dist)\n",
    "        d_0 = self.distance(c0, c0_dist)\n",
    "        d_1 = self.distance(c1, c1_dist)\n",
    "        d_2 = self.distance(c2, c2_dist)\n",
    "\n",
    "        dist = d*self.coefs[0] + d_0*self.coefs[1] + d_1*self.coefs[2] + d_2*self.coefs[3]\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def distance(img, img_dist):\n",
    "        diff = rearrange(img-img_dist, \"b h w c -> b (h w c)\")\n",
    "        return optax.safe_norm(diff, min_norm=0., ord=2, axis=1)\n",
    "    \n",
    "    def encode(self, img, **kwargs):\n",
    "        return self.perceptnet(img, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the metrics with `clu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    \"\"\"Collection of metrics to be tracked during training.\"\"\"\n",
    "    loss: metrics.Average.from_output(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `TrainState` doesn't include metrics, but it's very easy to subclass it so that it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "    state: FrozenDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a function that initializes the `TrainState` from a module, a rng key and some optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, key, tx, input_shape):\n",
    "    \"\"\"Creates the initial `TrainState`.\"\"\"\n",
    "    variables = module.init(key, jnp.ones(input_shape), jnp.ones(input_shape))\n",
    "    state, params = variables.pop('params')\n",
    "    return TrainState.create(\n",
    "        apply_fn=module.apply,\n",
    "        params=params,\n",
    "        state=state,\n",
    "        tx=tx,\n",
    "        metrics=Metrics.empty()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_distance(*, state, batch):\n",
    "    \"\"\"Obtaining the metrics for a given batch.\"\"\"\n",
    "    img, img_dist, mos = batch\n",
    "    \n",
    "    ## Forward pass through the model\n",
    "    dist = state.apply_fn({\"params\": state.params, **state.state}, img, img_dist, train=False)\n",
    "    # img_dist_pred = state.apply_fn({\"params\": state.params, **state.state}, img_dist, train=False)\n",
    "\n",
    "    ## Calculate the distance\n",
    "    # dist = ((img_pred - img_dist_pred)**2).sum(axis=(1,2,3))**(1/2)\n",
    "    \n",
    "    ## Calculate pearson correlation\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'TypeError'>",
     "evalue": "__call__() missing 1 required positional argument: 'img_dist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_train_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPRNGKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m, in \u001b[0;36mcreate_train_state\u001b[0;34m(module, key, tx, input_shape)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_train_state\u001b[39m(module, key, tx, input_shape):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\"Creates the initial `TrainState`.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     variables \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     state, params \u001b[38;5;241m=\u001b[39m variables\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TrainState\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      6\u001b[0m         apply_fn\u001b[38;5;241m=\u001b[39mmodule\u001b[38;5;241m.\u001b[39mapply,\n\u001b[1;32m      7\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         metrics\u001b[38;5;241m=\u001b[39mMetrics\u001b[38;5;241m.\u001b[39mempty()\n\u001b[1;32m     11\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/flax/linen/module.py:860\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m--> 860\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    862\u001b[0m   y \u001b[38;5;241m=\u001b[39m fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'img_dist'"
     ]
    }
   ],
   "source": [
    "state = create_train_state(Model(), random.PRNGKey(config.SEED), optax.adam(config.LEARNING_RATE), input_shape=(1,384,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trainable(path):\n",
    "    if not config.A_GDNSPATIOFREQORIENT:\n",
    "        if (\"GDNSpatioFreqOrient_0\" in path) and (\"A\" in path):\n",
    "            return True\n",
    "    if \"Color\" in path:\n",
    "        if not config.TRAIN_JH:\n",
    "            return True\n",
    "    if \"CenterSurroundLogSigmaK_0\" in path:\n",
    "        if not config.TRAIN_CS:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainable_tree \u001b[38;5;241m=\u001b[39m freeze(flax\u001b[38;5;241m.\u001b[39mtraverse_util\u001b[38;5;241m.\u001b[39mpath_aware_map(\u001b[38;5;28;01mlambda\u001b[39;00m path, v: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon_trainable\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_trainable(path)  \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mstate\u001b[49m\u001b[38;5;241m.\u001b[39mparams))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "trainable_tree = freeze(flax.traverse_util.path_aware_map(lambda path, v: \"non_trainable\" if check_trainable(path)  else \"trainable\", state.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1849, 1849)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(state.params))\n",
    "trainable_param_count = sum([w.size if t==\"trainable\" else 0 for w, t in zip(jax.tree_util.tree_leaves(state.params), jax.tree_util.tree_leaves(trainable_tree))])\n",
    "param_count, trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'param_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39msummary[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mparam_count\u001b[49m\n\u001b[1;32m      2\u001b[0m wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39msummary[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainable_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m trainable_param_count\n",
      "\u001b[0;31mNameError\u001b[0m: name 'param_count' is not defined"
     ]
    }
   ],
   "source": [
    "wandb.run.summary[\"total_parameters\"] = param_count\n",
    "wandb.run.summary[\"trainable_parameters\"] = trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    \"trainable\": optax.adam(learning_rate=config.LEARNING_RATE),\n",
    "    \"non_trainable\": optax.set_to_zero(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'trainable_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tx \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mmulti_transform(optimizers, \u001b[43mtrainable_tree\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainable_tree' is not defined"
     ]
    }
   ],
   "source": [
    "tx = optax.multi_transform(optimizers, trainable_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'tx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state \u001b[38;5;241m=\u001b[39m create_train_state(Model(), random\u001b[38;5;241m.\u001b[39mPRNGKey(config\u001b[38;5;241m.\u001b[39mSEED), \u001b[43mtx\u001b[49m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m384\u001b[39m,\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tx' is not defined"
     ]
    }
   ],
   "source": [
    "state = create_train_state(Model(), random.PRNGKey(config.SEED), tx, input_shape=(1,384,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Before actually training the model we're going to set up the checkpointer to be able to save our trained models:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m orbax_checkpointer \u001b[38;5;241m=\u001b[39m orbax\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mPyTreeCheckpointer()\n\u001b[0;32m----> 3\u001b[0m save_args \u001b[38;5;241m=\u001b[39m orbax_utils\u001b[38;5;241m.\u001b[39msave_args_from_target(\u001b[43mstate\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "# Before actually training the model we're going to set up the checkpointer to be able to save our trained models:\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load weights\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m state \u001b[38;5;241m=\u001b[39m orbax_checkpointer\u001b[38;5;241m.\u001b[39mrestore(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(prev_run\u001b[38;5;241m.\u001b[39mdir,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel-best\u001b[39m\u001b[38;5;124m\"\u001b[39m), item\u001b[38;5;241m=\u001b[39m\u001b[43mstate\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "state = orbax_checkpointer.restore(os.path.join(prev_run.dir,\"model-best\"), item=state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    \"distance\": [],\n",
    "    \"mos\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 39.8 s, total: 1min 49s\n",
      "Wall time: 1min 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]\r",
      "1it [00:08,  8.87s/it]\r",
      "4it [00:08,  1.71s/it]\r",
      "7it [00:09,  1.23it/s]\r",
      "10it [00:09,  2.00it/s]\r",
      "12it [00:09,  2.29it/s]\r",
      "14it [00:10,  2.52it/s]\r",
      "15it [00:10,  2.66it/s]\r",
      "16it [00:11,  2.71it/s]\r",
      "17it [00:11,  2.82it/s]\r",
      "18it [00:11,  2.87it/s]\r",
      "19it [00:12,  2.95it/s]\r",
      "20it [00:12,  3.05it/s]\r",
      "21it [00:12,  3.23it/s]\r",
      "22it [00:12,  3.37it/s]\r",
      "23it [00:13,  3.58it/s]\r",
      "24it [00:13,  3.79it/s]\r",
      "25it [00:13,  3.83it/s]\r",
      "26it [00:13,  3.66it/s]\r",
      "27it [00:14,  3.41it/s]\r",
      "28it [00:14,  3.40it/s]\r",
      "29it [00:14,  3.25it/s]\r",
      "30it [00:15,  3.25it/s]\r",
      "31it [00:15,  3.31it/s]\r",
      "32it [00:15,  3.35it/s]\r",
      "33it [00:16,  3.37it/s]\r",
      "34it [00:16,  3.36it/s]\r",
      "35it [00:16,  3.31it/s]\r",
      "36it [00:17,  3.23it/s]\r",
      "37it [00:17,  3.35it/s]\r",
      "38it [00:17,  3.34it/s]\r",
      "39it [00:17,  3.26it/s]\r",
      "40it [00:18,  3.21it/s]\r",
      "41it [00:18,  3.09it/s]\r",
      "42it [00:18,  3.21it/s]\r",
      "43it [00:19,  3.12it/s]\r",
      "44it [00:19,  3.12it/s]\r",
      "45it [00:19,  3.10it/s]\r",
      "46it [00:20,  3.20it/s]\r",
      "47it [00:20,  3.03it/s]\r",
      "48it [00:20,  2.98it/s]\r",
      "49it [00:21,  3.10it/s]\r",
      "50it [00:21,  3.19it/s]\r",
      "51it [00:21,  3.43it/s]\r",
      "52it [00:21,  3.63it/s]\r",
      "53it [00:22,  3.82it/s]\r",
      "54it [00:22,  3.96it/s]\r",
      "55it [00:22,  4.09it/s]\r",
      "56it [00:22,  4.11it/s]\r",
      "57it [00:23,  4.21it/s]\r",
      "58it [00:23,  4.18it/s]\r",
      "59it [00:23,  4.30it/s]\r",
      "60it [00:23,  3.99it/s]\r",
      "61it [00:24,  3.83it/s]\r",
      "62it [00:24,  3.80it/s]\r",
      "63it [00:24,  3.69it/s]\r",
      "64it [00:25,  3.57it/s]\r",
      "65it [00:25,  3.42it/s]\r",
      "66it [00:25,  3.36it/s]\r",
      "67it [00:25,  3.23it/s]\r",
      "68it [00:26,  3.23it/s]\r",
      "69it [00:26,  3.14it/s]\r",
      "70it [00:26,  3.12it/s]\r",
      "71it [00:27,  3.26it/s]\r",
      "72it [00:27,  3.29it/s]\r",
      "73it [00:27,  3.29it/s]\r",
      "74it [00:28,  3.18it/s]\r",
      "75it [00:28,  3.16it/s]\r",
      "76it [00:28,  2.96it/s]\r",
      "77it [00:29,  2.96it/s]\r",
      "78it [00:29,  2.98it/s]\r",
      "79it [00:29,  2.97it/s]\r",
      "80it [00:30,  2.94it/s]\r",
      "81it [00:30,  3.09it/s]\r",
      "82it [00:30,  3.07it/s]\r",
      "83it [00:31,  3.07it/s]\r",
      "84it [00:31,  3.17it/s]\r",
      "85it [00:31,  3.11it/s]\r",
      "86it [00:32,  3.24it/s]\r",
      "87it [00:32,  3.12it/s]\r",
      "88it [00:32,  3.26it/s]\r",
      "89it [00:33,  3.23it/s]\r",
      "90it [00:33,  3.29it/s]\r",
      "91it [00:33,  3.41it/s]\r",
      "92it [00:33,  3.48it/s]\r",
      "93it [00:34,  3.63it/s]\r",
      "94it [00:34,  3.63it/s]\r",
      "95it [00:34,  3.83it/s]\r",
      "96it [00:34,  3.76it/s]\r",
      "97it [00:35,  3.78it/s]\r",
      "98it [00:35,  3.55it/s]\r",
      "99it [00:35,  3.44it/s]\r",
      "100it [00:36,  3.37it/s]\r",
      "101it [00:36,  3.30it/s]\r",
      "102it [00:36,  3.22it/s]\r",
      "103it [00:37,  3.09it/s]\r",
      "104it [00:37,  3.05it/s]\r",
      "105it [00:37,  2.92it/s]\r",
      "106it [00:38,  3.16it/s]\r",
      "107it [00:38,  3.13it/s]\r",
      "108it [00:38,  3.05it/s]\r",
      "109it [00:39,  3.11it/s]\r",
      "110it [00:39,  3.15it/s]\r",
      "111it [00:39,  3.22it/s]\r",
      "112it [00:39,  3.16it/s]\r",
      "113it [00:40,  3.40it/s]\r",
      "114it [00:40,  3.56it/s]\r",
      "115it [00:40,  3.74it/s]\r",
      "116it [00:40,  3.81it/s]\r",
      "117it [00:41,  3.91it/s]\r",
      "118it [00:41,  3.54it/s]\r",
      "119it [00:41,  3.24it/s]\r",
      "120it [00:42,  3.25it/s]\r",
      "121it [00:42,  3.49it/s]\r",
      "122it [00:42,  3.43it/s]\r",
      "123it [00:43,  3.29it/s]\r",
      "124it [00:43,  3.31it/s]\r",
      "125it [00:43,  3.24it/s]\r",
      "126it [00:44,  3.25it/s]\r",
      "127it [00:44,  3.27it/s]\r",
      "128it [00:44,  3.51it/s]\r",
      "129it [00:44,  3.29it/s]\r",
      "130it [00:45,  3.53it/s]\r",
      "131it [00:45,  3.66it/s]\r",
      "132it [00:45,  3.76it/s]\r",
      "133it [00:45,  3.86it/s]\r",
      "134it [00:46,  3.99it/s]\r",
      "135it [00:46,  4.01it/s]\r",
      "136it [00:46,  3.64it/s]\r",
      "137it [00:46,  3.93it/s]\r",
      "138it [00:47,  4.16it/s]\r",
      "139it [00:47,  4.22it/s]\r",
      "140it [00:47,  3.81it/s]\r",
      "141it [00:47,  3.53it/s]\r",
      "142it [00:48,  3.46it/s]\r",
      "143it [00:48,  3.44it/s]\r",
      "144it [00:48,  3.54it/s]\r",
      "145it [00:49,  3.73it/s]\r",
      "146it [00:49,  3.53it/s]\r",
      "147it [00:49,  3.75it/s]\r",
      "148it [00:49,  3.87it/s]\r",
      "149it [00:50,  3.62it/s]\r",
      "150it [00:50,  3.64it/s]\r",
      "151it [00:50,  3.65it/s]\r",
      "152it [00:50,  3.66it/s]\r",
      "153it [00:51,  3.83it/s]\r",
      "154it [00:51,  3.61it/s]\r",
      "155it [00:51,  3.75it/s]\r",
      "156it [00:51,  4.09it/s]\r",
      "157it [00:52,  3.71it/s]\r",
      "158it [00:52,  3.59it/s]\r",
      "159it [00:52,  3.43it/s]\r",
      "160it [00:53,  3.26it/s]\r",
      "161it [00:53,  3.16it/s]\r",
      "162it [00:53,  3.20it/s]\r",
      "163it [00:54,  3.14it/s]\r",
      "164it [00:54,  3.16it/s]\r",
      "165it [00:54,  3.18it/s]\r",
      "166it [00:55,  3.10it/s]\r",
      "167it [00:55,  3.21it/s]\r",
      "168it [00:55,  3.31it/s]\r",
      "169it [00:56,  3.32it/s]\r",
      "170it [00:56,  3.27it/s]\r",
      "171it [00:56,  3.31it/s]\r",
      "172it [00:56,  3.34it/s]\r",
      "173it [00:57,  3.43it/s]\r",
      "174it [00:57,  3.21it/s]\r",
      "175it [00:57,  3.48it/s]\r",
      "176it [00:58,  3.27it/s]\r",
      "177it [00:58,  3.17it/s]\r",
      "178it [00:58,  3.28it/s]\r",
      "179it [00:59,  3.30it/s]\r",
      "180it [00:59,  3.37it/s]\r",
      "181it [00:59,  3.34it/s]\r",
      "182it [00:59,  3.33it/s]\r",
      "183it [01:00,  3.31it/s]\r",
      "184it [01:00,  3.27it/s]\r",
      "185it [01:00,  3.33it/s]\r",
      "186it [01:01,  3.50it/s]\r",
      "187it [01:01,  3.61it/s]\r",
      "188it [01:01,  3.71it/s]\r",
      "189it [01:01,  3.80it/s]\r",
      "190it [01:02,  3.82it/s]\r",
      "191it [01:02,  3.72it/s]\r",
      "192it [01:02,  3.84it/s]\r",
      "193it [01:02,  3.80it/s]\r",
      "194it [01:03,  3.74it/s]\r",
      "195it [01:03,  3.57it/s]\r",
      "196it [01:03,  3.51it/s]\r",
      "197it [01:04,  3.38it/s]\r",
      "198it [01:04,  3.39it/s]\r",
      "199it [01:04,  3.30it/s]\r",
      "200it [01:05,  3.31it/s]\r",
      "201it [01:05,  3.20it/s]\r",
      "202it [01:05,  3.18it/s]\r",
      "203it [01:06,  3.24it/s]\r",
      "204it [01:06,  3.18it/s]\r",
      "205it [01:06,  3.10it/s]\r",
      "206it [01:07,  3.05it/s]\r",
      "207it [01:07,  3.10it/s]\r",
      "208it [01:07,  3.08it/s]\r",
      "209it [01:07,  3.17it/s]\r",
      "210it [01:08,  3.13it/s]\r",
      "211it [01:08,  3.11it/s]\r",
      "212it [01:08,  3.27it/s]\r",
      "213it [01:09,  3.12it/s]\r",
      "214it [01:09,  3.25it/s]\r",
      "215it [01:09,  3.15it/s]\r",
      "216it [01:10,  3.23it/s]\r",
      "217it [01:10,  3.21it/s]\r",
      "218it [01:10,  3.28it/s]\r",
      "219it [01:11,  3.34it/s]\r",
      "220it [01:11,  3.37it/s]\r",
      "221it [01:11,  3.22it/s]\r",
      "222it [01:11,  3.29it/s]\r",
      "223it [01:12,  3.40it/s]\r",
      "224it [01:12,  3.35it/s]\r",
      "225it [01:12,  3.55it/s]\r",
      "226it [01:13,  3.69it/s]\r",
      "227it [01:13,  3.54it/s]\r",
      "228it [01:13,  3.42it/s]\r",
      "229it [01:13,  3.32it/s]\r",
      "230it [01:14,  3.29it/s]\r",
      "231it [01:14,  3.34it/s]\r",
      "232it [01:14,  3.22it/s]\r",
      "233it [01:15,  3.15it/s]\r",
      "234it [01:15,  3.24it/s]\r",
      "235it [01:15,  3.26it/s]\r",
      "236it [01:16,  3.27it/s]\r",
      "237it [01:16,  3.45it/s]\r",
      "238it [01:16,  3.67it/s]\r",
      "239it [01:16,  3.78it/s]\r",
      "240it [01:17,  3.96it/s]\r",
      "241it [01:17,  4.03it/s]\r",
      "242it [01:17,  4.16it/s]\r",
      "243it [01:17,  4.23it/s]\r",
      "244it [01:18,  4.29it/s]\r",
      "245it [01:18,  4.35it/s]\r",
      "246it [01:18,  4.20it/s]\r",
      "247it [01:18,  4.17it/s]\r",
      "248it [01:18,  4.13it/s]\r",
      "249it [01:19,  4.11it/s]\r",
      "250it [01:19,  4.08it/s]\r",
      "251it [01:19,  4.10it/s]\r",
      "252it [01:20,  3.67it/s]\r",
      "253it [01:20,  3.60it/s]\r",
      "254it [01:20,  3.64it/s]\r",
      "255it [01:20,  3.50it/s]\r",
      "256it [01:21,  3.48it/s]\r",
      "257it [01:21,  3.51it/s]\r",
      "258it [01:21,  3.50it/s]\r",
      "259it [01:22,  3.20it/s]\r",
      "260it [01:22,  3.23it/s]\r",
      "261it [01:22,  3.20it/s]\r",
      "262it [01:23,  3.32it/s]\r",
      "263it [01:23,  3.30it/s]\r",
      "264it [01:23,  3.17it/s]\r",
      "265it [01:24,  3.14it/s]\r",
      "266it [01:24,  3.03it/s]\r",
      "267it [01:24,  3.11it/s]\r",
      "268it [01:25,  3.09it/s]\r",
      "269it [01:25,  3.25it/s]\r",
      "270it [01:25,  3.38it/s]\r",
      "271it [01:25,  3.48it/s]\r",
      "272it [01:26,  3.56it/s]\r",
      "273it [01:26,  3.37it/s]\r",
      "274it [01:26,  3.44it/s]\r",
      "275it [01:27,  3.33it/s]\r",
      "276it [01:27,  3.52it/s]\r",
      "277it [01:27,  3.65it/s]\r",
      "278it [01:27,  3.81it/s]\r",
      "279it [01:28,  3.83it/s]\r",
      "280it [01:28,  3.76it/s]\r",
      "281it [01:28,  3.89it/s]\r",
      "282it [01:28,  4.12it/s]\r",
      "283it [01:28,  4.32it/s]\r",
      "284it [01:29,  4.27it/s]\r",
      "285it [01:29,  3.88it/s]\r",
      "286it [01:29,  3.73it/s]\r",
      "287it [01:30,  3.60it/s]\r",
      "288it [01:30,  3.41it/s]\r",
      "289it [01:30,  3.43it/s]\r",
      "290it [01:31,  3.28it/s]\r",
      "291it [01:31,  3.20it/s]\r",
      "292it [01:31,  3.17it/s]\r",
      "293it [01:32,  3.08it/s]\r",
      "294it [01:32,  3.14it/s]\r",
      "295it [01:32,  3.10it/s]\r",
      "296it [01:32,  3.50it/s]\r",
      "297it [01:33,  3.69it/s]\r",
      "298it [01:33,  3.89it/s]\r",
      "299it [01:33,  3.93it/s]\r",
      "300it [01:33,  4.06it/s]\r",
      "301it [01:34,  4.17it/s]\r",
      "302it [01:34,  4.18it/s]\r",
      "303it [01:34,  4.20it/s]\r",
      "304it [01:34,  4.00it/s]\r",
      "305it [01:35,  4.04it/s]\r",
      "306it [01:35,  3.97it/s]\r",
      "307it [01:35,  4.03it/s]\r",
      "308it [01:35,  4.06it/s]\r",
      "309it [01:36,  4.06it/s]\r",
      "310it [01:36,  4.11it/s]\r",
      "311it [01:36,  3.62it/s]\r",
      "312it [01:36,  3.38it/s]\r",
      "313it [01:37,  3.29it/s]\r",
      "314it [01:37,  3.17it/s]\r",
      "315it [01:37,  3.05it/s]\r",
      "316it [01:38,  3.02it/s]\r",
      "317it [01:38,  3.03it/s]\r",
      "318it [01:38,  2.99it/s]\r",
      "319it [01:39,  3.00it/s]\r",
      "320it [01:39,  3.15it/s]\r",
      "321it [01:39,  3.27it/s]\r",
      "322it [01:40,  3.29it/s]\r",
      "323it [01:40,  3.44it/s]\r",
      "324it [01:40,  3.38it/s]\r",
      "325it [01:41,  3.31it/s]\r",
      "326it [01:41,  3.26it/s]\r",
      "327it [01:41,  3.32it/s]\r",
      "328it [01:42,  3.20it/s]\r",
      "329it [01:42,  3.39it/s]\r",
      "330it [01:42,  3.61it/s]\r",
      "331it [01:42,  3.55it/s]\r",
      "332it [01:43,  3.72it/s]\r",
      "333it [01:43,  3.83it/s]\r",
      "334it [01:43,  3.96it/s]\r",
      "335it [01:43,  4.02it/s]\r",
      "336it [01:44,  3.65it/s]\r",
      "337it [01:44,  3.40it/s]\r",
      "338it [01:44,  3.24it/s]\r",
      "339it [01:45,  3.19it/s]\r",
      "340it [01:45,  3.19it/s]\r",
      "341it [01:45,  3.29it/s]\r",
      "342it [01:45,  3.28it/s]\r",
      "343it [01:46,  3.47it/s]\r",
      "344it [01:46,  3.39it/s]\r",
      "345it [01:46,  3.50it/s]\r",
      "346it [01:47,  3.53it/s]\r",
      "347it [01:47,  3.71it/s]\r",
      "348it [01:47,  3.53it/s]\r",
      "349it [01:47,  3.54it/s]\r",
      "350it [01:48,  3.48it/s]\r",
      "351it [01:48,  3.24it/s]\r",
      "352it [01:48,  3.51it/s]\r",
      "353it [01:49,  3.64it/s]\r",
      "354it [01:49,  3.44it/s]\r",
      "355it [01:49,  3.25it/s]\r",
      "356it [01:50,  3.28it/s]\r",
      "357it [01:50,  3.33it/s]\r",
      "358it [01:50,  3.37it/s]\r",
      "359it [01:50,  3.37it/s]\r",
      "360it [01:51,  3.58it/s]\r",
      "361it [01:51,  3.72it/s]\r",
      "362it [01:51,  3.76it/s]\r",
      "363it [01:56,  1.73s/it]\r",
      "363it [01:56,  3.11it/s]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for batch in tqdm(dst_rdy.as_numpy_iterator()):\n",
    "    img, img_dist, mos = batch\n",
    "    distance = compute_distance(state=state, batch=batch)\n",
    "    metrics_history[\"distance\"].extend(distance)\n",
    "    metrics_history[\"mos\"].extend(mos)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'AssertionError'>",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(metrics_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(dst\u001b[38;5;241m.\u001b[39mdata)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert len(metrics_history[\"distance\"]) == len(dst.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PearsonRResult(statistic=-0.5586493199527467, pvalue=0.0),\n",
       " SignificanceResult(statistic=-0.487503803953253, pvalue=0.0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(metrics_history[\"distance\"], metrics_history[\"mos\"]), stats.spearmanr(metrics_history[\"distance\"], metrics_history[\"mos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reference</th>\n",
       "      <th>Distorted</th>\n",
       "      <th>MOS</th>\n",
       "      <th>Directory</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001.bmp</td>\n",
       "      <td>A0001_00_00.bmp</td>\n",
       "      <td>1520.0648</td>\n",
       "      <td>Distortion_1</td>\n",
       "      <td>19.366316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0001.bmp</td>\n",
       "      <td>A0001_00_01.bmp</td>\n",
       "      <td>1437.0798</td>\n",
       "      <td>Distortion_1</td>\n",
       "      <td>26.88332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0001.bmp</td>\n",
       "      <td>A0001_00_02.bmp</td>\n",
       "      <td>1546.0616</td>\n",
       "      <td>Distortion_1</td>\n",
       "      <td>18.586107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0001.bmp</td>\n",
       "      <td>A0001_00_03.bmp</td>\n",
       "      <td>1539.5688</td>\n",
       "      <td>Distortion_1</td>\n",
       "      <td>22.950405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0001.bmp</td>\n",
       "      <td>A0001_00_04.bmp</td>\n",
       "      <td>1411.7958</td>\n",
       "      <td>Distortion_1</td>\n",
       "      <td>30.117554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reference        Distorted        MOS     Directory   Distance\n",
       "0  A0001.bmp  A0001_00_00.bmp  1520.0648  Distortion_1  19.366316\n",
       "1  A0001.bmp  A0001_00_01.bmp  1437.0798  Distortion_1   26.88332\n",
       "2  A0001.bmp  A0001_00_02.bmp  1546.0616  Distortion_1  18.586107\n",
       "3  A0001.bmp  A0001_00_03.bmp  1539.5688  Distortion_1  22.950405\n",
       "4  A0001.bmp  A0001_00_04.bmp  1411.7958  Distortion_1  30.117554"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = dst.data.copy()\n",
    "results[\"Distance\"] = metrics_history[\"distance\"]\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'ValueError'>",
     "evalue": "x and y must have length at least 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPIPAL\u001b[39m\u001b[38;5;124m\"\u001b[39m: wandb\u001b[38;5;241m.\u001b[39mTable(dataframe\u001b[38;5;241m=\u001b[39mresults),\n\u001b[0;32m----> 2\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPIPAL_pearson\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpearsonr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics_history\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_history\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      3\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPIPAL_spearman\u001b[39m\u001b[38;5;124m\"\u001b[39m: stats\u001b[38;5;241m.\u001b[39mspearmanr(metrics_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m], metrics_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmos\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      4\u001b[0m            })\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4411\u001b[0m, in \u001b[0;36mpearsonr\u001b[0;34m(x, y, alternative)\u001b[0m\n\u001b[1;32m   4408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx and y must have the same length.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   4410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 4411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx and y must have length at least 2.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   4413\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\n\u001b[1;32m   4414\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have length at least 2."
     ]
    }
   ],
   "source": [
    "wandb.log({\"PIPAL\": wandb.Table(dataframe=results),\n",
    "           \"PIPAL_pearson\": stats.pearsonr(metrics_history[\"distance\"], metrics_history[\"mos\"])[0],\n",
    "           \"PIPAL_spearman\": stats.spearmanr(metrics_history[\"distance\"], metrics_history[\"mos\"])[0],\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
