{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 15:16:13.886117: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 15:16:16.390409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lhome/ext/uv075/uv0752/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-04 15:16:23.110438: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "2023-12-04 15:16:23.111276: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:1: failed initializing StreamExecutor for CUDA device ordinal 1: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from typing import Any, Callable, Sequence, Union\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "import jax\n",
    "from jax import lax, random, numpy as jnp\n",
    "import flax\n",
    "from flax.core import freeze, unfreeze, FrozenDict\n",
    "from flax import linen as nn\n",
    "from flax import struct\n",
    "from flax.training import train_state\n",
    "from flax.training import orbax_utils\n",
    "\n",
    "import optax\n",
    "import orbax.checkpoint\n",
    "\n",
    "from clu import metrics\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "from einops import reduce, rearrange\n",
    "import wandb\n",
    "\n",
    "from iqadatasets.datasets import *\n",
    "from fxlayers.layers import *\n",
    "from fxlayers.layers import GaborLayerLogSigma_, GaussianLayerGamma, FreqGaussianGamma, OrientGaussianGamma\n",
    "from fxlayers.initializers import *\n",
    "from JaxPlayground.utils.constraints import *\n",
    "from JaxPlayground.utils.wandb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dst_train = TID2008(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2008/\", exclude_imgs=[25])\n",
    "# dst_val = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2013/\", exclude_imgs=[25])\n",
    "# dst_train = TID2008(\"/media/disk/databases/BBDD_video_image/Image_Quality//TID/TID2008/\", exclude_imgs=[25])\n",
    "# dst_val = TID2013(\"/media/disk/databases/BBDD_video_image/Image_Quality//TID/TID2013/\", exclude_imgs=[25])\n",
    "# dst = KADIK10K(\"/media/disk/databases/BBDD_video_image/Image_Quality/KADIK10K/\")\n",
    "# dst = PIPAL(\"/media/disk/databases/BBDD_video_image/Image_Quality/PIPAL/\")\n",
    "dst = KADIK10K(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/KADIK10K/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([384, 512, 3]), TensorShape([384, 512, 3]), TensorShape([]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, img_dist, mos = next(iter(dst.dataset))\n",
    "img.shape, img_dist.shape, mos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = \"6rhldh50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "prev_run = api.run(f\"jorgvt/PerceptNet_v15/{id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A_GABOR: true\n",
       "A_GDNSPATIOFREQORIENT: true\n",
       "BATCH_SIZE: 64\n",
       "CS_KERNEL_SIZE: 21\n",
       "EPOCHS: 500\n",
       "GABOR_KERNEL_SIZE: 31\n",
       "GDNGAUSSIAN_KERNEL_SIZE: 11\n",
       "GDN_CLIPPING: true\n",
       "INIT_JH: true\n",
       "LEARNING_RATE: 0.003\n",
       "NORMALIZE_ENERGY: true\n",
       "NORMALIZE_PROB: false\n",
       "N_GABORS: 128\n",
       "SEED: 42\n",
       "TRAIN_CS: true\n",
       "TRAIN_JH: true\n",
       "USE_BIAS: false\n",
       "USE_GAMMA: true\n",
       "ZERO_MEAN: true"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = ConfigDict(prev_run.config[\"_fields\"])\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in prev_run.files():\n",
    "    file.download(root=prev_run.dir, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: jorgvt. Use `wandb login --relogin` to force relogin\n",
      "wandb: wandb version 0.16.4 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "wandb: Tracking run with wandb version 0.15.1\n",
      "wandb: Run data is saved locally in /lhome/ext/uv075/uv0752/perceptnet/Notebooks/13_JaX/13_08_Skip/wandb/run-20240306_153720-71kayb9w\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run V19_128GaborFree_A_Skip\n",
      "wandb:  View project at https://wandb.ai/jorgvt/PerceptNet_JaX_Eval\n",
      "wandb:  View run at https://wandb.ai/jorgvt/PerceptNet_JaX_Eval/runs/71kayb9w\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "A_GABOR: true\n",
       "A_GDNSPATIOFREQORIENT: true\n",
       "BATCH_SIZE: 64\n",
       "CS_KERNEL_SIZE: 21\n",
       "EPOCHS: 500\n",
       "GABOR_KERNEL_SIZE: 31\n",
       "GDNGAUSSIAN_KERNEL_SIZE: 11\n",
       "GDN_CLIPPING: true\n",
       "INIT_JH: true\n",
       "LEARNING_RATE: 0.003\n",
       "NORMALIZE_ENERGY: true\n",
       "NORMALIZE_PROB: false\n",
       "N_GABORS: 128\n",
       "SEED: 42\n",
       "TRAIN_CS: true\n",
       "TRAIN_JH: true\n",
       "USE_BIAS: false\n",
       "USE_GAMMA: true\n",
       "ZERO_MEAN: true"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"PerceptNet_JaX_Eval\",\n",
    "           name=prev_run.name,\n",
    "           job_type=\"evaluate\",\n",
    "           mode=\"online\",\n",
    "           )\n",
    "config = config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_rdy = dst.dataset.batch(config.BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model we're going to use\n",
    "\n",
    "> It's going to be a very simple model just for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class FreqOrientGaussianGamma(nn.Module):\n",
    "    \"\"\"(1D) Gaussian interaction between frequencies and orientations optimizing gamma = 1/sigma instead of sigma.\"\"\"\n",
    "    use_bias: bool = False\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    bias_init: Callable = nn.initializers.zeros_init()\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 fmean,\n",
    "                 theta_mean,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        gamma_f = self.param(\"gamma_f\",\n",
    "                             k_array(1/0.4, arr=fmean),\n",
    "                             (inputs.shape[-1],))\n",
    "        gamma_theta = self.param(\"gamma_theta\",\n",
    "                                 equal_to(jnp.ones(shape=(len(theta_mean),)) * 20),\n",
    "                                 (inputs.shape[-1],))\n",
    "        if self.use_bias: bias = self.param(\"bias\",\n",
    "                                            self.bias_init,\n",
    "                                            (len(fmean),))\n",
    "        else: bias = 0.\n",
    "        # n_groups = inputs.shape[-1] // len(fmean)\n",
    "        kernel = jax.vmap(self.gaussian, in_axes=(None,None,0,0,0,0,None), out_axes=1)(fmean, theta_mean, fmean, theta_mean, gamma_f, gamma_theta, 1)\n",
    "        kernel = kernel[None,None,:,:]\n",
    "        # kernel = jnp.tile(kernel, reps=n_groups)\n",
    "\n",
    "        ## Add the batch dim if the input is a single element\n",
    "        if jnp.ndim(inputs) < 4: inputs = inputs[None,:]; had_batch = False\n",
    "        else: had_batch = True\n",
    "        outputs = lax.conv_general_dilated(\n",
    "                jnp.transpose(inputs,[0,3,1,2]),    # lhs = NCHW image tensor\n",
    "                jnp.transpose(kernel,[3,2,0,1]), # rhs = OIHW conv kernel tensor\n",
    "                (self.strides, self.strides),\n",
    "                self.padding)\n",
    "        ## Move the channels back to the last dim\n",
    "        outputs = jnp.transpose(outputs, (0,2,3,1))\n",
    "        if not had_batch: outputs = outputs[0]\n",
    "        return outputs + bias\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian(f, theta, fmean, theta_mean, gamma_f, gamma_theta, A=1):\n",
    "        return A*jnp.exp(-((gamma_f**2)*(f-fmean)**2)/(2))*jnp.exp(-((gamma_theta**2)*(theta-theta_mean)**2)/(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDNSpatioFreqOrient(nn.Module):\n",
    "    \"\"\"Generalized Divisive Normalization.\"\"\"\n",
    "    kernel_size: Union[int, Sequence[int]]\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    # inputs_star: float = 1.\n",
    "    # outputs_star: Union[None, float] = None\n",
    "    fs: int = 1\n",
    "    apply_independently: bool = False\n",
    "    bias_init: Callable = nn.initializers.ones_init()\n",
    "    alpha: float = 2.\n",
    "    epsilon: float = 1/2 # Exponential of the denominator\n",
    "    eps: float = 1e-6 # Numerical stability in the denominator\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 fmean,\n",
    "                 theta_mean,\n",
    "                 train=False,\n",
    "                 ):\n",
    "        b, h, w, c = inputs.shape\n",
    "        bias = self.param(\"bias\",\n",
    "                          #equal_to(inputs_star/10),\n",
    "                          self.bias_init,\n",
    "                          (c,))\n",
    "        # is_initialized = self.has_variable(\"batch_stats\", \"inputs_star\")\n",
    "        # inputs_star = self.variable(\"batch_stats\", \"inputs_star\", lambda x: jnp.ones(x)*self.inputs_star, (len(self.inputs_star),))\n",
    "        # inputs_star_ = jnp.ones_like(inputs)*inputs_star.value\n",
    "        GL = GaussianLayerGamma(features=c, kernel_size=self.kernel_size, strides=self.strides, padding=\"VALID\", fs=self.fs, xmean=self.kernel_size/self.fs/2, ymean=self.kernel_size/self.fs/2, normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY, use_bias=False, feature_group_count=c)\n",
    "        FOG = FreqOrientGaussianGamma()\n",
    "        outputs = GL(pad_same_from_kernel_size(inputs, kernel_size=self.kernel_size, mode=self.padding)**self.alpha, train=train)#/(self.kernel_size**2)\n",
    "        outputs = FOG(outputs, fmean=fmean, theta_mean=theta_mean)\n",
    "\n",
    "        ## Coef\n",
    "        # coef = GL(inputs_star_**self.alpha, train=train)#/(self.kernel_size**2)\n",
    "        # coef = FG(coef, fmean=fmean)\n",
    "        # coef = rearrange(coef, \"b h w (phase theta f) -> b h w (phase f theta)\", b=b, h=h, w=w, phase=2, f=config.N_SCALES, theta=config.N_ORIENTATIONS)\n",
    "        # coef = OG(coef, theta_mean=theta_mean) + bias\n",
    "        # coef = rearrange(coef, \"b h w (phase f theta) -> b h w (phase theta f)\", b=b, h=h, w=w, phase=2, f=config.N_SCALES, theta=config.N_ORIENTATIONS)\n",
    "        # coef = jnp.clip(coef+bias, a_min=1e-5)**self.epsilon\n",
    "        # # coef = inputs_star.value * coef\n",
    "        # if self.outputs_star is not None: coef = coef/inputs_star.value*self.outputs_star\n",
    "\n",
    "        # if is_initialized and train:\n",
    "        #     inputs_star.value = (inputs_star.value + jnp.quantile(jnp.abs(inputs), q=0.95, axis=(0,1,2)))/2\n",
    "        # return coef * inputs / (jnp.clip(denom+bias, a_min=1e-5)**self.epsilon + self.eps)\n",
    "        return inputs / (jnp.clip(outputs+bias, a_min=1e-5)**self.epsilon + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNet(nn.Module):\n",
    "    \"\"\"IQA model inspired by the visual system.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs, # Assuming fs = 128 (cpd)\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        ## (Independent) Color equilibration (Gamma correction)\n",
    "        ## Might need to be the same for each number\n",
    "        ## bias = 0.1 / kernel = 0.5\n",
    "        if config.USE_GAMMA: outputs, c0 = GDNGamma(return_coef=True)(inputs)\n",
    "        else: outputs, c0 = GDN(kernel_size=(1,1), apply_independently=True, return_coef=True)(inputs)        \n",
    "        \n",
    "        ## Color (ATD) Transformation\n",
    "        outputs = nn.Conv(features=3, kernel_size=(1,1), use_bias=False, name=\"Color\")(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        \n",
    "        ## GDN Star A - T - D [Separated]\n",
    "        outputs, c1 = GDN(kernel_size=(1,1), apply_independently=True, return_coef=True)(outputs)\n",
    "\n",
    "        ## Center Surround (DoG)\n",
    "        ## Initialized so that 3 are positives and 3 are negatives and no interaction between channels is present\n",
    "        outputs = pad_same_from_kernel_size(outputs, kernel_size=config.CS_KERNEL_SIZE, mode=\"symmetric\")\n",
    "        outputs = CenterSurroundLogSigmaK(features=3, kernel_size=config.CS_KERNEL_SIZE, fs=21, use_bias=False, padding=\"VALID\")(outputs, **kwargs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "\n",
    "        ## GDN per channel with mean substraction in T and D (Spatial Gaussian Kernel)\n",
    "        ### fs = 32 / kernel_size = (11,11) -> 0.32 > 0.02 --> OK!\n",
    "        ## TO-DO: - Spatial Gaussian Kernel (0.02 deg) -> fs = 64/2 & 0.02*64/2 = sigma (px) = 0.69\n",
    "        outputs, c2 = GDNGaussian(kernel_size=config.GDNGAUSSIAN_KERNEL_SIZE, apply_independently=True, fs=32, padding=\"symmetric\", normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY, return_coef=True)(outputs, **kwargs)\n",
    "\n",
    "        ## GaborLayer per channel with GDN mixing only same-origin-channel information\n",
    "        ### [Gaussian] sigma = 0.2 (deg) fs = 32 / kernel_size = (21,21) -> 21/32 = 0.66 --> OK!\n",
    "        outputs = pad_same_from_kernel_size(outputs, kernel_size=config.GABOR_KERNEL_SIZE, mode=\"symmetric\")\n",
    "        outputs, fmean, theta_mean = GaborLayerGammaRepeat(features=config.N_GABORS, kernel_size=config.GABOR_KERNEL_SIZE, fs=32, xmean=config.GABOR_KERNEL_SIZE/32/2, ymean=config.GABOR_KERNEL_SIZE/32/2, strides=1, padding=\"VALID\", normalize_prob=config.NORMALIZE_PROB, normalize_energy=config.NORMALIZE_ENERGY, zero_mean=config.ZERO_MEAN, use_bias=config.USE_BIAS, train_A=config.A_GABOR)(outputs, return_freq=True, return_theta=True, **kwargs)\n",
    "        \n",
    "        ## Final GDN mixing Gabor information (?)\n",
    "        outputs = GDNSpatioFreqOrient(kernel_size=21, strides=1, padding=\"symmetric\", fs=32, apply_independently=False)(outputs, fmean=fmean, theta_mean=theta_mean, **kwargs)\n",
    "\n",
    "        return outputs, c0, c1, c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def setup(self):\n",
    "        self.perceptnet = PerceptNet()\n",
    "        self.coefs = self.param(\"coefs\",\n",
    "                           nn.initializers.ones_init(),\n",
    "                           (4,))\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 img,\n",
    "                 img_dist,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        \n",
    "\n",
    "        outputs, c0, c1, c2 = self.perceptnet(img, **kwargs)\n",
    "        outputs_dist, c0_dist, c1_dist, c2_dist = self.perceptnet(img_dist, **kwargs)\n",
    "\n",
    "        d = self.distance(outputs, outputs_dist)\n",
    "        d_0 = self.distance(c0, c0_dist)\n",
    "        d_1 = self.distance(c1, c1_dist)\n",
    "        d_2 = self.distance(c2, c2_dist)\n",
    "\n",
    "        dist = d*self.coefs[0] + d_0*self.coefs[1] + d_1*self.coefs[2] + d_2*self.coefs[3]\n",
    "        return dist\n",
    "\n",
    "    @staticmethod\n",
    "    def distance(img, img_dist):\n",
    "        diff = rearrange(img-img_dist, \"b h w c -> b (h w c)\")\n",
    "        return optax.safe_norm(diff, min_norm=0., ord=2, axis=1)\n",
    "    \n",
    "    def encode(self, img, **kwargs):\n",
    "        return self.perceptnet(img, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the metrics with `clu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    \"\"\"Collection of metrics to be tracked during training.\"\"\"\n",
    "    loss: metrics.Average.from_output(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `TrainState` doesn't include metrics, but it's very easy to subclass it so that it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "    state: FrozenDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a function that initializes the `TrainState` from a module, a rng key and some optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, key, tx, input_shape):\n",
    "    \"\"\"Creates the initial `TrainState`.\"\"\"\n",
    "    variables = module.init(key, jnp.ones(input_shape), jnp.ones(input_shape))\n",
    "    state, params = variables.pop('params')\n",
    "    return TrainState.create(\n",
    "        apply_fn=module.apply,\n",
    "        params=params,\n",
    "        state=state,\n",
    "        tx=tx,\n",
    "        metrics=Metrics.empty()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_distance(*, state, batch):\n",
    "    \"\"\"Obtaining the metrics for a given batch.\"\"\"\n",
    "    img, img_dist, mos = batch\n",
    "    \n",
    "    ## Forward pass through the model\n",
    "    dist = state.apply_fn({\"params\": state.params, **state.state}, img, img_dist, train=False)\n",
    "    # img_dist_pred = state.apply_fn({\"params\": state.params, **state.state}, img_dist, train=False)\n",
    "\n",
    "    ## Calculate the distance\n",
    "    # dist = ((img_pred - img_dist_pred)**2).sum(axis=(1,2,3))**(1/2)\n",
    "    \n",
    "    ## Calculate pearson correlation\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'TypeError'>",
     "evalue": "__call__() missing 1 required positional argument: 'img_dist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_train_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPRNGKey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m, in \u001b[0;36mcreate_train_state\u001b[0;34m(module, key, tx, input_shape)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_train_state\u001b[39m(module, key, tx, input_shape):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\"Creates the initial `TrainState`.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     variables \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     state, params \u001b[38;5;241m=\u001b[39m variables\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TrainState\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      6\u001b[0m         apply_fn\u001b[38;5;241m=\u001b[39mmodule\u001b[38;5;241m.\u001b[39mapply,\n\u001b[1;32m      7\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         metrics\u001b[38;5;241m=\u001b[39mMetrics\u001b[38;5;241m.\u001b[39mempty()\n\u001b[1;32m     11\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/flax/linen/module.py:860\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m--> 860\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    862\u001b[0m   y \u001b[38;5;241m=\u001b[39m fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'img_dist'"
     ]
    }
   ],
   "source": [
    "state = create_train_state(Model(), random.PRNGKey(config.SEED), optax.adam(config.LEARNING_RATE), input_shape=(1,384,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trainable(path):\n",
    "    if not config.A_GDNSPATIOFREQORIENT:\n",
    "        if (\"GDNSpatioFreqOrient_0\" in path) and (\"A\" in path):\n",
    "            return True\n",
    "    if \"Color\" in path:\n",
    "        if not config.TRAIN_JH:\n",
    "            return True\n",
    "    if \"CenterSurroundLogSigmaK_0\" in path:\n",
    "        if not config.TRAIN_CS:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainable_tree \u001b[38;5;241m=\u001b[39m freeze(flax\u001b[38;5;241m.\u001b[39mtraverse_util\u001b[38;5;241m.\u001b[39mpath_aware_map(\u001b[38;5;28;01mlambda\u001b[39;00m path, v: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon_trainable\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_trainable(path)  \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mstate\u001b[49m\u001b[38;5;241m.\u001b[39mparams))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "trainable_tree = freeze(flax.traverse_util.path_aware_map(lambda path, v: \"non_trainable\" if check_trainable(path)  else \"trainable\", state.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1849, 1849)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(state.params))\n",
    "trainable_param_count = sum([w.size if t==\"trainable\" else 0 for w, t in zip(jax.tree_util.tree_leaves(state.params), jax.tree_util.tree_leaves(trainable_tree))])\n",
    "param_count, trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'param_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39msummary[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mparam_count\u001b[49m\n\u001b[1;32m      2\u001b[0m wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39msummary[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainable_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m trainable_param_count\n",
      "\u001b[0;31mNameError\u001b[0m: name 'param_count' is not defined"
     ]
    }
   ],
   "source": [
    "wandb.run.summary[\"total_parameters\"] = param_count\n",
    "wandb.run.summary[\"trainable_parameters\"] = trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    \"trainable\": optax.adam(learning_rate=config.LEARNING_RATE),\n",
    "    \"non_trainable\": optax.set_to_zero(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'trainable_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tx \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mmulti_transform(optimizers, \u001b[43mtrainable_tree\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainable_tree' is not defined"
     ]
    }
   ],
   "source": [
    "tx = optax.multi_transform(optimizers, trainable_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'tx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m state \u001b[38;5;241m=\u001b[39m create_train_state(Model(), random\u001b[38;5;241m.\u001b[39mPRNGKey(config\u001b[38;5;241m.\u001b[39mSEED), \u001b[43mtx\u001b[49m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m384\u001b[39m,\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tx' is not defined"
     ]
    }
   ],
   "source": [
    "state = create_train_state(Model(), random.PRNGKey(config.SEED), tx, input_shape=(1,384,512,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Before actually training the model we're going to set up the checkpointer to be able to save our trained models:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m orbax_checkpointer \u001b[38;5;241m=\u001b[39m orbax\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mPyTreeCheckpointer()\n\u001b[0;32m----> 3\u001b[0m save_args \u001b[38;5;241m=\u001b[39m orbax_utils\u001b[38;5;241m.\u001b[39msave_args_from_target(\u001b[43mstate\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "# Before actually training the model we're going to set up the checkpointer to be able to save our trained models:\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load weights\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m state \u001b[38;5;241m=\u001b[39m orbax_checkpointer\u001b[38;5;241m.\u001b[39mrestore(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(prev_run\u001b[38;5;241m.\u001b[39mdir,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel-best\u001b[39m\u001b[38;5;124m\"\u001b[39m), item\u001b[38;5;241m=\u001b[39m\u001b[43mstate\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "state = orbax_checkpointer.restore(os.path.join(prev_run.dir,\"model-best\"), item=state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    \"distance\": [],\n",
    "    \"mos\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 25s, sys: 29.4 s, total: 2min 55s\n",
      "Wall time: 46 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]\r",
      "1it [00:16, 16.99s/it]\r",
      "3it [00:17,  4.48s/it]\r",
      "5it [00:17,  2.25s/it]\r",
      "6it [00:17,  1.69s/it]\r",
      "7it [00:17,  1.26s/it]\r",
      "8it [00:17,  1.06it/s]\r",
      "9it [00:18,  1.39it/s]\r",
      "10it [00:18,  1.81it/s]\r",
      "11it [00:18,  2.30it/s]\r",
      "12it [00:18,  2.85it/s]\r",
      "13it [00:18,  3.43it/s]\r",
      "14it [00:18,  4.00it/s]\r",
      "15it [00:19,  4.53it/s]\r",
      "16it [00:19,  5.01it/s]\r",
      "17it [00:19,  5.40it/s]\r",
      "18it [00:19,  5.71it/s]\r",
      "19it [00:19,  5.95it/s]\r",
      "20it [00:19,  6.14it/s]\r",
      "21it [00:19,  6.27it/s]\r",
      "22it [00:20,  6.36it/s]\r",
      "23it [00:20,  6.43it/s]\r",
      "24it [00:20,  6.49it/s]\r",
      "25it [00:20,  6.52it/s]\r",
      "26it [00:20,  6.55it/s]\r",
      "27it [00:20,  6.56it/s]\r",
      "28it [00:20,  6.57it/s]\r",
      "29it [00:21,  6.58it/s]\r",
      "30it [00:21,  6.59it/s]\r",
      "31it [00:21,  6.59it/s]\r",
      "32it [00:21,  6.59it/s]\r",
      "33it [00:21,  6.61it/s]\r",
      "34it [00:21,  6.61it/s]\r",
      "35it [00:22,  6.61it/s]\r",
      "36it [00:22,  6.61it/s]\r",
      "37it [00:22,  6.61it/s]\r",
      "38it [00:22,  6.61it/s]\r",
      "39it [00:22,  6.61it/s]\r",
      "40it [00:22,  6.60it/s]\r",
      "41it [00:22,  6.60it/s]\r",
      "42it [00:23,  6.60it/s]\r",
      "43it [00:23,  6.61it/s]\r",
      "44it [00:23,  6.60it/s]\r",
      "45it [00:23,  6.59it/s]\r",
      "46it [00:23,  6.60it/s]\r",
      "47it [00:23,  6.59it/s]\r",
      "48it [00:23,  6.59it/s]\r",
      "49it [00:24,  6.59it/s]\r",
      "50it [00:24,  6.60it/s]\r",
      "51it [00:24,  6.59it/s]\r",
      "52it [00:24,  6.58it/s]\r",
      "53it [00:24,  6.58it/s]\r",
      "54it [00:24,  6.58it/s]\r",
      "55it [00:25,  6.59it/s]\r",
      "56it [00:25,  6.59it/s]\r",
      "57it [00:25,  6.59it/s]\r",
      "58it [00:25,  6.58it/s]\r",
      "59it [00:25,  6.58it/s]\r",
      "60it [00:25,  6.58it/s]\r",
      "61it [00:25,  6.58it/s]\r",
      "62it [00:26,  6.58it/s]\r",
      "63it [00:26,  6.59it/s]\r",
      "64it [00:26,  6.58it/s]\r",
      "65it [00:26,  6.60it/s]\r",
      "66it [00:26,  6.59it/s]\r",
      "67it [00:26,  6.58it/s]\r",
      "68it [00:27,  6.59it/s]\r",
      "69it [00:27,  6.58it/s]\r",
      "70it [00:27,  6.58it/s]\r",
      "71it [00:27,  6.58it/s]\r",
      "72it [00:27,  6.58it/s]\r",
      "73it [00:27,  6.57it/s]\r",
      "74it [00:27,  6.58it/s]\r",
      "75it [00:28,  6.57it/s]\r",
      "76it [00:28,  6.57it/s]\r",
      "77it [00:28,  6.57it/s]\r",
      "78it [00:28,  6.57it/s]\r",
      "79it [00:28,  6.57it/s]\r",
      "80it [00:28,  6.57it/s]\r",
      "81it [00:29,  6.56it/s]\r",
      "82it [00:29,  6.59it/s]\r",
      "83it [00:29,  6.59it/s]\r",
      "84it [00:29,  6.58it/s]\r",
      "85it [00:29,  6.58it/s]\r",
      "86it [00:29,  6.58it/s]\r",
      "87it [00:29,  6.58it/s]\r",
      "88it [00:30,  6.58it/s]\r",
      "89it [00:30,  6.59it/s]\r",
      "90it [00:30,  6.59it/s]\r",
      "91it [00:30,  6.60it/s]\r",
      "92it [00:30,  6.60it/s]\r",
      "93it [00:30,  6.60it/s]\r",
      "94it [00:30,  6.60it/s]\r",
      "95it [00:31,  6.60it/s]\r",
      "96it [00:31,  6.60it/s]\r",
      "97it [00:31,  6.60it/s]\r",
      "98it [00:31,  6.60it/s]\r",
      "99it [00:31,  6.60it/s]\r",
      "100it [00:31,  6.60it/s]\r",
      "101it [00:32,  6.60it/s]\r",
      "102it [00:32,  6.60it/s]\r",
      "103it [00:32,  6.60it/s]\r",
      "104it [00:32,  6.58it/s]\r",
      "105it [00:32,  6.59it/s]\r",
      "106it [00:32,  6.59it/s]\r",
      "107it [00:32,  6.59it/s]\r",
      "108it [00:33,  6.59it/s]\r",
      "109it [00:33,  6.60it/s]\r",
      "110it [00:33,  6.60it/s]\r",
      "111it [00:33,  6.60it/s]\r",
      "112it [00:33,  6.60it/s]\r",
      "113it [00:33,  6.60it/s]\r",
      "114it [00:34,  6.60it/s]\r",
      "115it [00:34,  6.60it/s]\r",
      "116it [00:34,  6.61it/s]\r",
      "117it [00:34,  6.61it/s]\r",
      "118it [00:34,  6.61it/s]\r",
      "119it [00:34,  6.60it/s]\r",
      "120it [00:34,  6.60it/s]\r",
      "121it [00:35,  6.61it/s]\r",
      "122it [00:35,  6.59it/s]\r",
      "123it [00:35,  6.59it/s]\r",
      "124it [00:35,  6.59it/s]\r",
      "125it [00:35,  6.60it/s]\r",
      "126it [00:35,  6.60it/s]\r",
      "127it [00:35,  6.60it/s]\r",
      "128it [00:36,  6.60it/s]\r",
      "129it [00:36,  6.60it/s]\r",
      "130it [00:36,  6.60it/s]\r",
      "131it [00:36,  6.60it/s]\r",
      "132it [00:36,  6.60it/s]\r",
      "133it [00:36,  6.60it/s]\r",
      "134it [00:37,  6.59it/s]\r",
      "135it [00:37,  6.60it/s]\r",
      "136it [00:37,  6.60it/s]\r",
      "137it [00:37,  6.60it/s]\r",
      "138it [00:37,  6.60it/s]\r",
      "139it [00:37,  6.60it/s]\r",
      "140it [00:37,  6.60it/s]\r",
      "141it [00:38,  6.60it/s]\r",
      "142it [00:38,  6.60it/s]\r",
      "143it [00:38,  6.60it/s]\r",
      "144it [00:38,  6.61it/s]\r",
      "145it [00:38,  6.61it/s]\r",
      "146it [00:38,  6.60it/s]\r",
      "147it [00:39,  6.60it/s]\r",
      "148it [00:39,  6.60it/s]\r",
      "149it [00:39,  6.60it/s]\r",
      "150it [00:39,  6.60it/s]\r",
      "151it [00:39,  6.60it/s]\r",
      "152it [00:39,  6.61it/s]\r",
      "153it [00:39,  6.61it/s]\r",
      "154it [00:40,  6.60it/s]\r",
      "155it [00:40,  6.60it/s]\r",
      "156it [00:40,  6.60it/s]\r",
      "157it [00:40,  6.61it/s]\r",
      "158it [00:40,  6.61it/s]\r",
      "159it [00:45,  1.70s/it]\r",
      "159it [00:45,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for batch in tqdm(dst_rdy.as_numpy_iterator()):\n",
    "    img, img_dist, mos = batch\n",
    "    distance = compute_distance(state=state, batch=batch)\n",
    "    metrics_history[\"distance\"].extend(distance)\n",
    "    metrics_history[\"mos\"].extend(mos)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'AssertionError'>",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(metrics_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(dst\u001b[38;5;241m.\u001b[39mdata)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert len(metrics_history[\"distance\"]) == len(dst.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PearsonRResult(statistic=-0.742261050630256, pvalue=0.0),\n",
       " SignificanceResult(statistic=-0.7688789145600774, pvalue=0.0))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(metrics_history[\"distance\"], metrics_history[\"mos\"]), stats.spearmanr(metrics_history[\"distance\"], metrics_history[\"mos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_img</th>\n",
       "      <th>ref_img</th>\n",
       "      <th>dmos</th>\n",
       "      <th>var</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I01_01_01.png</td>\n",
       "      <td>I01.png</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I01_01_02.png</td>\n",
       "      <td>I01.png</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.869</td>\n",
       "      <td>24.313652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I01_01_03.png</td>\n",
       "      <td>I01.png</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.789</td>\n",
       "      <td>64.95095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I01_01_04.png</td>\n",
       "      <td>I01.png</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.596</td>\n",
       "      <td>117.90538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I01_01_05.png</td>\n",
       "      <td>I01.png</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.300</td>\n",
       "      <td>241.88913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dist_img  ref_img  dmos    var   Distance\n",
       "0  I01_01_01.png  I01.png  4.57  0.496        0.0\n",
       "1  I01_01_02.png  I01.png  4.33  0.869  24.313652\n",
       "2  I01_01_03.png  I01.png  2.67  0.789   64.95095\n",
       "3  I01_01_04.png  I01.png  1.67  0.596  117.90538\n",
       "4  I01_01_05.png  I01.png  1.10  0.300  241.88913"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = dst.data.copy()\n",
    "results[\"Distance\"] = metrics_history[\"distance\"]\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'ValueError'>",
     "evalue": "x and y must have length at least 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKADID10K\u001b[39m\u001b[38;5;124m\"\u001b[39m: wandb\u001b[38;5;241m.\u001b[39mTable(dataframe\u001b[38;5;241m=\u001b[39mresults),\n\u001b[0;32m----> 2\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKADID10K_pearson\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpearsonr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics_history\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_history\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      3\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKADID10K_spearman\u001b[39m\u001b[38;5;124m\"\u001b[39m: stats\u001b[38;5;241m.\u001b[39mspearmanr(metrics_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m], metrics_history[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmos\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m      4\u001b[0m            })\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4411\u001b[0m, in \u001b[0;36mpearsonr\u001b[0;34m(x, y, alternative)\u001b[0m\n\u001b[1;32m   4408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx and y must have the same length.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   4410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 4411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx and y must have length at least 2.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   4413\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\n\u001b[1;32m   4414\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have length at least 2."
     ]
    }
   ],
   "source": [
    "wandb.log({\"KADID10K\": wandb.Table(dataframe=results),\n",
    "           \"KADID10K_pearson\": stats.pearsonr(metrics_history[\"distance\"], metrics_history[\"mos\"])[0],\n",
    "           \"KADID10K_spearman\": stats.spearmanr(metrics_history[\"distance\"], metrics_history[\"mos\"])[0],\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
