{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from typing import Any, Callable, Sequence, Union\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "import jax\n",
    "from jax import lax, random, numpy as jnp\n",
    "import flax\n",
    "from flax.core import freeze, unfreeze, FrozenDict\n",
    "from flax import linen as nn\n",
    "from flax import struct\n",
    "from flax.training import train_state\n",
    "from flax.training import orbax_utils\n",
    "\n",
    "import optax\n",
    "import orbax.checkpoint\n",
    "\n",
    "from clu import metrics\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "from einops import reduce, rearrange\n",
    "import wandb\n",
    "\n",
    "from iqadatasets.datasets import *\n",
    "from fxlayers.layers import *\n",
    "from fxlayers.layers import GaborLayerLogSigma_, GaussianLayerGamma, FreqGaussianGamma, OrientGaussianGamma\n",
    "from fxlayers.initializers import *\n",
    "from JaxPlayground.utils.constraints import *\n",
    "from JaxPlayground.utils.wandb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dst_train = TID2008(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2008/\", exclude_imgs=[25])\n",
    "# dst_val = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA//TID/TID2013/\", exclude_imgs=[25])\n",
    "# dst_train = TID2008(\"/media/disk/databases/BBDD_video_image/Image_Quality//TID/TID2008/\", exclude_imgs=[25])\n",
    "# dst_val = TID2013(\"/media/disk/databases/BBDD_video_image/Image_Quality//TID/TID2013/\", exclude_imgs=[25])\n",
    "# dst = KADIK10K(\"/media/disk/databases/BBDD_video_image/Image_Quality/KADIK10K/\")\n",
    "# dst = PIPAL(\"/media/disk/databases/BBDD_video_image/Image_Quality/PIPAL/\")\n",
    "# dst = KADIK10K(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/KADIK10K/\")\n",
    "dst = KADIK10K(\"/media/databases/IQA/KADIK10K/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, img_dist, mos = next(iter(dst.dataset))\n",
    "img.shape, img_dist.shape, mos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = \"gptw703y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "prev_run = api.run(f\"jorgvt/PerceptNet_KLD/{id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigDict(prev_run.config[\"_fields\"])\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in prev_run.files():\n",
    "    file.download(root=prev_run.dir, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"PerceptNet_KLD\",\n",
    "           name=prev_run.name,\n",
    "           job_type=\"evaluate\",\n",
    "           mode=\"online\",\n",
    "           )\n",
    "config = config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img, img_dist, mos):\n",
    "    h, w = 384, 512\n",
    "    img = tf.image.resize(img, (h//8, w//8))\n",
    "    img_dist = tf.image.resize(img_dist, (h//8, w//8))\n",
    "    return img, img_dist, mos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_rdy = dst.dataset.batch(config.BATCH_SIZE, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                     .map(resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model we're going to use\n",
    "\n",
    "> It's going to be a very simple model just for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNet(nn.Module):\n",
    "    \"\"\"IQA model inspired by the visual system.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        outputs = rearrange(inputs, \"b h w c -> b (h w c)\")\n",
    "        if config.METRIC == \"KLD\" or config.METRIC == \"JS\":\n",
    "            mean = nn.Dense(features=2)(outputs)\n",
    "            std = nn.Dense(features=2)(outputs)\n",
    "            return mean, std\n",
    "        elif config.METRIC == \"MSE\":\n",
    "            return nn.Dense(features=2)(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PerceptNet(nn.Module):\n",
    "#     \"\"\"IQA model inspired by the visual system.\"\"\"\n",
    "\n",
    "#     @nn.compact\n",
    "#     def __call__(self,\n",
    "#                  inputs,\n",
    "#                  **kwargs,\n",
    "#                  ):\n",
    "#         outputs = rearrange(inputs, \"b h w c -> b (h w c)\")\n",
    "#         mean = nn.Dense(features=2)(outputs)\n",
    "#         std = nn.Dense(features=2)(outputs)\n",
    "#         return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the metrics with `clu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    \"\"\"Collection of metrics to be tracked during training.\"\"\"\n",
    "    loss: metrics.Average.from_output(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `TrainState` doesn't include metrics, but it's very easy to subclass it so that it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "    state: FrozenDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a function that initializes the `TrainState` from a module, a rng key and some optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, key, tx, input_shape):\n",
    "    \"\"\"Creates the initial `TrainState`.\"\"\"\n",
    "    variables = module.init(key, jnp.ones(input_shape))\n",
    "    state, params = variables.pop('params')\n",
    "    return TrainState.create(\n",
    "        apply_fn=module.apply,\n",
    "        params=params,\n",
    "        state=state,\n",
    "        tx=tx,\n",
    "        metrics=Metrics.empty()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kld(mean_p, std_p, mean_q, std_q, axis=(1)):\n",
    "    \"\"\"Assume diagonal covariance matrix and that the input is the logvariance.\"\"\"\n",
    "    std_p, std_q = jnp.exp(std_p), jnp.exp(std_q)\n",
    "    def safe_div(a, b): return a/b #jnp.where(a == b, 1, a/b)\n",
    "    det_p = jnp.prod(std_p, axis=axis) + 1e-5\n",
    "    det_q = jnp.prod(std_q, axis=axis) + 1e-5\n",
    "    \n",
    "    return jnp.log(safe_div(det_p, det_q)) + jnp.sum((1/std_q)*(mean_p - mean_q)**2, axis=axis) + jnp.sum(std_p/std_q, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def js(mean_p, std_p, mean_q, std_q, axis=(1)):\n",
    "    return (1/2)*(kld(mean_p, std_p, mean_q, std_q, axis) + kld(mean_q, std_q, mean_p, std_p, axis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_distance(*, state, batch):\n",
    "    \"\"\"Obtaining the metrics for a given batch.\"\"\"\n",
    "    img, img_dist, mos = batch\n",
    "    \n",
    "    ## Calculate the KLD\n",
    "    if config.METRIC == \"KLD\":\n",
    "        (img_mean, img_std), updated_state = state.apply_fn({\"params\": state.params, **state.state}, img, mutable=list(state.state.keys()), train=False)\n",
    "        (img_dist_mean, img_dist_std), updated_state = state.apply_fn({\"params\": state.params, **state.state}, img_dist, mutable=list(state.state.keys()), train=False)\n",
    "        dist = kld(img_mean, img_std, img_dist_mean, img_dist_std)\n",
    "    \n",
    "    elif config.METRIC == \"JS\":\n",
    "        (img_mean, img_std), updated_state = state.apply_fn({\"params\": state.params, **state.state}, img, mutable=list(state.state.keys()), train=False)\n",
    "        (img_dist_mean, img_dist_std), updated_state = state.apply_fn({\"params\": state.params, **state.state}, img_dist, mutable=list(state.state.keys()), train=False)\n",
    "        dist = js(img_mean, img_std, img_dist_mean, img_dist_std)\n",
    "    \n",
    "    elif config.METRIC == \"MSE\":\n",
    "        img_pred, updated_state = state.apply_fn({\"params\": state.params, **state.state}, img, mutable=list(state.state.keys()), train=True)\n",
    "        img_dist_pred, updated_state = state.apply_fn({\"params\": state.params, **state.state}, img_dist, mutable=list(state.state.keys()), train=True)\n",
    "        ## Calculate the MSE\n",
    "        dist = ((img_pred - img_dist_pred)**2).sum(axis=(1))**(1/2)\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pretrained model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(PerceptNet(), random.PRNGKey(config.SEED), optax.adam(config.LEARNING_RATE), input_shape=(1,384//8,512//8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trainable(path):\n",
    "    return False\n",
    "    # return (\"A\" in path) or (\"alpha_achrom\" in path) or (\"alpha_chrom_rg\" in path) or (\"alpha_chrom_yb\" in path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_tree = freeze(flax.traverse_util.path_aware_map(lambda path, v: \"non_trainable\" if check_trainable(path)  else \"trainable\", state.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(state.params))\n",
    "trainable_param_count = sum([w.size if t==\"trainable\" else 0 for w, t in zip(jax.tree_util.tree_leaves(state.params), jax.tree_util.tree_leaves(trainable_tree))])\n",
    "param_count, trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.summary[\"total_parameters\"] = param_count\n",
    "wandb.run.summary[\"trainable_parameters\"] = trainable_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    \"trainable\": optax.adam(learning_rate=config.LEARNING_RATE),\n",
    "    \"non_trainable\": optax.set_to_zero(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = optax.multi_transform(optimizers, trainable_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(PerceptNet(), random.PRNGKey(config.SEED), tx, input_shape=(1,384//8,512//8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before actually training the model we're going to set up the checkpointer to be able to save our trained models:\n",
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights\n",
    "state = orbax_checkpointer.restore(os.path.join(prev_run.dir,\"model-best\"), item=state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    \"distance\": [],\n",
    "    \"mos\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for batch in tqdm(dst_rdy.as_numpy_iterator()):\n",
    "    img, img_dist, mos = batch\n",
    "    distance = compute_distance(state=state, batch=batch)\n",
    "    metrics_history[\"distance\"].extend(distance)\n",
    "    metrics_history[\"mos\"].extend(mos)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(metrics_history[\"distance\"]) == len(dst.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(metrics_history[\"distance\"], metrics_history[\"mos\"]), stats.spearmanr(metrics_history[\"distance\"], metrics_history[\"mos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dst.data.copy()\n",
    "results[\"Distance\"] = metrics_history[\"distance\"]\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"KADID10K\": wandb.Table(dataframe=results),\n",
    "           \"KADID10K_pearson\": stats.pearsonr(metrics_history[\"distance\"], metrics_history[\"mos\"])[0],\n",
    "           \"KADID10K_spearman\": stats.spearmanr(metrics_history[\"distance\"], metrics_history[\"mos\"])[0],\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
