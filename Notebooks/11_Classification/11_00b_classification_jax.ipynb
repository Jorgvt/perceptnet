{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os; os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jax.config import config\n",
    "# config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 13:05:58.557677: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-21 13:06:13.211352: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-21 13:07:05.463732: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:1: failed initializing StreamExecutor for CUDA device ordinal 1: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "2023-09-21 13:07:05.463819: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from typing import Any, Callable, Sequence, Union\n",
    "import numpy as np\n",
    "from fastcore.xtras import Path\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import jax\n",
    "from jax import lax, random, numpy as jnp\n",
    "from flax.core import freeze, unfreeze, FrozenDict\n",
    "from flax import linen as nn\n",
    "from flax import struct\n",
    "from flax.training import train_state\n",
    "from flax.training import orbax_utils\n",
    "\n",
    "import optax\n",
    "import orbax.checkpoint\n",
    "\n",
    "from clu import metrics\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "from einops import reduce, rearrange\n",
    "import wandb\n",
    "from iqadatasets.datasets import *\n",
    "from fxlayers.layers import *\n",
    "from fxlayers.initializers import mean\n",
    "from JaxPlayground.utils.constraints import *\n",
    "from JaxPlayground.utils.wandb import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'epochs':500,\n",
    "        'learning_rate':3e-4,\n",
    "        'batch_size':64,\n",
    "        'kernel_initializer':'ones',\n",
    "        'gdn_kernel_size':1,\n",
    "        'learnable_undersampling':False,\n",
    "        'verbose': 0,\n",
    "        'dataset': 'imagenet', # imagenet / imagenette / cifar10 / cifar100,\n",
    "        'validation_split': 0.2,\n",
    "        'seed': 42,\n",
    "        'GAP': False,\n",
    "        'use_bias': True,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: jorgvt. Use `wandb login --relogin` to force relogin\n",
      "wandb: wandb version 0.15.10 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "wandb: Tracking run with wandb version 0.15.1\n",
      "wandb: Run data is saved locally in /lhome/ext/uv075/uv0752/perceptnet/Notebooks/11_Classification/wandb/run-20230921_132217-tu6scbey\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run Baseline-Flatten-NoBias\n",
      "wandb:  View project at https://wandb.ai/jorgvt/PerceptNetClassification_JaX\n",
      "wandb:  View run at https://wandb.ai/jorgvt/PerceptNetClassification_JaX/runs/tu6scbey\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project='PerceptNetClassification_JaX',\n",
    "            notes=\"\",\n",
    "            tags=[],\n",
    "            name = 'Baseline-Flatten-NoBias',\n",
    "            config=config,\n",
    "            job_type=\"training\",\n",
    "            mode=\"online\",\n",
    "            )\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet():\n",
    "    path_data = Path(\"/lustre/ific.uv.es/ml/uv075/Databases/imagenet_images/\")\n",
    "    dst_train = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"training\",\n",
    "                seed=config.seed,\n",
    "                shuffle=True,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    dst_val = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"validation\",\n",
    "                seed=config.seed,\n",
    "                shuffle=False,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    return dst_train, dst_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenette():\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    dst_train, info = tfds.load(\"imagenette/320px-v2\", split=f\"train[:{(1-config.validation_split)*100:.0f}%]\", with_info=True, shuffle_files=True)\n",
    "    dst_val = tfds.load(\"imagenette/320px-v2\", split=f\"train[{(1-config.validation_split)*100:.0f}%:]\", with_info=False, shuffle_files=False)\n",
    "    def prepare_tfds(item):\n",
    "        x, y = item[\"image\"], item[\"label\"]\n",
    "        x = tf.image.resize_with_crop_or_pad(x, 256, 256)\n",
    "        return x, y\n",
    "    dst_train = dst_train.map(prepare_tfds)\n",
    "    dst_val = dst_val.map(prepare_tfds)\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size), info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10():\n",
    "    from tensorflow.keras.datasets import cifar10\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config.validation_split, random_state=config.seed)\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100():\n",
    "    from tensorflow.keras.datasets import cifar100\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config.validation_split, random_state=config.seed)\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202050 files belonging to 409 classes.\n",
      "Using 161640 files for training.\n",
      "Found 202050 files belonging to 409 classes.\n",
      "Using 40410 files for validation.\n",
      "Training on imagenet with 409 classes.\n"
     ]
    }
   ],
   "source": [
    "if config.dataset == \"imagenet\":\n",
    "    dst_train, dst_val = load_imagenet()\n",
    "    N_CLASSES = len(dst_train.class_names)\n",
    "elif config.dataset == \"cifar10\":\n",
    "    dst_train, dst_val = load_cifar10()\n",
    "    N_CLASSES = 10\n",
    "elif config.dataset == \"cifar100\":\n",
    "    dst_train, dst_val = load_cifar100()\n",
    "    N_CLASSES = 100\n",
    "elif config.dataset == \"imagenette\":\n",
    "    dst_train, dst_val, N_CLASSES = load_imagenette()\n",
    "else:\n",
    "    raise ValueError(\"Dataset parameter not allowed.\")\n",
    "print(f\"Training on {config.dataset} with {N_CLASSES} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([256, 256, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dst_train))\n",
    "input_shape = x[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.summary[\"N_CLASSES\"] = N_CLASSES\n",
    "wandb.run.summary[\"Input_Shape\"] = tuple(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_tid2013 = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/TID/TID2013\").dataset\\\n",
    "                                                                              .batch(config.batch_size)\\\n",
    "                                                                              .prefetch(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(y.shape) != 1:\n",
    "    dst_train = dst_train.map(lambda x,y: (tf.cast(x, tf.float32)/255.0, y[:,0]))\n",
    "    dst_val = dst_val.map(lambda x,y: (tf.cast(x, tf.float32)/255.0, y[:,0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "dst_train_rdy = dst_train.cache().prefetch(buffer_size=1)\n",
    "dst_val_rdy = dst_val.cache().prefetch(buffer_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDN(nn.Module):\n",
    "    \"\"\"Generalized Divisive Normalization.\"\"\"\n",
    "    kernel_size: Union[int, Sequence[int]]\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    apply_independently: bool = False\n",
    "    # kernel_init: Callable = nn.initializers.lecun_normal()\n",
    "    kernel_init: Callable = mean()\n",
    "    bias_init: Callable = nn.initializers.ones_init()\n",
    "    alpha: float = 2.\n",
    "    epsilon: float = 1/2 # Exponential of the denominator\n",
    "    eps: float = 1e-6 # Numerical stability in the denominator\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 ):\n",
    "        denom = nn.Conv(features=inputs.shape[-1], # Same output channels as input\n",
    "                        kernel_size=self.kernel_size if isinstance(self.kernel_size, Sequence) else [self.kernel_size]*2, \n",
    "                        strides=self.strides, \n",
    "                        padding=self.padding,\n",
    "                        feature_group_count=inputs.shape[-1] if self.apply_independently else 1,\n",
    "                        kernel_init=self.kernel_init, \n",
    "                        bias_init=self.bias_init)(inputs**self.alpha)\n",
    "        return inputs / (jnp.clip(denom, a_min=1e-5)**self.epsilon + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNet(nn.Module):\n",
    "    \"\"\"IQA model inspired by the visual system.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=True)(inputs)\n",
    "        outputs = nn.Conv(features=3, kernel_size=(1,1), strides=1, padding=\"SAME\", use_bias=config.use_bias)(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        outputs = nn.Conv(features=6, kernel_size=(5,5), strides=1, padding=\"SAME\", use_bias=config.use_bias)(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        outputs = nn.Conv(features=128, kernel_size=(5,5), strides=1, padding=\"SAME\", use_bias=config.use_bias)(outputs)\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 ):\n",
    "        outputs = nn.Dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNetClassifier(nn.Module):\n",
    "    \"\"\"Classifier with a PerceptNet backbone.\"\"\"\n",
    "\n",
    "    def setup(self):\n",
    "        self.perceptnet = PerceptNet()\n",
    "        self.cls = nn.Dense(N_CLASSES)\n",
    "\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 ):\n",
    "        outputs = self.perceptnet(inputs)\n",
    "        # outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = reduce(outputs, \"b h w c -> b c\", reduction=\"mean\") if config.GAP else rearrange(outputs, \"b h w c -> b (h w c)\")\n",
    "        outputs = self.cls(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    \"\"\"Collection of metrics to be tracked during training.\"\"\"\n",
    "    accuracy: metrics.Accuracy\n",
    "    loss: metrics.Average.from_output(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "    state: FrozenDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, key, tx, input_shape):\n",
    "    \"\"\"Creates the initial `TrainState`.\"\"\"\n",
    "    variables = module.init(key, jnp.ones(input_shape))\n",
    "    state, params = variables.pop('params')\n",
    "    return TrainState.create(\n",
    "        apply_fn=module.apply,\n",
    "        params=params,\n",
    "        state=state,\n",
    "        tx=tx,\n",
    "        metrics=Metrics.empty()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(PerceptNetClassifier(), random.PRNGKey(config.seed), optax.adam(config.learning_rate), input_shape=(1,*(x.shape[1:])))\n",
    "state = state.replace(params=clip_layer(state.params, \"GDN\", a_min=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log the number of trainable weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214470569"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(state.params))\n",
    "param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.summary[\"trainable_parameters\"] = param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    img, label = batch\n",
    "    def loss_fn(params):\n",
    "        ## Forward pass through the model\n",
    "        img_pred = state.apply_fn({\"params\": params, **state.state}, img)\n",
    "\n",
    "        ## Calculate crossentropy\n",
    "        return optax.softmax_cross_entropy_with_integer_labels(img_pred, label).mean(), img_pred\n",
    "    \n",
    "    (loss, dist_diff), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics_updates = state.metrics.single_from_model_output(loss=loss, logits=dist_diff, labels=jnp.round(label).astype(int))\n",
    "    metrics = state.metrics.merge(metrics_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def val_step(state, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    img, label = batch\n",
    "    def loss_fn(params):\n",
    "        ## Forward pass through the model\n",
    "        img_pred = state.apply_fn({\"params\": params, **state.state}, img)\n",
    "\n",
    "        ## Calculate crossentropy\n",
    "        return optax.softmax_cross_entropy_with_integer_labels(img_pred, label).mean(), img_pred\n",
    "    \n",
    "    loss, dist_diff = loss_fn(state.params)\n",
    "    metrics_updates = state.metrics.single_from_model_output(loss=loss, logits=dist_diff, labels=jnp.round(label).astype(int))\n",
    "    metrics = state.metrics.merge(metrics_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(state, img):\n",
    "    img_pred = PerceptNet().apply({\"params\": state.params[\"perceptnet\"]}, img)\n",
    "    return img_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(a, b): return jnp.sqrt(jnp.sum((a-b)**2, axis=(1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def obtain_distances(state, batch):\n",
    "    ref, dist, mos = batch\n",
    "    pred_ref = forward_pass(state, ref)\n",
    "    pred_dist = forward_pass(state, dist)\n",
    "    distance = rmse(pred_ref, pred_dist)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_correlation(state, dst):\n",
    "    distances, moses = [], []\n",
    "    for batch in dst:\n",
    "        distance = obtain_distances(state, batch)\n",
    "        distances.extend(distance)\n",
    "        moses.extend(batch[2])\n",
    "        # break\n",
    "    return stats.pearsonr(distances, moses)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_accuracy\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_accuracy\": [],\n",
    "    \"correlation\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -> [Train] Loss: 14.555 Acc: 0.009 [Val] Loss: 5.151 Acc: 0.203 || Corr: -0.635\n",
      "Epoch 1 -> [Train] Loss: 4.474 Acc: 0.231 [Val] Loss: 3.880 Acc: 0.405 || Corr: -0.590\n",
      "Epoch 2 -> [Train] Loss: 3.245 Acc: 0.435 [Val] Loss: 3.546 Acc: 0.517 || Corr: -0.543\n",
      "Epoch 3 -> [Train] Loss: 2.433 Acc: 0.591 [Val] Loss: 3.624 Acc: 0.591 || Corr: -0.512\n",
      "Epoch 4 -> [Train] Loss: 1.881 Acc: 0.701 [Val] Loss: 3.848 Acc: 0.636 || Corr: -0.498\n",
      "Epoch 5 -> [Train] Loss: 1.557 Acc: 0.764 [Val] Loss: 4.050 Acc: 0.663 || Corr: -0.486\n",
      "Epoch 6 -> [Train] Loss: 1.335 Acc: 0.803 [Val] Loss: 4.222 Acc: 0.682 || Corr: -0.482\n",
      "Epoch 7 -> [Train] Loss: 1.160 Acc: 0.834 [Val] Loss: 4.349 Acc: 0.698 || Corr: -0.473\n",
      "Epoch 8 -> [Train] Loss: 1.028 Acc: 0.856 [Val] Loss: 4.516 Acc: 0.707 || Corr: -0.462\n",
      "Epoch 9 -> [Train] Loss: 0.889 Acc: 0.873 [Val] Loss: 4.657 Acc: 0.717 || Corr: -0.456\n",
      "Epoch 10 -> [Train] Loss: 0.793 Acc: 0.888 [Val] Loss: 4.799 Acc: 0.722 || Corr: -0.442\n",
      "Epoch 11 -> [Train] Loss: 0.728 Acc: 0.898 [Val] Loss: 5.045 Acc: 0.720 || Corr: -0.436\n",
      "Epoch 12 -> [Train] Loss: 0.645 Acc: 0.910 [Val] Loss: 4.940 Acc: 0.734 || Corr: -0.427\n",
      "Epoch 13 -> [Train] Loss: 0.579 Acc: 0.920 [Val] Loss: 5.165 Acc: 0.734 || Corr: -0.420\n",
      "Epoch 14 -> [Train] Loss: 0.539 Acc: 0.927 [Val] Loss: 5.124 Acc: 0.740 || Corr: -0.412\n",
      "Epoch 15 -> [Train] Loss: 0.489 Acc: 0.935 [Val] Loss: 5.289 Acc: 0.740 || Corr: -0.403\n",
      "Epoch 16 -> [Train] Loss: 0.439 Acc: 0.943 [Val] Loss: 5.284 Acc: 0.746 || Corr: -0.395\n",
      "Epoch 17 -> [Train] Loss: 0.380 Acc: 0.952 [Val] Loss: 5.373 Acc: 0.759 || Corr: -0.401\n",
      "Epoch 18 -> [Train] Loss: 0.349 Acc: 0.959 [Val] Loss: 5.315 Acc: 0.762 || Corr: -0.400\n",
      "Epoch 19 -> [Train] Loss: 0.293 Acc: 0.967 [Val] Loss: 5.298 Acc: 0.768 || Corr: -0.388\n",
      "Epoch 20 -> [Train] Loss: 0.244 Acc: 0.973 [Val] Loss: 5.343 Acc: 0.772 || Corr: -0.388\n",
      "Epoch 21 -> [Train] Loss: 0.232 Acc: 0.976 [Val] Loss: 5.345 Acc: 0.779 || Corr: -0.385\n",
      "Epoch 22 -> [Train] Loss: 0.203 Acc: 0.980 [Val] Loss: 5.366 Acc: 0.783 || Corr: -0.388\n",
      "Epoch 23 -> [Train] Loss: 0.205 Acc: 0.982 [Val] Loss: 5.339 Acc: 0.784 || Corr: -0.389\n",
      "Epoch 24 -> [Train] Loss: 0.189 Acc: 0.984 [Val] Loss: 5.303 Acc: 0.788 || Corr: -0.389\n",
      "Epoch 25 -> [Train] Loss: 0.178 Acc: 0.986 [Val] Loss: 5.228 Acc: 0.790 || Corr: -0.393\n",
      "Epoch 26 -> [Train] Loss: 0.161 Acc: 0.987 [Val] Loss: 5.142 Acc: 0.792 || Corr: -0.392\n",
      "Epoch 27 -> [Train] Loss: 0.143 Acc: 0.989 [Val] Loss: 5.205 Acc: 0.792 || Corr: -0.387\n",
      "Epoch 28 -> [Train] Loss: 0.137 Acc: 0.989 [Val] Loss: 5.266 Acc: 0.788 || Corr: -0.380\n",
      "Epoch 29 -> [Train] Loss: 0.149 Acc: 0.988 [Val] Loss: 5.200 Acc: 0.793 || Corr: -0.381\n",
      "Epoch 30 -> [Train] Loss: 0.130 Acc: 0.992 [Val] Loss: 5.131 Acc: 0.794 || Corr: -0.382\n",
      "Epoch 31 -> [Train] Loss: 0.134 Acc: 0.991 [Val] Loss: 5.242 Acc: 0.788 || Corr: -0.392\n",
      "Epoch 32 -> [Train] Loss: 0.126 Acc: 0.992 [Val] Loss: 5.199 Acc: 0.795 || Corr: -0.390\n",
      "Epoch 33 -> [Train] Loss: 0.124 Acc: 0.991 [Val] Loss: 5.220 Acc: 0.793 || Corr: -0.395\n",
      "Epoch 34 -> [Train] Loss: 0.136 Acc: 0.991 [Val] Loss: 5.154 Acc: 0.794 || Corr: -0.398\n",
      "Epoch 35 -> [Train] Loss: 0.119 Acc: 0.991 [Val] Loss: 5.329 Acc: 0.787 || Corr: -0.390\n",
      "Epoch 36 -> [Train] Loss: 0.101 Acc: 0.993 [Val] Loss: 5.199 Acc: 0.794 || Corr: -0.382\n",
      "Epoch 37 -> [Train] Loss: 0.105 Acc: 0.994 [Val] Loss: 5.107 Acc: 0.793 || Corr: -0.395\n",
      "Epoch 38 -> [Train] Loss: 0.109 Acc: 0.993 [Val] Loss: 5.059 Acc: 0.795 || Corr: -0.396\n",
      "Epoch 39 -> [Train] Loss: 0.098 Acc: 0.994 [Val] Loss: 5.126 Acc: 0.792 || Corr: -0.402\n",
      "Epoch 40 -> [Train] Loss: 0.098 Acc: 0.994 [Val] Loss: 4.980 Acc: 0.793 || Corr: -0.402\n",
      "Epoch 41 -> [Train] Loss: 0.090 Acc: 0.995 [Val] Loss: 5.047 Acc: 0.797 || Corr: -0.399\n",
      "Epoch 42 -> [Train] Loss: 0.090 Acc: 0.995 [Val] Loss: 4.869 Acc: 0.799 || Corr: -0.396\n",
      "Epoch 43 -> [Train] Loss: 0.086 Acc: 0.995 [Val] Loss: 4.886 Acc: 0.798 || Corr: -0.403\n",
      "Epoch 44 -> [Train] Loss: 0.077 Acc: 0.996 [Val] Loss: 4.839 Acc: 0.798 || Corr: -0.407\n",
      "Epoch 45 -> [Train] Loss: 0.083 Acc: 0.996 [Val] Loss: 4.823 Acc: 0.797 || Corr: -0.410\n",
      "Epoch 46 -> [Train] Loss: 0.074 Acc: 0.996 [Val] Loss: 4.830 Acc: 0.798 || Corr: -0.406\n",
      "Epoch 47 -> [Train] Loss: 0.080 Acc: 0.996 [Val] Loss: 4.779 Acc: 0.799 || Corr: -0.406\n",
      "Epoch 48 -> [Train] Loss: 0.076 Acc: 0.996 [Val] Loss: 4.776 Acc: 0.799 || Corr: -0.407\n",
      "Epoch 49 -> [Train] Loss: 0.077 Acc: 0.996 [Val] Loss: 4.629 Acc: 0.800 || Corr: -0.407\n",
      "Epoch 50 -> [Train] Loss: 0.069 Acc: 0.996 [Val] Loss: 4.655 Acc: 0.800 || Corr: -0.417\n",
      "Epoch 51 -> [Train] Loss: 0.065 Acc: 0.996 [Val] Loss: 4.583 Acc: 0.801 || Corr: -0.411\n",
      "Epoch 52 -> [Train] Loss: 0.066 Acc: 0.996 [Val] Loss: 4.565 Acc: 0.801 || Corr: -0.411\n",
      "Epoch 53 -> [Train] Loss: 0.066 Acc: 0.997 [Val] Loss: 4.641 Acc: 0.798 || Corr: -0.411\n",
      "Epoch 54 -> [Train] Loss: 0.058 Acc: 0.997 [Val] Loss: 4.591 Acc: 0.799 || Corr: -0.409\n",
      "Epoch 55 -> [Train] Loss: 0.061 Acc: 0.997 [Val] Loss: 4.602 Acc: 0.799 || Corr: -0.414\n",
      "Epoch 56 -> [Train] Loss: 0.059 Acc: 0.997 [Val] Loss: 4.638 Acc: 0.798 || Corr: -0.409\n",
      "Epoch 57 -> [Train] Loss: 0.062 Acc: 0.997 [Val] Loss: 4.629 Acc: 0.801 || Corr: -0.419\n",
      "Epoch 58 -> [Train] Loss: 0.059 Acc: 0.997 [Val] Loss: 4.538 Acc: 0.799 || Corr: -0.412\n",
      "Epoch 59 -> [Train] Loss: 0.054 Acc: 0.997 [Val] Loss: 4.602 Acc: 0.797 || Corr: -0.415\n",
      "Epoch 60 -> [Train] Loss: 0.057 Acc: 0.997 [Val] Loss: 4.537 Acc: 0.796 || Corr: -0.427\n",
      "Epoch 61 -> [Train] Loss: 0.061 Acc: 0.997 [Val] Loss: 4.454 Acc: 0.799 || Corr: -0.420\n",
      "Epoch 62 -> [Train] Loss: 0.061 Acc: 0.997 [Val] Loss: 4.605 Acc: 0.795 || Corr: -0.420\n",
      "Epoch 63 -> [Train] Loss: 0.060 Acc: 0.997 [Val] Loss: 4.546 Acc: 0.795 || Corr: -0.421\n",
      "Epoch 64 -> [Train] Loss: 0.050 Acc: 0.997 [Val] Loss: 4.525 Acc: 0.797 || Corr: -0.417\n",
      "Epoch 65 -> [Train] Loss: 0.053 Acc: 0.997 [Val] Loss: 4.385 Acc: 0.801 || Corr: -0.429\n",
      "Epoch 66 -> [Train] Loss: 0.057 Acc: 0.997 [Val] Loss: 4.475 Acc: 0.797 || Corr: -0.427\n",
      "Epoch 67 -> [Train] Loss: 0.053 Acc: 0.997 [Val] Loss: 4.432 Acc: 0.801 || Corr: -0.433\n",
      "Epoch 68 -> [Train] Loss: 0.053 Acc: 0.997 [Val] Loss: 4.338 Acc: 0.801 || Corr: -0.427\n",
      "Epoch 69 -> [Train] Loss: 0.051 Acc: 0.998 [Val] Loss: 4.333 Acc: 0.800 || Corr: -0.422\n",
      "Epoch 70 -> [Train] Loss: 0.053 Acc: 0.997 [Val] Loss: 4.347 Acc: 0.800 || Corr: -0.428\n",
      "Epoch 71 -> [Train] Loss: 0.053 Acc: 0.997 [Val] Loss: 4.322 Acc: 0.800 || Corr: -0.428\n",
      "Epoch 72 -> [Train] Loss: 0.045 Acc: 0.997 [Val] Loss: 4.300 Acc: 0.800 || Corr: -0.433\n",
      "Epoch 73 -> [Train] Loss: 0.051 Acc: 0.998 [Val] Loss: 4.282 Acc: 0.800 || Corr: -0.423\n",
      "Epoch 74 -> [Train] Loss: 0.052 Acc: 0.997 [Val] Loss: 4.436 Acc: 0.796 || Corr: -0.427\n",
      "Epoch 75 -> [Train] Loss: 0.047 Acc: 0.997 [Val] Loss: 4.201 Acc: 0.801 || Corr: -0.424\n",
      "Epoch 76 -> [Train] Loss: 0.050 Acc: 0.997 [Val] Loss: 4.248 Acc: 0.801 || Corr: -0.429\n",
      "Epoch 77 -> [Train] Loss: 0.047 Acc: 0.998 [Val] Loss: 4.235 Acc: 0.799 || Corr: -0.431\n",
      "Epoch 78 -> [Train] Loss: 0.046 Acc: 0.998 [Val] Loss: 4.349 Acc: 0.795 || Corr: -0.438\n",
      "Epoch 79 -> [Train] Loss: 0.047 Acc: 0.998 [Val] Loss: 4.186 Acc: 0.800 || Corr: -0.428\n",
      "Epoch 80 -> [Train] Loss: 0.042 Acc: 0.998 [Val] Loss: 4.274 Acc: 0.799 || Corr: -0.430\n",
      "Epoch 81 -> [Train] Loss: 0.046 Acc: 0.998 [Val] Loss: 4.300 Acc: 0.798 || Corr: -0.430\n",
      "Epoch 82 -> [Train] Loss: 0.047 Acc: 0.998 [Val] Loss: 4.218 Acc: 0.799 || Corr: -0.434\n",
      "Epoch 83 -> [Train] Loss: 0.044 Acc: 0.998 [Val] Loss: 4.176 Acc: 0.802 || Corr: -0.436\n",
      "Epoch 84 -> [Train] Loss: 0.042 Acc: 0.998 [Val] Loss: 4.192 Acc: 0.801 || Corr: -0.428\n",
      "Epoch 85 -> [Train] Loss: 0.038 Acc: 0.998 [Val] Loss: 4.131 Acc: 0.800 || Corr: -0.425\n",
      "Epoch 86 -> [Train] Loss: 0.037 Acc: 0.998 [Val] Loss: 4.135 Acc: 0.801 || Corr: -0.431\n",
      "Epoch 87 -> [Train] Loss: 0.043 Acc: 0.998 [Val] Loss: 4.168 Acc: 0.797 || Corr: -0.433\n",
      "Epoch 88 -> [Train] Loss: 0.041 Acc: 0.998 [Val] Loss: 4.261 Acc: 0.798 || Corr: -0.433\n",
      "Epoch 89 -> [Train] Loss: 0.045 Acc: 0.998 [Val] Loss: 4.234 Acc: 0.797 || Corr: -0.435\n",
      "Epoch 90 -> [Train] Loss: 0.047 Acc: 0.998 [Val] Loss: 4.171 Acc: 0.797 || Corr: -0.436\n",
      "Epoch 91 -> [Train] Loss: 0.040 Acc: 0.998 [Val] Loss: 4.185 Acc: 0.801 || Corr: -0.439\n",
      "Epoch 92 -> [Train] Loss: 0.039 Acc: 0.998 [Val] Loss: 4.150 Acc: 0.801 || Corr: -0.443\n",
      "Epoch 93 -> [Train] Loss: 0.037 Acc: 0.998 [Val] Loss: 4.146 Acc: 0.800 || Corr: -0.430\n",
      "Epoch 94 -> [Train] Loss: 0.038 Acc: 0.998 [Val] Loss: 4.134 Acc: 0.800 || Corr: -0.435\n",
      "Epoch 95 -> [Train] Loss: 0.040 Acc: 0.998 [Val] Loss: 4.203 Acc: 0.798 || Corr: -0.424\n",
      "Epoch 96 -> [Train] Loss: 0.045 Acc: 0.998 [Val] Loss: 4.063 Acc: 0.801 || Corr: -0.437\n",
      "Epoch 97 -> [Train] Loss: 0.037 Acc: 0.998 [Val] Loss: 4.053 Acc: 0.801 || Corr: -0.426\n",
      "Epoch 98 -> [Train] Loss: 0.038 Acc: 0.998 [Val] Loss: 4.166 Acc: 0.799 || Corr: -0.429\n",
      "Epoch 99 -> [Train] Loss: 0.037 Acc: 0.998 [Val] Loss: 4.193 Acc: 0.791 || Corr: -0.419\n",
      "Epoch 100 -> [Train] Loss: 0.037 Acc: 0.998 [Val] Loss: 4.154 Acc: 0.797 || Corr: -0.426\n",
      "Epoch 101 -> [Train] Loss: 0.039 Acc: 0.998 [Val] Loss: 4.178 Acc: 0.795 || Corr: -0.422\n",
      "Epoch 102 -> [Train] Loss: 0.040 Acc: 0.998 [Val] Loss: 4.078 Acc: 0.796 || Corr: -0.427\n",
      "Epoch 103 -> [Train] Loss: 0.034 Acc: 0.998 [Val] Loss: 4.195 Acc: 0.795 || Corr: -0.434\n",
      "Epoch 104 -> [Train] Loss: 0.037 Acc: 0.998 [Val] Loss: 4.029 Acc: 0.800 || Corr: -0.422\n",
      "Epoch 105 -> [Train] Loss: 0.038 Acc: 0.998 [Val] Loss: 4.091 Acc: 0.798 || Corr: -0.439\n",
      "Epoch 106 -> [Train] Loss: 0.036 Acc: 0.998 [Val] Loss: 4.012 Acc: 0.800 || Corr: -0.428\n",
      "Epoch 107 -> [Train] Loss: 0.035 Acc: 0.998 [Val] Loss: 4.097 Acc: 0.797 || Corr: -0.425\n",
      "Epoch 108 -> [Train] Loss: 0.033 Acc: 0.998 [Val] Loss: 4.016 Acc: 0.801 || Corr: -0.434\n",
      "Epoch 109 -> [Train] Loss: 0.037 Acc: 0.998 [Val] Loss: 3.978 Acc: 0.799 || Corr: -0.421\n",
      "Epoch 110 -> [Train] Loss: 0.032 Acc: 0.998 [Val] Loss: 4.029 Acc: 0.798 || Corr: -0.430\n",
      "Epoch 111 -> [Train] Loss: 0.034 Acc: 0.998 [Val] Loss: 4.092 Acc: 0.798 || Corr: -0.436\n",
      "Epoch 112 -> [Train] Loss: 0.038 Acc: 0.998 [Val] Loss: 4.162 Acc: 0.793 || Corr: -0.441\n",
      "Epoch 113 -> [Train] Loss: 0.036 Acc: 0.998 [Val] Loss: 3.977 Acc: 0.800 || Corr: -0.437\n",
      "Epoch 114 -> [Train] Loss: 0.032 Acc: 0.998 [Val] Loss: 4.033 Acc: 0.795 || Corr: -0.439\n",
      "Epoch 115 -> [Train] Loss: 0.037 Acc: 0.998 [Val] Loss: 3.981 Acc: 0.797 || Corr: -0.437\n",
      "Epoch 116 -> [Train] Loss: 0.033 Acc: 0.998 [Val] Loss: 3.994 Acc: 0.797 || Corr: -0.438\n",
      "Epoch 117 -> [Train] Loss: 0.032 Acc: 0.998 [Val] Loss: 3.996 Acc: 0.796 || Corr: -0.430\n",
      "Epoch 118 -> [Train] Loss: 0.028 Acc: 0.998 [Val] Loss: 3.997 Acc: 0.799 || Corr: -0.437\n",
      "Epoch 119 -> [Train] Loss: 0.033 Acc: 0.998 [Val] Loss: 4.048 Acc: 0.795 || Corr: -0.421\n",
      "Epoch 120 -> [Train] Loss: 0.031 Acc: 0.998 [Val] Loss: 4.114 Acc: 0.791 || Corr: -0.431\n",
      "Epoch 121 -> [Train] Loss: 0.034 Acc: 0.998 [Val] Loss: 3.947 Acc: 0.796 || Corr: -0.424\n",
      "Epoch 122 -> [Train] Loss: 0.032 Acc: 0.998 [Val] Loss: 3.935 Acc: 0.799 || Corr: -0.428\n",
      "Epoch 123 -> [Train] Loss: 0.033 Acc: 0.998 [Val] Loss: 3.949 Acc: 0.798 || Corr: -0.415\n",
      "Epoch 124 -> [Train] Loss: 0.034 Acc: 0.998 [Val] Loss: 4.050 Acc: 0.797 || Corr: -0.435\n",
      "Epoch 125 -> [Train] Loss: 0.032 Acc: 0.998 [Val] Loss: 4.073 Acc: 0.791 || Corr: -0.434\n",
      "Epoch 126 -> [Train] Loss: 0.028 Acc: 0.999 [Val] Loss: 3.979 Acc: 0.795 || Corr: -0.440\n",
      "Epoch 127 -> [Train] Loss: 0.032 Acc: 0.998 [Val] Loss: 4.057 Acc: 0.792 || Corr: -0.446\n",
      "Epoch 128 -> [Train] Loss: 0.031 Acc: 0.998 [Val] Loss: 3.951 Acc: 0.797 || Corr: -0.428\n",
      "Epoch 129 -> [Train] Loss: 0.032 Acc: 0.998 [Val] Loss: 3.879 Acc: 0.797 || Corr: -0.419\n",
      "Epoch 130 -> [Train] Loss: 0.028 Acc: 0.998 [Val] Loss: 3.898 Acc: 0.799 || Corr: -0.419\n",
      "Epoch 131 -> [Train] Loss: 0.031 Acc: 0.998 [Val] Loss: 3.941 Acc: 0.798 || Corr: -0.430\n",
      "Epoch 132 -> [Train] Loss: 0.025 Acc: 0.999 [Val] Loss: 3.964 Acc: 0.795 || Corr: -0.430\n",
      "Epoch 133 -> [Train] Loss: 0.031 Acc: 0.998 [Val] Loss: 3.819 Acc: 0.801 || Corr: -0.436\n",
      "Epoch 134 -> [Train] Loss: 0.027 Acc: 0.998 [Val] Loss: 3.863 Acc: 0.799 || Corr: -0.437\n",
      "Epoch 135 -> [Train] Loss: 0.030 Acc: 0.998 [Val] Loss: 3.935 Acc: 0.798 || Corr: -0.431\n",
      "Epoch 136 -> [Train] Loss: 0.027 Acc: 0.999 [Val] Loss: 3.905 Acc: 0.798 || Corr: -0.438\n",
      "Epoch 137 -> [Train] Loss: 0.031 Acc: 0.998 [Val] Loss: 3.949 Acc: 0.796 || Corr: -0.430\n",
      "Epoch 138 -> [Train] Loss: 0.032 Acc: 0.998 [Val] Loss: 3.953 Acc: 0.790 || Corr: -0.432\n",
      "Epoch 139 -> [Train] Loss: 0.027 Acc: 0.999 [Val] Loss: 3.914 Acc: 0.797 || Corr: -0.427\n",
      "Epoch 140 -> [Train] Loss: 0.031 Acc: 0.998 [Val] Loss: 3.884 Acc: 0.798 || Corr: -0.436\n",
      "Epoch 141 -> [Train] Loss: 0.028 Acc: 0.999 [Val] Loss: 3.879 Acc: 0.796 || Corr: -0.434\n",
      "Epoch 142 -> [Train] Loss: 0.031 Acc: 0.999 [Val] Loss: 3.880 Acc: 0.797 || Corr: -0.444\n",
      "Epoch 143 -> [Train] Loss: 0.027 Acc: 0.998 [Val] Loss: 3.906 Acc: 0.794 || Corr: -0.437\n",
      "Epoch 144 -> [Train] Loss: 0.026 Acc: 0.999 [Val] Loss: 3.923 Acc: 0.796 || Corr: -0.437\n",
      "Epoch 145 -> [Train] Loss: 0.032 Acc: 0.998 [Val] Loss: 3.942 Acc: 0.790 || Corr: -0.445\n",
      "Epoch 146 -> [Train] Loss: 0.026 Acc: 0.999 [Val] Loss: 3.808 Acc: 0.798 || Corr: -0.445\n",
      "Epoch 147 -> [Train] Loss: 0.028 Acc: 0.998 [Val] Loss: 3.880 Acc: 0.797 || Corr: -0.434\n",
      "Epoch 148 -> [Train] Loss: 0.025 Acc: 0.999 [Val] Loss: 3.797 Acc: 0.798 || Corr: -0.434\n",
      "Epoch 149 -> [Train] Loss: 0.026 Acc: 0.999 [Val] Loss: 3.755 Acc: 0.798 || Corr: -0.437\n",
      "Epoch 150 -> [Train] Loss: 0.028 Acc: 0.998 [Val] Loss: 3.836 Acc: 0.799 || Corr: -0.435\n",
      "Epoch 151 -> [Train] Loss: 0.025 Acc: 0.999 [Val] Loss: 3.902 Acc: 0.791 || Corr: -0.439\n",
      "Epoch 152 -> [Train] Loss: 0.024 Acc: 0.999 [Val] Loss: 3.880 Acc: 0.797 || Corr: -0.444\n",
      "Epoch 153 -> [Train] Loss: 0.027 Acc: 0.998 [Val] Loss: 3.856 Acc: 0.796 || Corr: -0.444\n",
      "Epoch 154 -> [Train] Loss: 0.024 Acc: 0.999 [Val] Loss: 3.861 Acc: 0.797 || Corr: -0.430\n",
      "Epoch 155 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 3.887 Acc: 0.793 || Corr: -0.437\n",
      "Epoch 156 -> [Train] Loss: 0.027 Acc: 0.998 [Val] Loss: 3.871 Acc: 0.796 || Corr: -0.440\n",
      "Epoch 157 -> [Train] Loss: 0.025 Acc: 0.999 [Val] Loss: 3.913 Acc: 0.793 || Corr: -0.448\n",
      "Epoch 158 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 4.016 Acc: 0.787 || Corr: -0.444\n",
      "Epoch 159 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 3.873 Acc: 0.796 || Corr: -0.457\n",
      "Epoch 160 -> [Train] Loss: 0.025 Acc: 0.999 [Val] Loss: 3.850 Acc: 0.796 || Corr: -0.445\n",
      "Epoch 161 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 3.914 Acc: 0.795 || Corr: -0.436\n",
      "Epoch 162 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 3.916 Acc: 0.794 || Corr: -0.452\n",
      "Epoch 163 -> [Train] Loss: 0.022 Acc: 0.999 [Val] Loss: 3.877 Acc: 0.796 || Corr: -0.449\n",
      "Epoch 164 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 3.857 Acc: 0.798 || Corr: -0.444\n",
      "Epoch 165 -> [Train] Loss: 0.026 Acc: 0.999 [Val] Loss: 3.813 Acc: 0.797 || Corr: -0.445\n",
      "Epoch 166 -> [Train] Loss: 0.022 Acc: 0.999 [Val] Loss: 3.816 Acc: 0.797 || Corr: -0.435\n",
      "Epoch 167 -> [Train] Loss: 0.025 Acc: 0.999 [Val] Loss: 3.830 Acc: 0.796 || Corr: -0.443\n",
      "Epoch 168 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 3.734 Acc: 0.798 || Corr: -0.437\n",
      "Epoch 169 -> [Train] Loss: 0.024 Acc: 0.999 [Val] Loss: 3.786 Acc: 0.800 || Corr: -0.445\n",
      "Epoch 170 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 3.782 Acc: 0.798 || Corr: -0.447\n",
      "Epoch 171 -> [Train] Loss: 0.025 Acc: 0.999 [Val] Loss: 3.756 Acc: 0.801 || Corr: -0.456\n",
      "Epoch 172 -> [Train] Loss: 0.021 Acc: 0.999 [Val] Loss: 3.777 Acc: 0.799 || Corr: -0.450\n",
      "Epoch 173 -> [Train] Loss: 0.021 Acc: 0.999 [Val] Loss: 3.799 Acc: 0.797 || Corr: -0.447\n",
      "Epoch 174 -> [Train] Loss: 0.021 Acc: 0.999 [Val] Loss: 3.774 Acc: 0.799 || Corr: -0.437\n",
      "Epoch 175 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.662 Acc: 0.802 || Corr: -0.451\n",
      "Epoch 176 -> [Train] Loss: 0.025 Acc: 0.999 [Val] Loss: 3.770 Acc: 0.796 || Corr: -0.444\n",
      "Epoch 177 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 3.706 Acc: 0.800 || Corr: -0.438\n",
      "Epoch 178 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 3.693 Acc: 0.799 || Corr: -0.441\n",
      "Epoch 179 -> [Train] Loss: 0.022 Acc: 0.999 [Val] Loss: 3.818 Acc: 0.794 || Corr: -0.442\n",
      "Epoch 180 -> [Train] Loss: 0.021 Acc: 0.999 [Val] Loss: 3.703 Acc: 0.801 || Corr: -0.442\n",
      "Epoch 181 -> [Train] Loss: 0.026 Acc: 0.999 [Val] Loss: 3.706 Acc: 0.798 || Corr: -0.437\n",
      "Epoch 182 -> [Train] Loss: 0.022 Acc: 0.999 [Val] Loss: 3.709 Acc: 0.796 || Corr: -0.442\n",
      "Epoch 183 -> [Train] Loss: 0.025 Acc: 0.999 [Val] Loss: 3.616 Acc: 0.801 || Corr: -0.444\n",
      "Epoch 184 -> [Train] Loss: 0.022 Acc: 0.999 [Val] Loss: 3.741 Acc: 0.794 || Corr: -0.435\n",
      "Epoch 185 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.702 Acc: 0.795 || Corr: -0.446\n",
      "Epoch 186 -> [Train] Loss: 0.022 Acc: 0.999 [Val] Loss: 3.665 Acc: 0.796 || Corr: -0.449\n",
      "Epoch 187 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 3.718 Acc: 0.795 || Corr: -0.449\n",
      "Epoch 188 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.667 Acc: 0.800 || Corr: -0.444\n",
      "Epoch 189 -> [Train] Loss: 0.021 Acc: 0.999 [Val] Loss: 3.785 Acc: 0.797 || Corr: -0.452\n",
      "Epoch 190 -> [Train] Loss: 0.022 Acc: 0.999 [Val] Loss: 3.769 Acc: 0.796 || Corr: -0.442\n",
      "Epoch 191 -> [Train] Loss: 0.022 Acc: 0.999 [Val] Loss: 3.755 Acc: 0.795 || Corr: -0.441\n",
      "Epoch 192 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.725 Acc: 0.797 || Corr: -0.452\n",
      "Epoch 193 -> [Train] Loss: 0.021 Acc: 0.999 [Val] Loss: 3.730 Acc: 0.797 || Corr: -0.446\n",
      "Epoch 194 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.713 Acc: 0.799 || Corr: -0.440\n",
      "Epoch 195 -> [Train] Loss: 0.021 Acc: 0.999 [Val] Loss: 3.767 Acc: 0.795 || Corr: -0.441\n",
      "Epoch 196 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 3.712 Acc: 0.797 || Corr: -0.445\n",
      "Epoch 197 -> [Train] Loss: 0.021 Acc: 0.999 [Val] Loss: 3.735 Acc: 0.796 || Corr: -0.447\n",
      "Epoch 198 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.793 Acc: 0.791 || Corr: -0.451\n",
      "Epoch 199 -> [Train] Loss: 0.022 Acc: 0.999 [Val] Loss: 3.627 Acc: 0.800 || Corr: -0.446\n",
      "Epoch 200 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.774 Acc: 0.796 || Corr: -0.447\n",
      "Epoch 201 -> [Train] Loss: 0.022 Acc: 0.999 [Val] Loss: 3.669 Acc: 0.798 || Corr: -0.443\n",
      "Epoch 202 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 3.658 Acc: 0.798 || Corr: -0.445\n",
      "Epoch 203 -> [Train] Loss: 0.021 Acc: 0.999 [Val] Loss: 3.806 Acc: 0.793 || Corr: -0.451\n",
      "Epoch 204 -> [Train] Loss: 0.024 Acc: 0.999 [Val] Loss: 3.686 Acc: 0.797 || Corr: -0.445\n",
      "Epoch 205 -> [Train] Loss: 0.022 Acc: 0.999 [Val] Loss: 3.662 Acc: 0.800 || Corr: -0.448\n",
      "Epoch 206 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.711 Acc: 0.798 || Corr: -0.454\n",
      "Epoch 207 -> [Train] Loss: 0.024 Acc: 0.999 [Val] Loss: 3.838 Acc: 0.791 || Corr: -0.449\n",
      "Epoch 208 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.725 Acc: 0.794 || Corr: -0.450\n",
      "Epoch 209 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.704 Acc: 0.796 || Corr: -0.448\n",
      "Epoch 210 -> [Train] Loss: 0.021 Acc: 0.999 [Val] Loss: 3.723 Acc: 0.792 || Corr: -0.444\n",
      "Epoch 211 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.741 Acc: 0.793 || Corr: -0.455\n",
      "Epoch 212 -> [Train] Loss: 0.021 Acc: 0.999 [Val] Loss: 3.696 Acc: 0.796 || Corr: -0.441\n",
      "Epoch 213 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.675 Acc: 0.796 || Corr: -0.442\n",
      "Epoch 214 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.652 Acc: 0.801 || Corr: -0.445\n",
      "Epoch 215 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.638 Acc: 0.802 || Corr: -0.446\n",
      "Epoch 216 -> [Train] Loss: 0.023 Acc: 0.999 [Val] Loss: 3.697 Acc: 0.796 || Corr: -0.435\n",
      "Epoch 217 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.783 Acc: 0.793 || Corr: -0.447\n",
      "Epoch 218 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.811 Acc: 0.792 || Corr: -0.434\n",
      "Epoch 219 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.842 Acc: 0.786 || Corr: -0.440\n",
      "Epoch 220 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.742 Acc: 0.792 || Corr: -0.452\n",
      "Epoch 221 -> [Train] Loss: 0.022 Acc: 0.999 [Val] Loss: 3.715 Acc: 0.795 || Corr: -0.447\n",
      "Epoch 222 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.673 Acc: 0.796 || Corr: -0.445\n",
      "Epoch 223 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.688 Acc: 0.792 || Corr: -0.451\n",
      "Epoch 224 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.747 Acc: 0.794 || Corr: -0.451\n",
      "Epoch 225 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.750 Acc: 0.788 || Corr: -0.443\n",
      "Epoch 226 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.737 Acc: 0.792 || Corr: -0.444\n",
      "Epoch 227 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.638 Acc: 0.796 || Corr: -0.446\n",
      "Epoch 228 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.733 Acc: 0.788 || Corr: -0.448\n",
      "Epoch 229 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.621 Acc: 0.796 || Corr: -0.449\n",
      "Epoch 230 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.682 Acc: 0.792 || Corr: -0.451\n",
      "Epoch 231 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.766 Acc: 0.787 || Corr: -0.446\n",
      "Epoch 232 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.746 Acc: 0.790 || Corr: -0.441\n",
      "Epoch 233 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.712 Acc: 0.793 || Corr: -0.446\n",
      "Epoch 234 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.742 Acc: 0.790 || Corr: -0.447\n",
      "Epoch 235 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.851 Acc: 0.787 || Corr: -0.452\n",
      "Epoch 236 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.732 Acc: 0.791 || Corr: -0.447\n",
      "Epoch 237 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.737 Acc: 0.795 || Corr: -0.454\n",
      "Epoch 238 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.615 Acc: 0.798 || Corr: -0.451\n",
      "Epoch 239 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.744 Acc: 0.790 || Corr: -0.453\n",
      "Epoch 240 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.725 Acc: 0.792 || Corr: -0.454\n",
      "Epoch 241 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.685 Acc: 0.796 || Corr: -0.447\n",
      "Epoch 242 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.732 Acc: 0.794 || Corr: -0.451\n",
      "Epoch 243 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.665 Acc: 0.796 || Corr: -0.461\n",
      "Epoch 244 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.763 Acc: 0.791 || Corr: -0.459\n",
      "Epoch 245 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.739 Acc: 0.796 || Corr: -0.460\n",
      "Epoch 246 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.728 Acc: 0.791 || Corr: -0.480\n",
      "Epoch 247 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.698 Acc: 0.798 || Corr: -0.465\n",
      "Epoch 248 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.640 Acc: 0.798 || Corr: -0.470\n",
      "Epoch 249 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.753 Acc: 0.792 || Corr: -0.462\n",
      "Epoch 250 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.731 Acc: 0.788 || Corr: -0.452\n",
      "Epoch 251 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.886 Acc: 0.789 || Corr: -0.465\n",
      "Epoch 252 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.789 Acc: 0.790 || Corr: -0.475\n",
      "Epoch 253 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.790 Acc: 0.790 || Corr: -0.476\n",
      "Epoch 254 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.762 Acc: 0.793 || Corr: -0.460\n",
      "Epoch 255 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.704 Acc: 0.794 || Corr: -0.479\n",
      "Epoch 256 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.602 Acc: 0.797 || Corr: -0.476\n",
      "Epoch 257 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.549 Acc: 0.800 || Corr: -0.468\n",
      "Epoch 258 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.528 Acc: 0.801 || Corr: -0.477\n",
      "Epoch 259 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.497 Acc: 0.800 || Corr: -0.486\n",
      "Epoch 260 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.707 Acc: 0.795 || Corr: -0.475\n",
      "Epoch 261 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.669 Acc: 0.793 || Corr: -0.479\n",
      "Epoch 262 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.677 Acc: 0.794 || Corr: -0.481\n",
      "Epoch 263 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.657 Acc: 0.791 || Corr: -0.479\n",
      "Epoch 264 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.596 Acc: 0.796 || Corr: -0.487\n",
      "Epoch 265 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.602 Acc: 0.797 || Corr: -0.460\n",
      "Epoch 266 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.623 Acc: 0.793 || Corr: -0.483\n",
      "Epoch 267 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.670 Acc: 0.798 || Corr: -0.480\n",
      "Epoch 268 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.671 Acc: 0.789 || Corr: -0.469\n",
      "Epoch 269 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.627 Acc: 0.798 || Corr: -0.470\n",
      "Epoch 270 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.637 Acc: 0.794 || Corr: -0.487\n",
      "Epoch 271 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.523 Acc: 0.799 || Corr: -0.472\n",
      "Epoch 272 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.470 Acc: 0.803 || Corr: -0.471\n",
      "Epoch 273 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.708 Acc: 0.792 || Corr: -0.474\n",
      "Epoch 274 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.582 Acc: 0.797 || Corr: -0.478\n",
      "Epoch 275 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.548 Acc: 0.798 || Corr: -0.480\n",
      "Epoch 276 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.697 Acc: 0.792 || Corr: -0.472\n",
      "Epoch 277 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.638 Acc: 0.795 || Corr: -0.476\n",
      "Epoch 278 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.622 Acc: 0.798 || Corr: -0.474\n",
      "Epoch 279 -> [Train] Loss: 0.019 Acc: 0.999 [Val] Loss: 3.589 Acc: 0.798 || Corr: -0.487\n",
      "Epoch 280 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.555 Acc: 0.800 || Corr: -0.479\n",
      "Epoch 281 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.652 Acc: 0.795 || Corr: -0.485\n",
      "Epoch 282 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.583 Acc: 0.799 || Corr: -0.473\n",
      "Epoch 283 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.573 Acc: 0.797 || Corr: -0.492\n",
      "Epoch 284 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.549 Acc: 0.799 || Corr: -0.487\n",
      "Epoch 285 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.699 Acc: 0.789 || Corr: -0.500\n",
      "Epoch 286 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.587 Acc: 0.793 || Corr: -0.494\n",
      "Epoch 287 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.534 Acc: 0.797 || Corr: -0.479\n",
      "Epoch 288 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.599 Acc: 0.793 || Corr: -0.488\n",
      "Epoch 289 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.595 Acc: 0.792 || Corr: -0.477\n",
      "Epoch 290 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.529 Acc: 0.798 || Corr: -0.481\n",
      "Epoch 291 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.548 Acc: 0.798 || Corr: -0.494\n",
      "Epoch 292 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.513 Acc: 0.798 || Corr: -0.480\n",
      "Epoch 293 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.562 Acc: 0.801 || Corr: -0.482\n",
      "Epoch 294 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.525 Acc: 0.796 || Corr: -0.475\n",
      "Epoch 295 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.475 Acc: 0.800 || Corr: -0.485\n",
      "Epoch 296 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.607 Acc: 0.794 || Corr: -0.498\n",
      "Epoch 297 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.510 Acc: 0.798 || Corr: -0.487\n",
      "Epoch 298 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.491 Acc: 0.800 || Corr: -0.491\n",
      "Epoch 299 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.474 Acc: 0.798 || Corr: -0.484\n",
      "Epoch 300 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.515 Acc: 0.800 || Corr: -0.489\n",
      "Epoch 301 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.447 Acc: 0.803 || Corr: -0.486\n",
      "Epoch 302 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.381 Acc: 0.802 || Corr: -0.499\n",
      "Epoch 303 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.407 Acc: 0.802 || Corr: -0.496\n",
      "Epoch 304 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.543 Acc: 0.801 || Corr: -0.493\n",
      "Epoch 305 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.494 Acc: 0.789 || Corr: -0.483\n",
      "Epoch 306 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.423 Acc: 0.801 || Corr: -0.483\n",
      "Epoch 307 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.549 Acc: 0.793 || Corr: -0.492\n",
      "Epoch 308 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.533 Acc: 0.797 || Corr: -0.478\n",
      "Epoch 309 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.531 Acc: 0.801 || Corr: -0.484\n",
      "Epoch 310 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.508 Acc: 0.800 || Corr: -0.484\n",
      "Epoch 311 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.484 Acc: 0.799 || Corr: -0.484\n",
      "Epoch 312 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.461 Acc: 0.797 || Corr: -0.491\n",
      "Epoch 313 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.593 Acc: 0.793 || Corr: -0.484\n",
      "Epoch 314 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.532 Acc: 0.799 || Corr: -0.479\n",
      "Epoch 315 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.435 Acc: 0.801 || Corr: -0.477\n",
      "Epoch 316 -> [Train] Loss: 0.016 Acc: 0.999 [Val] Loss: 3.470 Acc: 0.801 || Corr: -0.481\n",
      "Epoch 317 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.459 Acc: 0.802 || Corr: -0.489\n",
      "Epoch 318 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.417 Acc: 0.801 || Corr: -0.495\n",
      "Epoch 319 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.579 Acc: 0.799 || Corr: -0.479\n",
      "Epoch 320 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.543 Acc: 0.801 || Corr: -0.483\n",
      "Epoch 321 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.637 Acc: 0.796 || Corr: -0.499\n",
      "Epoch 322 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.612 Acc: 0.798 || Corr: -0.477\n",
      "Epoch 323 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.671 Acc: 0.794 || Corr: -0.498\n",
      "Epoch 324 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.536 Acc: 0.802 || Corr: -0.476\n",
      "Epoch 325 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.538 Acc: 0.799 || Corr: -0.483\n",
      "Epoch 326 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.604 Acc: 0.792 || Corr: -0.481\n",
      "Epoch 327 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.635 Acc: 0.797 || Corr: -0.481\n",
      "Epoch 328 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.555 Acc: 0.801 || Corr: -0.483\n",
      "Epoch 329 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.557 Acc: 0.795 || Corr: -0.474\n",
      "Epoch 330 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.618 Acc: 0.788 || Corr: -0.475\n",
      "Epoch 331 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.542 Acc: 0.800 || Corr: -0.474\n",
      "Epoch 332 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.527 Acc: 0.800 || Corr: -0.491\n",
      "Epoch 333 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.581 Acc: 0.794 || Corr: -0.492\n",
      "Epoch 334 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.518 Acc: 0.797 || Corr: -0.483\n",
      "Epoch 335 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.522 Acc: 0.796 || Corr: -0.484\n",
      "Epoch 336 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.564 Acc: 0.796 || Corr: -0.487\n",
      "Epoch 337 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.626 Acc: 0.792 || Corr: -0.475\n",
      "Epoch 338 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.662 Acc: 0.795 || Corr: -0.473\n",
      "Epoch 339 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.609 Acc: 0.797 || Corr: -0.474\n",
      "Epoch 340 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.597 Acc: 0.796 || Corr: -0.491\n",
      "Epoch 341 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.561 Acc: 0.796 || Corr: -0.476\n",
      "Epoch 342 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.525 Acc: 0.798 || Corr: -0.498\n",
      "Epoch 343 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.478 Acc: 0.797 || Corr: -0.490\n",
      "Epoch 344 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.611 Acc: 0.795 || Corr: -0.497\n",
      "Epoch 345 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.721 Acc: 0.786 || Corr: -0.458\n",
      "Epoch 346 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.642 Acc: 0.792 || Corr: -0.476\n",
      "Epoch 347 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.520 Acc: 0.799 || Corr: -0.468\n",
      "Epoch 348 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.597 Acc: 0.794 || Corr: -0.497\n",
      "Epoch 349 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.620 Acc: 0.793 || Corr: -0.484\n",
      "Epoch 350 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.568 Acc: 0.797 || Corr: -0.483\n",
      "Epoch 351 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.627 Acc: 0.792 || Corr: -0.473\n",
      "Epoch 352 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.642 Acc: 0.787 || Corr: -0.488\n",
      "Epoch 353 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.556 Acc: 0.798 || Corr: -0.462\n",
      "Epoch 354 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.490 Acc: 0.798 || Corr: -0.468\n",
      "Epoch 355 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.535 Acc: 0.800 || Corr: -0.468\n",
      "Epoch 356 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.555 Acc: 0.800 || Corr: -0.482\n",
      "Epoch 357 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.578 Acc: 0.798 || Corr: -0.478\n",
      "Epoch 358 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.695 Acc: 0.789 || Corr: -0.481\n",
      "Epoch 359 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.662 Acc: 0.791 || Corr: -0.464\n",
      "Epoch 360 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.530 Acc: 0.800 || Corr: -0.475\n",
      "Epoch 361 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.690 Acc: 0.793 || Corr: -0.474\n",
      "Epoch 362 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.469 Acc: 0.796 || Corr: -0.480\n",
      "Epoch 363 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.581 Acc: 0.793 || Corr: -0.484\n",
      "Epoch 364 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.579 Acc: 0.796 || Corr: -0.458\n",
      "Epoch 365 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.542 Acc: 0.797 || Corr: -0.471\n",
      "Epoch 366 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.517 Acc: 0.797 || Corr: -0.482\n",
      "Epoch 367 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.678 Acc: 0.786 || Corr: -0.486\n",
      "Epoch 368 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.524 Acc: 0.795 || Corr: -0.484\n",
      "Epoch 369 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.533 Acc: 0.793 || Corr: -0.482\n",
      "Epoch 370 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.588 Acc: 0.796 || Corr: -0.448\n",
      "Epoch 371 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.605 Acc: 0.798 || Corr: -0.467\n",
      "Epoch 372 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.484 Acc: 0.801 || Corr: -0.464\n",
      "Epoch 373 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.437 Acc: 0.802 || Corr: -0.458\n",
      "Epoch 374 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.486 Acc: 0.799 || Corr: -0.477\n",
      "Epoch 375 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.525 Acc: 0.800 || Corr: -0.467\n",
      "Epoch 376 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.507 Acc: 0.799 || Corr: -0.458\n",
      "Epoch 377 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.609 Acc: 0.793 || Corr: -0.504\n",
      "Epoch 378 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.475 Acc: 0.798 || Corr: -0.492\n",
      "Epoch 379 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.409 Acc: 0.801 || Corr: -0.468\n",
      "Epoch 380 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.471 Acc: 0.802 || Corr: -0.469\n",
      "Epoch 381 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.428 Acc: 0.802 || Corr: -0.473\n",
      "Epoch 382 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.421 Acc: 0.800 || Corr: -0.479\n",
      "Epoch 383 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.468 Acc: 0.799 || Corr: -0.480\n",
      "Epoch 384 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.443 Acc: 0.798 || Corr: -0.475\n",
      "Epoch 385 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.433 Acc: 0.802 || Corr: -0.475\n",
      "Epoch 386 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.430 Acc: 0.799 || Corr: -0.482\n",
      "Epoch 387 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.414 Acc: 0.799 || Corr: -0.495\n",
      "Epoch 388 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.506 Acc: 0.794 || Corr: -0.482\n",
      "Epoch 389 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.432 Acc: 0.799 || Corr: -0.482\n",
      "Epoch 390 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.447 Acc: 0.799 || Corr: -0.478\n",
      "Epoch 391 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.459 Acc: 0.799 || Corr: -0.476\n",
      "Epoch 392 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.451 Acc: 0.799 || Corr: -0.474\n",
      "Epoch 393 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.432 Acc: 0.799 || Corr: -0.477\n",
      "Epoch 394 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.582 Acc: 0.791 || Corr: -0.486\n",
      "Epoch 395 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.550 Acc: 0.792 || Corr: -0.481\n",
      "Epoch 396 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.436 Acc: 0.801 || Corr: -0.484\n",
      "Epoch 397 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.525 Acc: 0.798 || Corr: -0.469\n",
      "Epoch 398 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.554 Acc: 0.794 || Corr: -0.484\n",
      "Epoch 399 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.569 Acc: 0.791 || Corr: -0.477\n",
      "Epoch 400 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.478 Acc: 0.797 || Corr: -0.474\n",
      "Epoch 401 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.532 Acc: 0.795 || Corr: -0.490\n",
      "Epoch 402 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.355 Acc: 0.803 || Corr: -0.488\n",
      "Epoch 403 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.615 Acc: 0.789 || Corr: -0.488\n",
      "Epoch 404 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.623 Acc: 0.793 || Corr: -0.488\n",
      "Epoch 405 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.640 Acc: 0.787 || Corr: -0.498\n",
      "Epoch 406 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.445 Acc: 0.802 || Corr: -0.506\n",
      "Epoch 407 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.477 Acc: 0.799 || Corr: -0.484\n",
      "Epoch 408 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.482 Acc: 0.801 || Corr: -0.488\n",
      "Epoch 409 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.426 Acc: 0.800 || Corr: -0.485\n",
      "Epoch 410 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.448 Acc: 0.802 || Corr: -0.489\n",
      "Epoch 411 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.388 Acc: 0.803 || Corr: -0.498\n",
      "Epoch 412 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.395 Acc: 0.803 || Corr: -0.501\n",
      "Epoch 413 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.409 Acc: 0.801 || Corr: -0.485\n",
      "Epoch 414 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.339 Acc: 0.802 || Corr: -0.485\n",
      "Epoch 415 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.522 Acc: 0.794 || Corr: -0.498\n",
      "Epoch 416 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.483 Acc: 0.795 || Corr: -0.498\n",
      "Epoch 417 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.536 Acc: 0.793 || Corr: -0.490\n",
      "Epoch 418 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.452 Acc: 0.797 || Corr: -0.497\n",
      "Epoch 419 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.522 Acc: 0.795 || Corr: -0.491\n",
      "Epoch 420 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.538 Acc: 0.790 || Corr: -0.476\n",
      "Epoch 421 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.443 Acc: 0.802 || Corr: -0.502\n",
      "Epoch 422 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.510 Acc: 0.801 || Corr: -0.496\n",
      "Epoch 423 -> [Train] Loss: 0.009 Acc: 0.999 [Val] Loss: 3.466 Acc: 0.800 || Corr: -0.503\n",
      "Epoch 424 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.486 Acc: 0.799 || Corr: -0.500\n",
      "Epoch 425 -> [Train] Loss: 0.013 Acc: 0.999 [Val] Loss: 3.509 Acc: 0.796 || Corr: -0.500\n",
      "Epoch 426 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.518 Acc: 0.795 || Corr: -0.499\n",
      "Epoch 427 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.473 Acc: 0.797 || Corr: -0.493\n",
      "Epoch 428 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.527 Acc: 0.791 || Corr: -0.498\n",
      "Epoch 429 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.496 Acc: 0.796 || Corr: -0.485\n",
      "Epoch 430 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.569 Acc: 0.793 || Corr: -0.485\n",
      "Epoch 431 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.473 Acc: 0.798 || Corr: -0.491\n",
      "Epoch 432 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.496 Acc: 0.797 || Corr: -0.484\n",
      "Epoch 433 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.486 Acc: 0.798 || Corr: -0.503\n",
      "Epoch 434 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.533 Acc: 0.800 || Corr: -0.492\n",
      "Epoch 435 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.572 Acc: 0.795 || Corr: -0.488\n",
      "Epoch 436 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.542 Acc: 0.796 || Corr: -0.494\n",
      "Epoch 437 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.522 Acc: 0.796 || Corr: -0.498\n",
      "Epoch 438 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.594 Acc: 0.790 || Corr: -0.502\n",
      "Epoch 439 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.591 Acc: 0.795 || Corr: -0.495\n",
      "Epoch 440 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.657 Acc: 0.789 || Corr: -0.500\n",
      "Epoch 441 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.671 Acc: 0.789 || Corr: -0.505\n",
      "Epoch 442 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.604 Acc: 0.791 || Corr: -0.496\n",
      "Epoch 443 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.538 Acc: 0.796 || Corr: -0.514\n",
      "Epoch 444 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.652 Acc: 0.794 || Corr: -0.496\n",
      "Epoch 445 -> [Train] Loss: 0.009 Acc: 0.999 [Val] Loss: 3.535 Acc: 0.797 || Corr: -0.492\n",
      "Epoch 446 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.570 Acc: 0.796 || Corr: -0.508\n",
      "Epoch 447 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.622 Acc: 0.789 || Corr: -0.510\n",
      "Epoch 448 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.661 Acc: 0.788 || Corr: -0.513\n",
      "Epoch 449 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.669 Acc: 0.793 || Corr: -0.509\n",
      "Epoch 450 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.575 Acc: 0.797 || Corr: -0.507\n",
      "Epoch 451 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.663 Acc: 0.793 || Corr: -0.520\n",
      "Epoch 452 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.553 Acc: 0.796 || Corr: -0.505\n",
      "Epoch 453 -> [Train] Loss: 0.009 Acc: 0.999 [Val] Loss: 3.659 Acc: 0.790 || Corr: -0.508\n",
      "Epoch 454 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.520 Acc: 0.800 || Corr: -0.498\n",
      "Epoch 455 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.533 Acc: 0.798 || Corr: -0.508\n",
      "Epoch 456 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.525 Acc: 0.799 || Corr: -0.514\n",
      "Epoch 457 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.586 Acc: 0.798 || Corr: -0.510\n",
      "Epoch 458 -> [Train] Loss: 0.009 Acc: 0.999 [Val] Loss: 3.668 Acc: 0.794 || Corr: -0.507\n",
      "Epoch 459 -> [Train] Loss: 0.009 Acc: 0.999 [Val] Loss: 3.572 Acc: 0.799 || Corr: -0.499\n",
      "Epoch 460 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.596 Acc: 0.798 || Corr: -0.511\n",
      "Epoch 461 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.589 Acc: 0.798 || Corr: -0.513\n",
      "Epoch 462 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.537 Acc: 0.800 || Corr: -0.500\n",
      "Epoch 463 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.671 Acc: 0.793 || Corr: -0.497\n",
      "Epoch 464 -> [Train] Loss: 0.009 Acc: 0.999 [Val] Loss: 3.594 Acc: 0.799 || Corr: -0.501\n",
      "Epoch 465 -> [Train] Loss: 0.009 Acc: 0.999 [Val] Loss: 3.615 Acc: 0.798 || Corr: -0.506\n",
      "Epoch 466 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.507 Acc: 0.802 || Corr: -0.474\n",
      "Epoch 467 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.602 Acc: 0.798 || Corr: -0.503\n",
      "Epoch 468 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.563 Acc: 0.801 || Corr: -0.517\n",
      "Epoch 469 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.559 Acc: 0.800 || Corr: -0.502\n",
      "Epoch 470 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.597 Acc: 0.798 || Corr: -0.503\n",
      "Epoch 471 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.688 Acc: 0.797 || Corr: -0.500\n",
      "Epoch 472 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.591 Acc: 0.801 || Corr: -0.506\n",
      "Epoch 473 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.559 Acc: 0.801 || Corr: -0.513\n",
      "Epoch 474 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.557 Acc: 0.800 || Corr: -0.504\n",
      "Epoch 475 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.625 Acc: 0.800 || Corr: -0.507\n",
      "Epoch 476 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.576 Acc: 0.800 || Corr: -0.507\n",
      "Epoch 477 -> [Train] Loss: 0.009 Acc: 0.999 [Val] Loss: 3.552 Acc: 0.804 || Corr: -0.496\n",
      "Epoch 478 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.753 Acc: 0.795 || Corr: -0.489\n",
      "Epoch 479 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.574 Acc: 0.800 || Corr: -0.473\n",
      "Epoch 480 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.670 Acc: 0.798 || Corr: -0.522\n",
      "Epoch 481 -> [Train] Loss: 0.009 Acc: 0.999 [Val] Loss: 3.689 Acc: 0.795 || Corr: -0.519\n",
      "Epoch 482 -> [Train] Loss: 0.008 Acc: 0.999 [Val] Loss: 3.641 Acc: 0.801 || Corr: -0.502\n",
      "Epoch 483 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.699 Acc: 0.798 || Corr: -0.498\n",
      "Epoch 484 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.631 Acc: 0.799 || Corr: -0.502\n",
      "Epoch 485 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.520 Acc: 0.803 || Corr: -0.478\n",
      "Epoch 486 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.666 Acc: 0.800 || Corr: -0.495\n",
      "Epoch 487 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.682 Acc: 0.799 || Corr: -0.507\n",
      "Epoch 488 -> [Train] Loss: 0.009 Acc: 0.999 [Val] Loss: 3.623 Acc: 0.798 || Corr: -0.514\n",
      "Epoch 489 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.686 Acc: 0.800 || Corr: -0.499\n",
      "Epoch 490 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.564 Acc: 0.800 || Corr: -0.478\n",
      "Epoch 491 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.575 Acc: 0.803 || Corr: -0.484\n",
      "Epoch 492 -> [Train] Loss: 0.011 Acc: 0.999 [Val] Loss: 3.608 Acc: 0.803 || Corr: -0.492\n",
      "Epoch 493 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.541 Acc: 0.802 || Corr: -0.479\n",
      "Epoch 494 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.692 Acc: 0.800 || Corr: -0.520\n",
      "Epoch 495 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.724 Acc: 0.799 || Corr: -0.502\n",
      "Epoch 496 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.678 Acc: 0.800 || Corr: -0.511\n",
      "Epoch 497 -> [Train] Loss: 0.009 Acc: 0.999 [Val] Loss: 3.701 Acc: 0.800 || Corr: -0.506\n",
      "Epoch 498 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.596 Acc: 0.800 || Corr: -0.478\n",
      "Epoch 499 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.717 Acc: 0.799 || Corr: -0.497\n",
      "CPU times: user 13h 29min 22s, sys: 1h 52min 55s, total: 15h 22min 18s\n",
      "Wall time: 16h 30min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(config.epochs):\n",
    "    ## Training\n",
    "    for batch in dst_train_rdy.as_numpy_iterator():\n",
    "        state = train_step(state, batch)\n",
    "        state = state.replace(params=clip_layer(state.params, \"GDN\", a_min=0))\n",
    "        # state = compute_metrics(state=state, batch=batch)\n",
    "        # break\n",
    "\n",
    "    ## Log the metrics\n",
    "    for name, value in state.metrics.compute().items():\n",
    "        metrics_history[f\"train_{name}\"].append(value)\n",
    "    \n",
    "    ## Empty the metrics\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "\n",
    "    ## Evaluation (Classification)\n",
    "    for batch in dst_val_rdy.as_numpy_iterator():\n",
    "        state = val_step(state=state, batch=batch)\n",
    "        # break\n",
    "    for name, value in state.metrics.compute().items():\n",
    "        metrics_history[f\"val_{name}\"].append(value)\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "\n",
    "    ## Evaluation (Correlation)\n",
    "    correlation = obtain_correlation(state, dst_tid2013.as_numpy_iterator())\n",
    "    metrics_history[\"correlation\"].append(correlation)\n",
    "    \n",
    "    ## Checkpointing\n",
    "    if metrics_history[\"val_loss\"][-1] <= min(metrics_history[\"val_loss\"]):\n",
    "        orbax_checkpointer.save(os.path.join(wandb.run.dir, \"model-best\"), state, save_args=save_args, force=True) # force=True means allow overwritting.\n",
    "\n",
    "    wandb.log({f\"{k}\": wandb.Histogram(v) for k, v in flatten_params(state.params).items()}, commit=False)\n",
    "    wandb.log({\"epoch\": epoch+1, **{name:values[-1] for name, values in metrics_history.items()}})\n",
    "    print(f'Epoch {epoch} -> [Train] Loss: {metrics_history[\"train_loss\"][-1]:.3f} Acc: {metrics_history[\"train_accuracy\"][-1]:.3f} [Val] Loss: {metrics_history[\"val_loss\"][-1]:.3f} Acc: {metrics_history[\"val_accuracy\"][-1]:.3f} || Corr: {metrics_history[\"correlation\"][-1]:.3f}')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbax_checkpointer.save(os.path.join(wandb.run.dir, \"model-final\"), state, save_args=save_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da5141a55de43f9a5c077a362efe5e2ae0cb795b0fc8676e62dbd4f64287ec27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
