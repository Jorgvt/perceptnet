{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os; os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from fastcore.xtras import Path\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "import scipy.stats as stats\n",
    "\n",
    "from perceptnet.networks import *\n",
    "from iqadatasets.datasets.tid2013 import TID2013\n",
    "\n",
    "from flayers.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluatePerceptuality(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Evaluates a perceptual model that is part of another model.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 dst, # Dataset to be evaluated.\n",
    "                 model, # Model to be evaluated.\n",
    "                 name=None, # Name to prepend to the logged metrics.\n",
    "                 ):\n",
    "        self.dst = dst\n",
    "        self.eval_model = model\n",
    "        self.name = \"\" if name is None else name+\"_\"\n",
    "        \n",
    "    def on_epoch_end(self,\n",
    "                     epoch, \n",
    "                     logs=None):\n",
    "        distances, moses = [], []\n",
    "        for i, data in enumerate(self.dst):\n",
    "            img, dist_img, mos = data\n",
    "            features_original = self.eval_model(img, training=False)\n",
    "            features_distorted = self.eval_model(dist_img, training=False)\n",
    "            l2 = (features_original-features_distorted)**2\n",
    "            l2 = tf.reduce_sum(l2, axis=[1,2,3])\n",
    "            l2 = tf.sqrt(l2)\n",
    "            distances.extend(l2)\n",
    "            moses.extend(mos)\n",
    "        pearson = stats.pearsonr(distances, moses)[0]\n",
    "        spearman = stats.spearmanr(distances, moses)[0]\n",
    "        wandb.log({f\"{self.name}Pearson\": pearson,\n",
    "                   f\"{self.name}Spearman\": spearman}, commit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'epochs':500,\n",
    "        'learning_rate':3e-4,\n",
    "        'batch_size':64,\n",
    "        'kernel_initializer':'ones',\n",
    "        'gdn_kernel_size':1,\n",
    "        'learnable_undersampling':False,\n",
    "        'verbose': 0,\n",
    "        'dataset': 'cifar10', # imagenet / imagenette / cifar10 / cifar100,\n",
    "        'validation_split': 0.2,\n",
    "        'seed': 42\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project='PerceptNetClassification',\n",
    "            notes=\"\",\n",
    "            tags=[],\n",
    "            name = 'Baseline',\n",
    "            config=config,\n",
    "            job_type=\"training\",\n",
    "            mode=\"online\",\n",
    "            )\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet():\n",
    "    path_data = Path(\"/lustre/ific.uv.es/ml/uv075/Databases/imagenet_images/\")\n",
    "    dst_train = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"training\",\n",
    "                seed=config.seed,\n",
    "                shuffle=True,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    dst_val = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"validation\",\n",
    "                seed=config.seed,\n",
    "                shuffle=False,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    return dst_train, dst_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenette():\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    dst_train, info = tfds.load(\"imagenette/320px-v2\", split=f\"train[:{config.validation_split*100:.0f}%]\", with_info=True, shuffle_files=True)\n",
    "    dst_val = tfds.load(\"imagenette/320px-v2\", split=f\"train[{config.validation_split*100:.0f}%:]\", with_info=False, shuffle_files=False)\n",
    "    def prepare_tfds(item):\n",
    "        x, y = item[\"image\"], item[\"label\"]\n",
    "        x = tf.image.resize_with_crop_or_pad(x, 256, 256)\n",
    "        return x, y\n",
    "    dst_train = dst_train.map(prepare_tfds)\n",
    "    dst_val = dst_val.map(prepare_tfds)\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size), info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10():\n",
    "    from tensorflow.keras.datasets import cifar10\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config.validation_split, random_state=config.seed)\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100():\n",
    "    from tensorflow.keras.datasets import cifar100\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config.validation_split, random_state=config.seed)\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset == \"imagenet\":\n",
    "    dst_train, dst_val = load_imagenet()\n",
    "    N_CLASSES = len(dst_train.class_names)\n",
    "elif config.dataset == \"cifar10\":\n",
    "    dst_train, dst_val = load_cifar10()\n",
    "    N_CLASSES = 10\n",
    "elif config.dataset == \"cifar100\":\n",
    "    dst_train, dst_val = load_cifar100()\n",
    "    N_CLASSES = 100\n",
    "elif config.dataset == \"imagenette\":\n",
    "    dst_train, dst_val, N_CLASSES = load_imagenette()\n",
    "else:\n",
    "    raise ValueError(\"Dataset parameter not allowed.\")\n",
    "print(f\"Training on {config.dataset} with {N_CLASSES} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dst_train))\n",
    "input_shape = x[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.summary[\"N_CLASSES\"] = N_CLASSES\n",
    "wandb.run.summary[\"Input_Shape\"] = input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_tid2013 = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/TID/TID2013\", exclude_imgs=[25]).dataset.batch(config.batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train = dst_train.map(lambda x,y: (normalization_layer(x), y))\n",
    "dst_val = dst_val.map(lambda x,y: (normalization_layer(x), y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "dst_train = dst_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "dst_val = dst_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PerceptNetExpGDNGaussian(kernel_initializer=config.kernel_initializer, gdn_kernel_size=config.gdn_kernel_size)\n",
    "# model = PerceptNetExpGaborLast(kernel_initializer=config.kernel_initializer, gdn_kernel_size=config.gdn_kernel_size)\n",
    "feature_extractor = PerceptNet(kernel_initializer=config.kernel_initializer, gdn_kernel_size=config.gdn_kernel_size, learnable_undersampling=config.learnable_undersampling)\n",
    "model = tf.keras.Sequential([\n",
    "    feature_extractor,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(N_CLASSES, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=config.learning_rate),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log the number of trainable weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset == \"imagenet\" or config.dataset == \"imagenette\":\n",
    "    model.build((None,256,256,3))\n",
    "elif config.dataset == \"cifar10\" or config.dataset == \"cifar100\":\n",
    "    model.build((None,32,32,3))\n",
    "else: #Â If it isn't a known dataset, just call the model on a batch of data to build the weights.\n",
    "    pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trainable_vars = np.sum([np.prod(v.shape) for v in model.trainable_variables])\n",
    "wandb.run.summary[\"trainable_parameters\"] = num_trainable_vars\n",
    "num_vars = np.sum([np.prod(v.shape) for v in model.weights])\n",
    "wandb.run.summary[\"parameters\"] = int(num_vars)\n",
    "print(f\"Trainable: {num_trainable_vars} | Vars: {num_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(dst_train, \n",
    "                    epochs=config.epochs, \n",
    "                    validation_data=dst_val,\n",
    "                    callbacks=[EvaluatePerceptuality(dst=dst_tid2013, model=feature_extractor, name=\"TID2013\"),\n",
    "                               WandbMetricsLogger(log_freq=\"epoch\"),\n",
    "                               WandbModelCheckpoint(filepath=os.path.join(wandb.run.dir, \"model-best\"),\n",
    "                                                    monitor=\"val_loss\",\n",
    "                                                    save_best_only=True,\n",
    "                                                    save_weights_only=True,\n",
    "                                                    mode=\"min\")\n",
    "                               ],\n",
    "                    verbose=config.verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da5141a55de43f9a5c077a362efe5e2ae0cb795b0fc8676e62dbd4f64287ec27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
