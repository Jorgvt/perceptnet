{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os; os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from fastcore.xtras import Path\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "import scipy.stats as stats\n",
    "\n",
    "from perceptnet.networks import *\n",
    "from iqadatasets.datasets.tid2013 import TID2013\n",
    "\n",
    "from flayers.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluatePerceptuality(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Evaluates a perceptual model that is part of another model.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 dst, # Dataset to be evaluated.\n",
    "                 model, # Model to be evaluated.\n",
    "                 name=None, # Name to prepend to the logged metrics.\n",
    "                 ):\n",
    "        self.dst = dst\n",
    "        self.eval_model = model\n",
    "        self.name = \"\" if name is None else name+\"_\"\n",
    "        \n",
    "    def on_epoch_end(self,\n",
    "                     epoch, \n",
    "                     logs=None):\n",
    "        distances, moses = [], []\n",
    "        for i, data in enumerate(self.dst):\n",
    "            img, dist_img, mos = data\n",
    "            features_original = self.eval_model(img, training=False)\n",
    "            features_distorted = self.eval_model(dist_img, training=False)\n",
    "            l2 = (features_original-features_distorted)**2\n",
    "            l2 = tf.reduce_sum(l2, axis=[1,2,3])\n",
    "            l2 = tf.sqrt(l2)\n",
    "            distances.extend(l2)\n",
    "            moses.extend(mos)\n",
    "        pearson = stats.pearsonr(distances, moses)[0]\n",
    "        spearman = stats.spearmanr(distances, moses)[0]\n",
    "        wandb.log({f\"{self.name}Pearson\": pearson,\n",
    "                   f\"{self.name}Spearman\": spearman}, commit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id = \"7cakiknt\" # imagenet\n",
    "# id = \"psmk04za\" # cifar10\n",
    "# id = \"0cnhyn1v\" # cifar100\n",
    "id = \"iupl77hz\" # imagenette\n",
    "MORE_EPOCHS = 500\n",
    "# MORE_EPOCHS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: jorgvt. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/lhome/ext/uv075/uv0752/perceptnet/Notebooks/11_Classification/wandb/run-20230626_111307-iupl77hz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/jorgvt/PerceptNetClassification/runs/iupl77hz\" target=\"_blank\">Baseline</a></strong> to <a href=\"https://wandb.ai/jorgvt/PerceptNetClassification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/jorgvt/PerceptNetClassification\" target=\"_blank\">https://wandb.ai/jorgvt/PerceptNetClassification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/jorgvt/PerceptNetClassification/runs/iupl77hz\" target=\"_blank\">https://wandb.ai/jorgvt/PerceptNetClassification/runs/iupl77hz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='PerceptNetClassification',\n",
    "            id=id,\n",
    "            mode=\"online\",\n",
    "            resume=\"allow\",\n",
    "            )\n",
    "config = wandb.config\n",
    "config.epochs += MORE_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet():\n",
    "    path_data = Path(\"/lustre/ific.uv.es/ml/uv075/Databases/imagenet_images/\")\n",
    "    dst_train = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"training\",\n",
    "                seed=config.seed,\n",
    "                shuffle=True,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    dst_val = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"validation\",\n",
    "                seed=config.seed,\n",
    "                shuffle=False,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    return dst_train, dst_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenette():\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    dst_train, info = tfds.load(\"imagenette/320px-v2\", split=f\"train[:{config.validation_split*100:.0f}%]\", with_info=True, shuffle_files=True)\n",
    "    dst_val = tfds.load(\"imagenette/320px-v2\", split=f\"train[{config.validation_split*100:.0f}%:]\", with_info=False, shuffle_files=False)\n",
    "    def prepare_tfds(item):\n",
    "        x, y = item[\"image\"], item[\"label\"]\n",
    "        x = tf.image.resize_with_crop_or_pad(x, 256, 256)\n",
    "        return x, y\n",
    "    dst_train = dst_train.map(prepare_tfds)\n",
    "    dst_val = dst_val.map(prepare_tfds)\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size), info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10():\n",
    "    from tensorflow.keras.datasets import cifar10\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config.validation_split, random_state=config.seed)\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100():\n",
    "    from tensorflow.keras.datasets import cifar100\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config.validation_split, random_state=config.seed)\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on imagenette with 10 classes.\n"
     ]
    }
   ],
   "source": [
    "if config.dataset == \"imagenet\":\n",
    "    dst_train, dst_val = load_imagenet()\n",
    "    N_CLASSES = len(dst_train.class_names)\n",
    "elif config.dataset == \"cifar10\":\n",
    "    dst_train, dst_val = load_cifar10()\n",
    "    N_CLASSES = 10\n",
    "elif config.dataset == \"cifar100\":\n",
    "    dst_train, dst_val = load_cifar100()\n",
    "    N_CLASSES = 100\n",
    "elif config.dataset == \"imagenette\":\n",
    "    dst_train, dst_val, N_CLASSES = load_imagenette()\n",
    "else:\n",
    "    raise ValueError(\"Dataset parameter not allowed.\")\n",
    "print(f\"Training on {config.dataset} with {N_CLASSES} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([256, 256, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dst_train))\n",
    "input_shape = x[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_tid2013 = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/TID/TID2013\", exclude_imgs=[25]).dataset.batch(config.batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train = dst_train.map(lambda x,y: (normalization_layer(x), y))\n",
    "dst_val = dst_val.map(lambda x,y: (normalization_layer(x), y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "dst_train = dst_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "dst_val = dst_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = PerceptNet(kernel_initializer=config.kernel_initializer, gdn_kernel_size=config.gdn_kernel_size, learnable_undersampling=config.learnable_undersampling)\n",
    "model = tf.keras.Sequential([\n",
    "    feature_extractor,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(N_CLASSES, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=config.learning_rate),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset == \"imagenet\" or config.dataset == \"imagenette\":\n",
    "    model.build((None,256,256,3))\n",
    "elif config.dataset == \"cifar10\" or config.dataset == \"cifar100\":\n",
    "    model.build((None,32,32,3))\n",
    "else: # If it isn't a known dataset, just call the model on a batch of data to build the weights.\n",
    "    pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   3 of 3 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "best_model = wandb.run.use_artifact(f\"run_{wandb.run.id}_model:latest\", type=\"model\")\n",
    "best_model_dir = best_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2b31fee781f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(f\"{best_model_dir}/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 999)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = wandb.run.summary._as_dict()\n",
    "summary[\"epoch/epoch\"], summary[\"_step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING When using `save_best_only`, ensure that the `filepath` argument contains formatting placeholders like `{epoch:02d}` or `{batch:02d}`. This ensures correct interpretation of the logged artifacts.\n",
      "wandb: WARNING A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dst_train, \n",
    "                    epochs=config.epochs, \n",
    "                    initial_epoch=summary[\"epoch/epoch\"]+1,\n",
    "                    validation_data=dst_val,\n",
    "                    callbacks=[EvaluatePerceptuality(dst=dst_tid2013, model=feature_extractor, name=\"TID2013\"),\n",
    "                               WandbMetricsLogger(log_freq=\"epoch\", initial_global_step=summary[\"_step\"]+1),\n",
    "                               WandbModelCheckpoint(filepath=\"model-best\",\n",
    "                                                    monitor=\"val_loss\",\n",
    "                                                    save_best_only=True,\n",
    "                                                    save_weights_only=True,\n",
    "                                                    mode=\"min\")\n",
    "                               ],\n",
    "                    verbose=config.verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'TypeError'>",
     "evalue": "get_range() missing 1 required positional argument: 'session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:3671\u001b[0m, in \u001b[0;36mfinish\u001b[0;34m(exit_code, quiet)\u001b[0m\n\u001b[1;32m   3661\u001b[0m \u001b[38;5;124;03m\"\"\"Marks a run as finished, and finishes uploading all data.\u001b[39;00m\n\u001b[1;32m   3662\u001b[0m \n\u001b[1;32m   3663\u001b[0m \u001b[38;5;124;03mThis is used when creating multiple runs in the same process.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3668\u001b[0m \u001b[38;5;124;03m    quiet: Set to true to minimize log output\u001b[39;00m\n\u001b[1;32m   3669\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mrun:\n\u001b[0;32m-> 3671\u001b[0m     \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexit_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:370\u001b[0m, in \u001b[0;36m_run_decorator._noop.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mtermwarn(message, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mDummy()\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:333\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:1835\u001b[0m, in \u001b[0;36mRun.finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[38;5;129m@_run_decorator\u001b[39m\u001b[38;5;241m.\u001b[39m_noop\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;129m@_run_decorator\u001b[39m\u001b[38;5;241m.\u001b[39m_attach\n\u001b[1;32m   1823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinish\u001b[39m(\n\u001b[1;32m   1824\u001b[0m     \u001b[38;5;28mself\u001b[39m, exit_code: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, quiet: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1825\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1826\u001b[0m     \u001b[38;5;124;03m\"\"\"Marks a run as finished, and finishes uploading all data.\u001b[39;00m\n\u001b[1;32m   1827\u001b[0m \n\u001b[1;32m   1828\u001b[0m \u001b[38;5;124;03m    This is used when creating multiple runs in the same process. We automatically\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m \u001b[38;5;124;03m        quiet: Set to true to minimize log output\u001b[39;00m\n\u001b[1;32m   1834\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:1848\u001b[0m, in \u001b[0;36mRun._finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown_hooks:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m==\u001b[39m TeardownStage\u001b[38;5;241m.\u001b[39mEARLY:\n\u001b[0;32m-> 1848\u001b[0m         \u001b[43mhook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atexit_cleanup(exit_code\u001b[38;5;241m=\u001b[39mexit_code)\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl\u001b[38;5;241m.\u001b[39m_global_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:406\u001b[0m, in \u001b[0;36m_WandbInit._jupyter_teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"Teardown hooks and display saving, called with wandb.finish.\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m ipython \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook\u001b[38;5;241m.\u001b[39mshell\n\u001b[0;32m--> 406\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotebook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook\u001b[38;5;241m.\u001b[39msave_ipynb():\n\u001b[1;32m    408\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mlog_code(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/jupyter.py:447\u001b[0m, in \u001b[0;36mNotebook.save_history\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    446\u001b[0m cells \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 447\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(hist) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39msave_code:\n\u001b[1;32m    449\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot saving jupyter history\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_range() missing 1 required positional argument: 'session'"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da5141a55de43f9a5c077a362efe5e2ae0cb795b0fc8676e62dbd4f64287ec27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
