{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os; os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:24:51.647068: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:25:35.855067: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "2023-09-20 16:25:35.855357: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:1: failed initializing StreamExecutor for CUDA device ordinal 1: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from typing import Any, Callable, Sequence, Union\n",
    "import numpy as np\n",
    "from fastcore.xtras import Path\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import jax\n",
    "from jax import lax, random, numpy as jnp\n",
    "from flax.core import freeze, unfreeze, FrozenDict\n",
    "from flax import linen as nn\n",
    "from flax import struct\n",
    "from flax.training import train_state\n",
    "from flax.training import orbax_utils\n",
    "\n",
    "import optax\n",
    "import orbax.checkpoint\n",
    "\n",
    "from clu import metrics\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "from einops import reduce, rearrange\n",
    "import wandb\n",
    "from iqadatasets.datasets import *\n",
    "from fxlayers.layers import *\n",
    "from fxlayers.initializers import mean\n",
    "from JaxPlayground.utils.constraints import *\n",
    "from JaxPlayground.utils.wandb import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'epochs':500,\n",
    "        'learning_rate':3e-4,\n",
    "        'batch_size':64,\n",
    "        'kernel_initializer':'ones',\n",
    "        'gdn_kernel_size':1,\n",
    "        'learnable_undersampling':False,\n",
    "        'verbose': 0,\n",
    "        'dataset': 'cifar10', # imagenet / imagenette / cifar10 / cifar100,\n",
    "        'validation_split': 0.2,\n",
    "        'seed': 42,\n",
    "        'GAP': False,\n",
    "        'use_bias': False,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project='PerceptNetClassification_JaX',\n",
    "            notes=\"\",\n",
    "            tags=[],\n",
    "            name = 'Baseline-Flatten-NoBias',\n",
    "            config=config,\n",
    "            job_type=\"training\",\n",
    "            mode=\"disabled\",\n",
    "            )\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet():\n",
    "    path_data = Path(\"/lustre/ific.uv.es/ml/uv075/Databases/imagenet_images/\")\n",
    "    dst_train = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"training\",\n",
    "                seed=config.seed,\n",
    "                shuffle=True,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    dst_val = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"validation\",\n",
    "                seed=config.seed,\n",
    "                shuffle=False,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    return dst_train, dst_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenette():\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    dst_train, info = tfds.load(\"imagenette/320px-v2\", split=f\"train[:{(1-config.validation_split)*100:.0f}%]\", with_info=True, shuffle_files=True)\n",
    "    dst_val = tfds.load(\"imagenette/320px-v2\", split=f\"train[{(1-config.validation_split)*100:.0f}%:]\", with_info=False, shuffle_files=False)\n",
    "    def prepare_tfds(item):\n",
    "        x, y = item[\"image\"], item[\"label\"]\n",
    "        x = tf.image.resize_with_crop_or_pad(x, 256, 256)\n",
    "        return x, y\n",
    "    dst_train = dst_train.map(prepare_tfds)\n",
    "    dst_val = dst_val.map(prepare_tfds)\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size), info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10():\n",
    "    from tensorflow.keras.datasets import cifar10\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config.validation_split, random_state=config.seed)\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100():\n",
    "    from tensorflow.keras.datasets import cifar100\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config.validation_split, random_state=config.seed)\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cifar10 with 10 classes.\n"
     ]
    }
   ],
   "source": [
    "if config.dataset == \"imagenet\":\n",
    "    dst_train, dst_val = load_imagenet()\n",
    "    N_CLASSES = len(dst_train.class_names)\n",
    "elif config.dataset == \"cifar10\":\n",
    "    dst_train, dst_val = load_cifar10()\n",
    "    N_CLASSES = 10\n",
    "elif config.dataset == \"cifar100\":\n",
    "    dst_train, dst_val = load_cifar100()\n",
    "    N_CLASSES = 100\n",
    "elif config.dataset == \"imagenette\":\n",
    "    dst_train, dst_val, N_CLASSES = load_imagenette()\n",
    "else:\n",
    "    raise ValueError(\"Dataset parameter not allowed.\")\n",
    "print(f\"Training on {config.dataset} with {N_CLASSES} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dst_train))\n",
    "input_shape = x[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.summary[\"N_CLASSES\"] = N_CLASSES\n",
    "wandb.run.summary[\"Input_Shape\"] = tuple(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_tid2013 = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/TID/TID2013\").dataset\\\n",
    "                                                                              .batch(config.batch_size)\\\n",
    "                                                                              .prefetch(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train = dst_train.map(lambda x,y: (tf.cast(x, tf.float32)/255.0, y[:,0]))\n",
    "dst_val = dst_val.map(lambda x,y: (tf.cast(x, tf.float32)/255.0, y[:,0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "dst_train_rdy = dst_train.cache().prefetch(buffer_size=1)\n",
    "dst_val_rdy = dst_val.cache().prefetch(buffer_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDN(nn.Module):\n",
    "    \"\"\"Generalized Divisive Normalization.\"\"\"\n",
    "    kernel_size: Union[int, Sequence[int]]\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    apply_independently: bool = False\n",
    "    # kernel_init: Callable = nn.initializers.lecun_normal()\n",
    "    kernel_init: Callable = mean()\n",
    "    bias_init: Callable = nn.initializers.ones_init()\n",
    "    alpha: float = 2.\n",
    "    epsilon: float = 1/2 # Exponential of the denominator\n",
    "    eps: float = 1e-6 # Numerical stability in the denominator\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 ):\n",
    "        denom = nn.Conv(features=inputs.shape[-1], # Same output channels as input\n",
    "                        kernel_size=self.kernel_size if isinstance(self.kernel_size, Sequence) else [self.kernel_size]*2, \n",
    "                        strides=self.strides, \n",
    "                        padding=self.padding,\n",
    "                        feature_group_count=inputs.shape[-1] if self.apply_independently else 1,\n",
    "                        kernel_init=self.kernel_init, \n",
    "                        bias_init=self.bias_init)(jnp.clip(inputs**self.alpha, a_min=1e-5))\n",
    "        return inputs / (denom**self.epsilon + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNet(nn.Module):\n",
    "    \"\"\"IQA model inspired by the visual system.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=True)(inputs)\n",
    "        outputs = nn.Conv(features=3, kernel_size=(1,1), strides=1, padding=\"SAME\", use_bias=config.use_bias)(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        outputs = nn.Conv(features=6, kernel_size=(5,5), strides=1, padding=\"SAME\", use_bias=config.use_bias)(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        outputs = nn.Conv(features=128, kernel_size=(5,5), strides=1, padding=\"SAME\", use_bias=config.use_bias)(outputs)\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 ):\n",
    "        outputs = nn.Dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNetClassifier(nn.Module):\n",
    "    \"\"\"Classifier with a PerceptNet backbone.\"\"\"\n",
    "\n",
    "    def setup(self):\n",
    "        self.perceptnet = PerceptNet()\n",
    "        self.cls = nn.Dense(N_CLASSES)\n",
    "\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 ):\n",
    "        outputs = self.perceptnet(inputs)\n",
    "        # outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = reduce(outputs, \"b h w c -> b c\", reduction=\"mean\") if config.GAP else rearrange(outputs, \"b h w c -> b (h w c)\")\n",
    "        outputs = self.cls(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    \"\"\"Collection of metrics to be tracked during training.\"\"\"\n",
    "    accuracy: metrics.Accuracy\n",
    "    loss: metrics.Average.from_output(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "    state: FrozenDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, key, tx, input_shape):\n",
    "    \"\"\"Creates the initial `TrainState`.\"\"\"\n",
    "    variables = module.init(key, jnp.ones(input_shape))\n",
    "    state, params = variables.pop('params')\n",
    "    return TrainState.create(\n",
    "        apply_fn=module.apply,\n",
    "        params=params,\n",
    "        state=state,\n",
    "        tx=tx,\n",
    "        metrics=Metrics.empty()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = PerceptNetClassifier().init(random.PRNGKey(config.seed), jnp.zeros((1,32,32,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(PerceptNetClassifier(), random.PRNGKey(config.seed), optax.adam(config.learning_rate), input_shape=(1,32,32,3))\n",
    "state = state.replace(params=clip_layer(state.params, \"GDN\", a_min=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log the number of trainable weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118161"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(state.params))\n",
    "param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.summary[\"trainable_parameters\"] = param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    img, label = batch\n",
    "    def loss_fn(params):\n",
    "        ## Forward pass through the model\n",
    "        img_pred = state.apply_fn({\"params\": params, **state.state}, img)\n",
    "\n",
    "        ## Calculate crossentropy\n",
    "        return optax.softmax_cross_entropy_with_integer_labels(img_pred, label).mean(), img_pred\n",
    "    \n",
    "    (loss, dist_diff), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics_updates = state.metrics.single_from_model_output(loss=loss, logits=dist_diff, labels=jnp.round(label).astype(int))\n",
    "    metrics = state.metrics.merge(metrics_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def val_step(state, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    img, label = batch\n",
    "    def loss_fn(params):\n",
    "        ## Forward pass through the model\n",
    "        img_pred = state.apply_fn({\"params\": params, **state.state}, img)\n",
    "\n",
    "        ## Calculate crossentropy\n",
    "        return optax.softmax_cross_entropy_with_integer_labels(img_pred, label).mean(), img_pred\n",
    "    \n",
    "    loss, dist_diff = loss_fn(state.params)\n",
    "    metrics_updates = state.metrics.single_from_model_output(loss=loss, logits=dist_diff, labels=jnp.round(label).astype(int))\n",
    "    metrics = state.metrics.merge(metrics_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(state, img):\n",
    "    img_pred = PerceptNet().apply({\"params\": state.params[\"perceptnet\"]}, img)\n",
    "    return img_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(a, b): return jnp.sqrt(jnp.sum((a-b)**2, axis=(1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def obtain_distances(state, batch):\n",
    "    ref, dist, mos = batch\n",
    "    pred_ref = forward_pass(state, ref)\n",
    "    pred_dist = forward_pass(state, dist)\n",
    "    distance = rmse(pred_ref, pred_dist)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_correlation(state, dst):\n",
    "    distances, moses = [], []\n",
    "    for batch in dst:\n",
    "        distance = obtain_distances(state, batch)\n",
    "        distances.extend(distance)\n",
    "        moses.extend(batch[2])\n",
    "        # break\n",
    "    return stats.pearsonr(distances, moses)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_accuracy\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_accuracy\": [],\n",
    "    \"correlation\": [0.],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:28:01.571891: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -> [Train] Loss: 1.802 Acc: 0.365 [Val] Loss: 1.602 Acc: 0.453 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:28:43.419999: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -> [Train] Loss: 1.624 Acc: 0.435 [Val] Loss: 1.548 Acc: 0.500 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:29:23.882536: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 -> [Train] Loss: 1.562 Acc: 0.456 [Val] Loss: 1.491 Acc: 0.500 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:30:04.285005: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 -> [Train] Loss: 1.514 Acc: 0.472 [Val] Loss: 1.454 Acc: 0.516 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:30:44.647473: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 -> [Train] Loss: 1.478 Acc: 0.483 [Val] Loss: 1.430 Acc: 0.516 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:31:24.969276: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 -> [Train] Loss: 1.450 Acc: 0.494 [Val] Loss: 1.406 Acc: 0.469 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:32:05.269432: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 -> [Train] Loss: 1.427 Acc: 0.503 [Val] Loss: 1.384 Acc: 0.469 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:32:45.294712: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 -> [Train] Loss: 1.406 Acc: 0.509 [Val] Loss: 1.364 Acc: 0.484 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:33:25.498203: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 -> [Train] Loss: 1.388 Acc: 0.514 [Val] Loss: 1.349 Acc: 0.484 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:34:05.900824: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 -> [Train] Loss: 1.372 Acc: 0.519 [Val] Loss: 1.338 Acc: 0.469 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:34:46.069815: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 -> [Train] Loss: 1.358 Acc: 0.522 [Val] Loss: 1.330 Acc: 0.469 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:35:26.811106: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 -> [Train] Loss: 1.345 Acc: 0.526 [Val] Loss: 1.323 Acc: 0.453 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:36:07.648857: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 -> [Train] Loss: 1.334 Acc: 0.530 [Val] Loss: 1.317 Acc: 0.438 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:36:48.115251: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 -> [Train] Loss: 1.324 Acc: 0.533 [Val] Loss: 1.312 Acc: 0.438 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:37:28.937273: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 -> [Train] Loss: 1.315 Acc: 0.537 [Val] Loss: 1.306 Acc: 0.438 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:38:09.229078: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 -> [Train] Loss: 1.305 Acc: 0.540 [Val] Loss: 1.300 Acc: 0.422 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:38:49.615461: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 -> [Train] Loss: 1.296 Acc: 0.543 [Val] Loss: 1.294 Acc: 0.438 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:39:30.376971: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 -> [Train] Loss: 1.287 Acc: 0.545 [Val] Loss: 1.287 Acc: 0.438 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:40:11.281005: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 -> [Train] Loss: 1.278 Acc: 0.548 [Val] Loss: 1.281 Acc: 0.422 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:40:51.551460: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 -> [Train] Loss: 1.269 Acc: 0.551 [Val] Loss: 1.273 Acc: 0.438 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:41:32.356721: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 -> [Train] Loss: 1.259 Acc: 0.555 [Val] Loss: 1.265 Acc: 0.453 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:42:13.480548: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 -> [Train] Loss: 1.250 Acc: 0.559 [Val] Loss: 1.257 Acc: 0.453 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:42:54.418021: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 -> [Train] Loss: 1.240 Acc: 0.562 [Val] Loss: 1.249 Acc: 0.453 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:43:35.224132: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 -> [Train] Loss: 1.230 Acc: 0.565 [Val] Loss: 1.241 Acc: 0.453 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:44:16.404354: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 -> [Train] Loss: 1.221 Acc: 0.569 [Val] Loss: 1.235 Acc: 0.469 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:44:57.500481: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 -> [Train] Loss: 1.210 Acc: 0.572 [Val] Loss: 1.229 Acc: 0.469 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:45:38.544783: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 -> [Train] Loss: 1.200 Acc: 0.576 [Val] Loss: 1.224 Acc: 0.469 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:46:19.774641: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 -> [Train] Loss: 1.190 Acc: 0.580 [Val] Loss: 1.219 Acc: 0.469 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:47:00.878755: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 -> [Train] Loss: 1.179 Acc: 0.584 [Val] Loss: 1.215 Acc: 0.484 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:47:41.788610: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 -> [Train] Loss: 1.168 Acc: 0.587 [Val] Loss: 1.212 Acc: 0.484 || Corr: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 16:48:22.614665: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 -> [Train] Loss: 1.157 Acc: 0.591 [Val] Loss: 1.209 Acc: 0.484 || Corr: 0.000\n",
      "Invalid nan value encountered in the output of a C++-jit/pmap function. Calling the de-optimized version.\n"
     ]
    },
    {
     "ename": "FloatingPointError",
     "evalue": "invalid value (nan) encountered in jit(mul)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/api.py:131\u001b[0m, in \u001b[0;36m_nan_check_posthook\u001b[0;34m(fun, args, kwargs, output)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m   dispatch\u001b[39m.\u001b[39;49mcheck_special(pjit\u001b[39m.\u001b[39;49mpjit_p, buffers)\n\u001b[1;32m    132\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m   \u001b[39m# compiled_fun can only raise in this case\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/dispatch.py:436\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mfor\u001b[39;00m buf \u001b[39min\u001b[39;00m bufs:\n\u001b[0;32m--> 436\u001b[0m   _check_special(name, buf\u001b[39m.\u001b[39;49mdtype, buf)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/dispatch.py:441\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misnan(np\u001b[39m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 441\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid value (nan) encountered in \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misinf(np\u001b[39m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in pjit",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    315\u001b[0m \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/interpreters/pxla.py:1920\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[39mfor\u001b[39;00m arrays \u001b[39min\u001b[39;00m out_arrays:\n\u001b[0;32m-> 1920\u001b[0m   dispatch\u001b[39m.\u001b[39;49mcheck_special(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, arrays)\n\u001b[1;32m   1921\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/dispatch.py:436\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mfor\u001b[39;00m buf \u001b[39min\u001b[39;00m bufs:\n\u001b[0;32m--> 436\u001b[0m   _check_special(name, buf\u001b[39m.\u001b[39;49mdtype, buf)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/dispatch.py:441\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misnan(np\u001b[39m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 441\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid value (nan) encountered in \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misinf(np\u001b[39m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(train_step)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/runpy.py:194\u001b[0m, in \u001b[0;36m_run_module_as_main\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    193\u001b[0m     sys\u001b[39m.\u001b[39margv[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m mod_spec\u001b[39m.\u001b[39morigin\n\u001b[0;32m--> 194\u001b[0m \u001b[39mreturn\u001b[39;00m _run_code(code, main_globals, \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    195\u001b[0m                  \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m, mod_spec)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/runpy.py:87\u001b[0m, in \u001b[0;36m_run_code\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     80\u001b[0m run_globals\u001b[39m.\u001b[39mupdate(\u001b[39m__name__\u001b[39m \u001b[39m=\u001b[39m mod_name,\n\u001b[1;32m     81\u001b[0m                    \u001b[39m__file__\u001b[39m \u001b[39m=\u001b[39m fname,\n\u001b[1;32m     82\u001b[0m                    __cached__ \u001b[39m=\u001b[39m cached,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m                    __package__ \u001b[39m=\u001b[39m pkg_name,\n\u001b[1;32m     86\u001b[0m                    __spec__ \u001b[39m=\u001b[39m mod_spec)\n\u001b[0;32m---> 87\u001b[0m exec(code, run_globals)\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m run_globals\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel_launcher.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mipykernel\u001b[39;00m \u001b[39mimport\u001b[39;00m kernelapp \u001b[39mas\u001b[39;00m app\n\u001b[0;32m---> 17\u001b[0m app\u001b[39m.\u001b[39mlaunch_new_instance()\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/traitlets/config/application.py:992\u001b[0m, in \u001b[0;36mApplication.launch_instance\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    991\u001b[0m app\u001b[39m.\u001b[39minitialize(argv)\n\u001b[0;32m--> 992\u001b[0m app\u001b[39m.\u001b[39mstart()\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/kernelapp.py:736\u001b[0m, in \u001b[0;36mIPKernelApp.start\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 736\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mio_loop\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    737\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/tornado/platform/asyncio.py:199\u001b[0m, in \u001b[0;36mBaseAsyncIOLoop.start\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    198\u001b[0m     asyncio\u001b[39m.\u001b[39mset_event_loop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39masyncio_loop)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39masyncio_loop\u001b[39m.\u001b[39mrun_forever()\n\u001b[1;32m    200\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/asyncio/base_events.py:570\u001b[0m, in \u001b[0;36mBaseEventLoop.run_forever\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 570\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_once()\n\u001b[1;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stopping:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/nest_asyncio.py:120\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m handle\u001b[39m.\u001b[39m_cancelled:\n\u001b[0;32m--> 120\u001b[0m         handle\u001b[39m.\u001b[39m_run()\n\u001b[1;32m    121\u001b[0m handle \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/asyncio/events.py:81\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args)\n\u001b[1;32m     82\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mSystemExit\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py:516\u001b[0m, in \u001b[0;36mKernel.dispatch_queue\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_one()\n\u001b[1;32m    517\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py:505\u001b[0m, in \u001b[0;36mKernel.process_one\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m \u001b[39mawait\u001b[39;00m dispatch(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py:412\u001b[0m, in \u001b[0;36mKernel.dispatch_shell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misawaitable(result):\n\u001b[0;32m--> 412\u001b[0m         \u001b[39mawait\u001b[39;00m result\n\u001b[1;32m    413\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py:740\u001b[0m, in \u001b[0;36mKernel.execute_request\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misawaitable(reply_content):\n\u001b[0;32m--> 740\u001b[0m     reply_content \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m reply_content\n\u001b[1;32m    742\u001b[0m \u001b[39m# Flush output before sending the reply.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/ipkernel.py:422\u001b[0m, in \u001b[0;36mIPythonKernel.do_execute\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[39mif\u001b[39;00m with_cell_id:\n\u001b[0;32m--> 422\u001b[0m     res \u001b[39m=\u001b[39m shell\u001b[39m.\u001b[39mrun_cell(\n\u001b[1;32m    423\u001b[0m         code,\n\u001b[1;32m    424\u001b[0m         store_history\u001b[39m=\u001b[39mstore_history,\n\u001b[1;32m    425\u001b[0m         silent\u001b[39m=\u001b[39msilent,\n\u001b[1;32m    426\u001b[0m         cell_id\u001b[39m=\u001b[39mcell_id,\n\u001b[1;32m    427\u001b[0m     )\n\u001b[1;32m    428\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/zmqshell.py:546\u001b[0m, in \u001b[0;36mZMQInteractiveShell.run_cell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_traceback \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrun_cell(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3006\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3005\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3006\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_cell(\n\u001b[1;32m   3007\u001b[0m         raw_cell, store_history, silent, shell_futures, cell_id\n\u001b[1;32m   3008\u001b[0m     )\n\u001b[1;32m   3009\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3061\u001b[0m, in \u001b[0;36mInteractiveShell._run_cell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3060\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3061\u001b[0m     result \u001b[39m=\u001b[39m runner(coro)\n\u001b[1;32m   3062\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/async_helpers.py:129\u001b[0m, in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     coro\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3266\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_async\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3263\u001b[0m interactivity \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m silent \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mast_node_interactivity\n\u001b[0;32m-> 3266\u001b[0m has_raised \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_ast_nodes(code_ast\u001b[39m.\u001b[39mbody, cell_name,\n\u001b[1;32m   3267\u001b[0m        interactivity\u001b[39m=\u001b[39minteractivity, compiler\u001b[39m=\u001b[39mcompiler, result\u001b[39m=\u001b[39mresult)\n\u001b[1;32m   3269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_execution_succeeded \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m has_raised\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445\u001b[0m, in \u001b[0;36mInteractiveShell.run_ast_nodes\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3444\u001b[0m     asy \u001b[39m=\u001b[39m compare(code)\n\u001b[0;32m-> 3445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_code(code, result, async_\u001b[39m=\u001b[39masy):\n\u001b[1;32m   3446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3505\u001b[0m, in \u001b[0;36mInteractiveShell.run_code\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3504\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3505\u001b[0m         exec(code_obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_global_ns, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_ns)\n\u001b[1;32m   3506\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   3507\u001b[0m     \u001b[39m# Reset our crash handler in place\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_cell_magic(\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfor epoch in range(config.epochs):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    ## Training\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    for batch in dst_train_rdy.as_numpy_iterator():\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        state = train_step(state, batch)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        state = state.replace(params=clip_layer(state.params, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGDN\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, a_min=0))\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        # state = compute_metrics(state=state, batch=batch)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        # break\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m    ## Log the metrics\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    for name, value in state.metrics.compute().items():\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        metrics_history[f\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain_\u001b[39m\u001b[39m{name}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m].append(value)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    ##\u001b[39m\u001b[39m\\xa0\u001b[39;00m\u001b[39mEmpty the metrics\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    state = state.replace(metrics=state.metrics.empty())\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m    ## Evaluation (Classification)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    for batch in dst_val_rdy.as_numpy_iterator():\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        state = val_step(state=state, batch=batch)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        break\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    for name, value in state.metrics.compute().items():\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        metrics_history[f\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m{name}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m].append(value)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    state = state.replace(metrics=state.metrics.empty())\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m    ##\u001b[39m\u001b[39m\\xa0\u001b[39;00m\u001b[39mEvaluation (Correlation)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    # correlation = obtain_correlation(state, dst_tid2013.as_numpy_iterator())\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    # metrics_history[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcorrelation\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m].append(correlation)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    ##\u001b[39m\u001b[39m\\xa0\u001b[39;00m\u001b[39mCheckpointing\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    if metrics_history[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m][-1] <= min(metrics_history[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        orbax_checkpointer.save(os.path.join(wandb.run.dir, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel-best\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m), state, save_args=save_args, force=True) # force=True means allow overwritting.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m    wandb.log(\u001b[39m\u001b[39m{\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{k}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m: wandb.Histogram(v) for k, v in flatten_params(state.params).items()}, commit=False)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    wandb.log(\u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: epoch+1, **\u001b[39m\u001b[39m{\u001b[39m\u001b[39mname:values[-1] for name, values in metrics_history.items()}})\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    print(f\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mEpoch \u001b[39m\u001b[39m{epoch}\u001b[39;00m\u001b[39m -> [Train] Loss: \u001b[39m\u001b[39m{metrics_history[\"train_loss\"][-1]:.3f}\u001b[39;00m\u001b[39m Acc: \u001b[39m\u001b[39m{metrics_history[\"train_accuracy\"][-1]:.3f}\u001b[39;00m\u001b[39m [Val] Loss: \u001b[39m\u001b[39m{metrics_history[\"val_loss\"][-1]:.3f}\u001b[39;00m\u001b[39m Acc: \u001b[39m\u001b[39m{metrics_history[\"val_accuracy\"][-1]:.3f}\u001b[39;00m\u001b[39m || Corr: \u001b[39m\u001b[39m{metrics_history[\"correlation\"][-1]:.3f}\u001b[39;00m\u001b[39m\\'\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    # break\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2475\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2474\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2475\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   2477\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2478\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2479\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/magics/execution.py:1325\u001b[0m, in \u001b[0;36mExecutionMagics.time\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m     exec(code, glob, local_ns)\n\u001b[1;32m   1326\u001b[0m     out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "Cell \u001b[0;32mIn[30], line 12\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m optax\u001b[39m.\u001b[39msoftmax_cross_entropy_with_integer_labels(img_pred, label)\u001b[39m.\u001b[39mmean(), img_pred\n\u001b[0;32m---> 12\u001b[0m (loss, dist_diff), grads \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mvalue_and_grad(loss_fn, has_aux\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(state\u001b[39m.\u001b[39mparams)\n\u001b[1;32m     13\u001b[0m state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_gradients(grads\u001b[39m=\u001b[39mgrads)\n",
      "Cell \u001b[0;32mIn[30], line 7\u001b[0m, in \u001b[0;36mtrain_step.<locals>.loss_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_fn\u001b[39m(params):\n\u001b[1;32m      6\u001b[0m     \u001b[39m## Forward pass through the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     img_pred \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_fn({\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m: params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mstate\u001b[39m.\u001b[39mstate}, img)\n\u001b[1;32m      9\u001b[0m     \u001b[39m## Calculate crossentropy\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m, in \u001b[0;36mPerceptNetClassifier.__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m      9\u001b[0m              inputs,\n\u001b[1;32m     10\u001b[0m              ):\n\u001b[0;32m---> 11\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperceptnet(inputs)\n\u001b[1;32m     12\u001b[0m     \u001b[39m# outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m, in \u001b[0;36mPerceptNet.__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     16\u001b[0m outputs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv(features\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m), strides\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSAME\u001b[39m\u001b[39m\"\u001b[39m, use_bias\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39muse_bias)(outputs)\n\u001b[0;32m---> 17\u001b[0m outputs \u001b[39m=\u001b[39m GDN(kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, strides\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSAME\u001b[39m\u001b[39m\"\u001b[39m, apply_independently\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)(outputs)\n\u001b[1;32m     18\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "Cell \u001b[0;32mIn[18], line 24\u001b[0m, in \u001b[0;36mGDN.__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m@nn\u001b[39m\u001b[39m.\u001b[39mcompact\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     16\u001b[0m              inputs,\n\u001b[1;32m     17\u001b[0m              ):\n\u001b[1;32m     18\u001b[0m     denom \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv(features\u001b[39m=\u001b[39minputs\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39m# Same output channels as input\u001b[39;00m\n\u001b[1;32m     19\u001b[0m                     kernel_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size, Sequence) \u001b[39melse\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size]\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, \n\u001b[1;32m     20\u001b[0m                     strides\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrides, \n\u001b[1;32m     21\u001b[0m                     padding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding,\n\u001b[1;32m     22\u001b[0m                     feature_group_count\u001b[39m=\u001b[39minputs\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_independently \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m,\n\u001b[1;32m     23\u001b[0m                     kernel_init\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_init, \n\u001b[0;32m---> 24\u001b[0m                     bias_init\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_init)(inputs\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha)\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m inputs \u001b[39m/\u001b[39m (denom\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepsilon \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meps)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/numpy/array_methods.py:251\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 251\u001b[0m   \u001b[39mreturn\u001b[39;00m binary_op(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _rejected_binop_types):\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/numpy/ufuncs.py:344\u001b[0m, in \u001b[0;36mpower\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39minteger_pow(x1, x2)\n\u001b[0;32m--> 344\u001b[0m \u001b[39mreturn\u001b[39;00m _power(x1, x2)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/numpy/ufuncs.py:312\u001b[0m, in \u001b[0;36m_power\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dtypes\u001b[39m.\u001b[39missubdtype(dtype, np\u001b[39m.\u001b[39minteger):\n\u001b[0;32m--> 312\u001b[0m   \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39mpow(x1, x2)\n\u001b[1;32m    314\u001b[0m \u001b[39m# Integer power => use binary exponentiation.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \n\u001b[1;32m    316\u001b[0m \u001b[39m# TODO(phawkins): add integer pow support to XLA.\u001b[39;00m\n",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m: FloatingPointError: invalid value (nan) encountered in jit(mul)\n\nThe preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n\n--------------------",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/api.py:137\u001b[0m, in \u001b[0;36m_nan_check_posthook\u001b[0;34m(fun, args, kwargs, output)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39massert\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mor\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs\n\u001b[1;32m    135\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInvalid nan value encountered in the output of a C++-jit/pmap \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mfunction. Calling the de-optimized version.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 137\u001b[0m fun\u001b[39m.\u001b[39;49m_cache_miss(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)[\u001b[39m0\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 17 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/dispatch.py:441\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m dtypes\u001b[39m.\u001b[39missubdtype(dtype, np\u001b[39m.\u001b[39minexact):\n\u001b[1;32m    440\u001b[0m   \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misnan(np\u001b[39m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 441\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid value (nan) encountered in \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m   \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misinf(np\u001b[39m.\u001b[39masarray(buf))):\n\u001b[1;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid value (inf) encountered in \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(mul)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(config.epochs):\n",
    "    ## Training\n",
    "    for batch in dst_train_rdy.as_numpy_iterator():\n",
    "        state = train_step(state, batch)\n",
    "        state = state.replace(params=clip_layer(state.params, \"GDN\", a_min=0))\n",
    "        # state = compute_metrics(state=state, batch=batch)\n",
    "        # break\n",
    "\n",
    "    ## Log the metrics\n",
    "    for name, value in state.metrics.compute().items():\n",
    "        metrics_history[f\"train_{name}\"].append(value)\n",
    "    \n",
    "    ## Empty the metrics\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "\n",
    "    ## Evaluation (Classification)\n",
    "    for batch in dst_val_rdy.as_numpy_iterator():\n",
    "        state = val_step(state=state, batch=batch)\n",
    "        break\n",
    "    for name, value in state.metrics.compute().items():\n",
    "        metrics_history[f\"val_{name}\"].append(value)\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "\n",
    "    ## Evaluation (Correlation)\n",
    "    # correlation = obtain_correlation(state, dst_tid2013.as_numpy_iterator())\n",
    "    # metrics_history[\"correlation\"].append(correlation)\n",
    "    \n",
    "    ## Checkpointing\n",
    "    if metrics_history[\"val_loss\"][-1] <= min(metrics_history[\"val_loss\"]):\n",
    "        orbax_checkpointer.save(os.path.join(wandb.run.dir, \"model-best\"), state, save_args=save_args, force=True) # force=True means allow overwritting.\n",
    "\n",
    "    wandb.log({f\"{k}\": wandb.Histogram(v) for k, v in flatten_params(state.params).items()}, commit=False)\n",
    "    wandb.log({\"epoch\": epoch+1, **{name:values[-1] for name, values in metrics_history.items()}})\n",
    "    print(f'Epoch {epoch} -> [Train] Loss: {metrics_history[\"train_loss\"][-1]:.3f} Acc: {metrics_history[\"train_accuracy\"][-1]:.3f} [Val] Loss: {metrics_history[\"val_loss\"][-1]:.3f} Acc: {metrics_history[\"val_accuracy\"][-1]:.3f} || Corr: {metrics_history[\"correlation\"][-1]:.3f}')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "distances, moses = [], []\n",
    "for b in dst_tid2013.as_numpy_iterator():\n",
    "    distance = obtain_distances(state, b)\n",
    "    distances.extend(distance)\n",
    "    moses.extend(batch[2])\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid nan value encountered in the output of a C++-jit/pmap function. Calling the de-optimized version.\n"
     ]
    },
    {
     "ename": "FloatingPointError",
     "evalue": "invalid value (nan) encountered in jit(mul)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/api.py:131\u001b[0m, in \u001b[0;36m_nan_check_posthook\u001b[0;34m(fun, args, kwargs, output)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m   dispatch\u001b[39m.\u001b[39;49mcheck_special(pjit\u001b[39m.\u001b[39;49mpjit_p, buffers)\n\u001b[1;32m    132\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m   \u001b[39m# compiled_fun can only raise in this case\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/dispatch.py:436\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mfor\u001b[39;00m buf \u001b[39min\u001b[39;00m bufs:\n\u001b[0;32m--> 436\u001b[0m   _check_special(name, buf\u001b[39m.\u001b[39;49mdtype, buf)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/dispatch.py:441\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misnan(np\u001b[39m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 441\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid value (nan) encountered in \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misinf(np\u001b[39m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in pjit",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m   \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    315\u001b[0m \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/interpreters/pxla.py:1920\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[39mfor\u001b[39;00m arrays \u001b[39min\u001b[39;00m out_arrays:\n\u001b[0;32m-> 1920\u001b[0m   dispatch\u001b[39m.\u001b[39;49mcheck_special(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, arrays)\n\u001b[1;32m   1921\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/dispatch.py:436\u001b[0m, in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mfor\u001b[39;00m buf \u001b[39min\u001b[39;00m bufs:\n\u001b[0;32m--> 436\u001b[0m   _check_special(name, buf\u001b[39m.\u001b[39;49mdtype, buf)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/dispatch.py:441\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misnan(np\u001b[39m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 441\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid value (nan) encountered in \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misinf(np\u001b[39m.\u001b[39masarray(buf))):\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(train_step)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/runpy.py:194\u001b[0m, in \u001b[0;36m_run_module_as_main\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    193\u001b[0m     sys\u001b[39m.\u001b[39margv[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m mod_spec\u001b[39m.\u001b[39morigin\n\u001b[0;32m--> 194\u001b[0m \u001b[39mreturn\u001b[39;00m _run_code(code, main_globals, \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    195\u001b[0m                  \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m, mod_spec)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/runpy.py:87\u001b[0m, in \u001b[0;36m_run_code\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     80\u001b[0m run_globals\u001b[39m.\u001b[39mupdate(\u001b[39m__name__\u001b[39m \u001b[39m=\u001b[39m mod_name,\n\u001b[1;32m     81\u001b[0m                    \u001b[39m__file__\u001b[39m \u001b[39m=\u001b[39m fname,\n\u001b[1;32m     82\u001b[0m                    __cached__ \u001b[39m=\u001b[39m cached,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m                    __package__ \u001b[39m=\u001b[39m pkg_name,\n\u001b[1;32m     86\u001b[0m                    __spec__ \u001b[39m=\u001b[39m mod_spec)\n\u001b[0;32m---> 87\u001b[0m exec(code, run_globals)\n\u001b[1;32m     88\u001b[0m \u001b[39mreturn\u001b[39;00m run_globals\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel_launcher.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mipykernel\u001b[39;00m \u001b[39mimport\u001b[39;00m kernelapp \u001b[39mas\u001b[39;00m app\n\u001b[0;32m---> 17\u001b[0m app\u001b[39m.\u001b[39mlaunch_new_instance()\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/traitlets/config/application.py:992\u001b[0m, in \u001b[0;36mApplication.launch_instance\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    991\u001b[0m app\u001b[39m.\u001b[39minitialize(argv)\n\u001b[0;32m--> 992\u001b[0m app\u001b[39m.\u001b[39mstart()\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/kernelapp.py:736\u001b[0m, in \u001b[0;36mIPKernelApp.start\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 736\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mio_loop\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    737\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/tornado/platform/asyncio.py:199\u001b[0m, in \u001b[0;36mBaseAsyncIOLoop.start\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    198\u001b[0m     asyncio\u001b[39m.\u001b[39mset_event_loop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39masyncio_loop)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39masyncio_loop\u001b[39m.\u001b[39mrun_forever()\n\u001b[1;32m    200\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/asyncio/base_events.py:570\u001b[0m, in \u001b[0;36mBaseEventLoop.run_forever\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 570\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_once()\n\u001b[1;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stopping:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/nest_asyncio.py:120\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m handle\u001b[39m.\u001b[39m_cancelled:\n\u001b[0;32m--> 120\u001b[0m         handle\u001b[39m.\u001b[39m_run()\n\u001b[1;32m    121\u001b[0m handle \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/asyncio/events.py:81\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args)\n\u001b[1;32m     82\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mSystemExit\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py:516\u001b[0m, in \u001b[0;36mKernel.dispatch_queue\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_one()\n\u001b[1;32m    517\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py:505\u001b[0m, in \u001b[0;36mKernel.process_one\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m \u001b[39mawait\u001b[39;00m dispatch(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py:412\u001b[0m, in \u001b[0;36mKernel.dispatch_shell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misawaitable(result):\n\u001b[0;32m--> 412\u001b[0m         \u001b[39mawait\u001b[39;00m result\n\u001b[1;32m    413\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py:740\u001b[0m, in \u001b[0;36mKernel.execute_request\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misawaitable(reply_content):\n\u001b[0;32m--> 740\u001b[0m     reply_content \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m reply_content\n\u001b[1;32m    742\u001b[0m \u001b[39m# Flush output before sending the reply.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/ipkernel.py:422\u001b[0m, in \u001b[0;36mIPythonKernel.do_execute\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[39mif\u001b[39;00m with_cell_id:\n\u001b[0;32m--> 422\u001b[0m     res \u001b[39m=\u001b[39m shell\u001b[39m.\u001b[39mrun_cell(\n\u001b[1;32m    423\u001b[0m         code,\n\u001b[1;32m    424\u001b[0m         store_history\u001b[39m=\u001b[39mstore_history,\n\u001b[1;32m    425\u001b[0m         silent\u001b[39m=\u001b[39msilent,\n\u001b[1;32m    426\u001b[0m         cell_id\u001b[39m=\u001b[39mcell_id,\n\u001b[1;32m    427\u001b[0m     )\n\u001b[1;32m    428\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/ipykernel/zmqshell.py:546\u001b[0m, in \u001b[0;36mZMQInteractiveShell.run_cell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_traceback \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrun_cell(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3006\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3005\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3006\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_cell(\n\u001b[1;32m   3007\u001b[0m         raw_cell, store_history, silent, shell_futures, cell_id\n\u001b[1;32m   3008\u001b[0m     )\n\u001b[1;32m   3009\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3061\u001b[0m, in \u001b[0;36mInteractiveShell._run_cell\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3060\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3061\u001b[0m     result \u001b[39m=\u001b[39m runner(coro)\n\u001b[1;32m   3062\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/async_helpers.py:129\u001b[0m, in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     coro\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3266\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_async\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3263\u001b[0m interactivity \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m silent \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mast_node_interactivity\n\u001b[0;32m-> 3266\u001b[0m has_raised \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_ast_nodes(code_ast\u001b[39m.\u001b[39mbody, cell_name,\n\u001b[1;32m   3267\u001b[0m        interactivity\u001b[39m=\u001b[39minteractivity, compiler\u001b[39m=\u001b[39mcompiler, result\u001b[39m=\u001b[39mresult)\n\u001b[1;32m   3269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_execution_succeeded \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m has_raised\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445\u001b[0m, in \u001b[0;36mInteractiveShell.run_ast_nodes\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3444\u001b[0m     asy \u001b[39m=\u001b[39m compare(code)\n\u001b[0;32m-> 3445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_code(code, result, async_\u001b[39m=\u001b[39masy):\n\u001b[1;32m   3446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3505\u001b[0m, in \u001b[0;36mInteractiveShell.run_code\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3504\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3505\u001b[0m         exec(code_obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_global_ns, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_ns)\n\u001b[1;32m   3506\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   3507\u001b[0m     \u001b[39m# Reset our crash handler in place\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[173], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_cell_magic(\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfor epoch in range(config.epochs):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    ## Training\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    for batch in dst_train_rdy.as_numpy_iterator():\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        state = train_step(state, batch)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        state = state.replace(params=clip_layer(state.params, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGDN\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, a_min=0))\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        # state = compute_metrics(state=state, batch=batch)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        # break\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m    ## Log the metrics\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    for name, value in state.metrics.compute().items():\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        metrics_history[f\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain_\u001b[39m\u001b[39m{name}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m].append(value)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    ##\u001b[39m\u001b[39m\\xa0\u001b[39;00m\u001b[39mEmpty the metrics\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    state = state.replace(metrics=state.metrics.empty())\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m    ## Evaluation (Classification)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    for batch in dst_val_rdy.as_numpy_iterator():\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        state = val_step(state=state, batch=batch)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        # break\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    for name, value in state.metrics.compute().items():\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        metrics_history[f\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m{name}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m].append(value)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    state = state.replace(metrics=state.metrics.empty())\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m    ##\u001b[39m\u001b[39m\\xa0\u001b[39;00m\u001b[39mEvaluation (Correlation)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    correlation = obtain_correlation(state, dst_tid2013.as_numpy_iterator())\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    metrics_history[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcorrelation\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m].append(correlation)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    ##\u001b[39m\u001b[39m\\xa0\u001b[39;00m\u001b[39mCheckpointing\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    if metrics_history[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m][-1] <= min(metrics_history[\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m        orbax_checkpointer.save(os.path.join(wandb.run.dir, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel-best\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m), state, save_args=save_args, force=True) # force=True means allow overwritting.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m    wandb.log(\u001b[39m\u001b[39m{\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{k}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m: wandb.Histogram(v) for k, v in flatten_params(state.params).items()}, commit=False)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    wandb.log(\u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: epoch+1, **\u001b[39m\u001b[39m{\u001b[39m\u001b[39mname:values[-1] for name, values in metrics_history.items()}})\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    print(f\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mEpoch \u001b[39m\u001b[39m{epoch}\u001b[39;00m\u001b[39m -> [Train] Loss: \u001b[39m\u001b[39m{metrics_history[\"train_loss\"][-1]:.3f}\u001b[39;00m\u001b[39m Acc: \u001b[39m\u001b[39m{metrics_history[\"train_accuracy\"][-1]:.3f}\u001b[39;00m\u001b[39m [Val] Loss: \u001b[39m\u001b[39m{metrics_history[\"val_loss\"][-1]:.3f}\u001b[39;00m\u001b[39m Acc: \u001b[39m\u001b[39m{metrics_history[\"val_accuracy\"][-1]:.3f}\u001b[39;00m\u001b[39m || Corr: \u001b[39m\u001b[39m{metrics_history[\"correlation\"][-1]:.3f}\u001b[39;00m\u001b[39m\\'\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    # break\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2475\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2474\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2475\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   2477\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2478\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2479\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/IPython/core/magics/execution.py:1325\u001b[0m, in \u001b[0;36mExecutionMagics.time\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m     exec(code, glob, local_ns)\n\u001b[1;32m   1326\u001b[0m     out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "Cell \u001b[0;32mIn[144], line 12\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m optax\u001b[39m.\u001b[39msoftmax_cross_entropy_with_integer_labels(img_pred, label)\u001b[39m.\u001b[39mmean(), img_pred\n\u001b[0;32m---> 12\u001b[0m (loss, dist_diff), grads \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mvalue_and_grad(loss_fn, has_aux\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(state\u001b[39m.\u001b[39mparams)\n\u001b[1;32m     13\u001b[0m state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_gradients(grads\u001b[39m=\u001b[39mgrads)\n",
      "Cell \u001b[0;32mIn[144], line 7\u001b[0m, in \u001b[0;36mtrain_step.<locals>.loss_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_fn\u001b[39m(params):\n\u001b[1;32m      6\u001b[0m     \u001b[39m## Forward pass through the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     img_pred \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mapply_fn({\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m: params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mstate\u001b[39m.\u001b[39mstate}, img)\n\u001b[1;32m      9\u001b[0m     \u001b[39m## Calculate crossentropy\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[135], line 11\u001b[0m, in \u001b[0;36mPerceptNetClassifier.__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m      9\u001b[0m              inputs,\n\u001b[1;32m     10\u001b[0m              ):\n\u001b[0;32m---> 11\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mperceptnet(inputs)\n\u001b[1;32m     12\u001b[0m     \u001b[39m# outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[133], line 17\u001b[0m, in \u001b[0;36mPerceptNet.__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     16\u001b[0m outputs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv(features\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m,\u001b[39m5\u001b[39m), strides\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSAME\u001b[39m\u001b[39m\"\u001b[39m, use_bias\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39muse_bias)(outputs)\n\u001b[0;32m---> 17\u001b[0m outputs \u001b[39m=\u001b[39m GDN(kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, strides\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSAME\u001b[39m\u001b[39m\"\u001b[39m, apply_independently\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)(outputs)\n\u001b[1;32m     18\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "Cell \u001b[0;32mIn[132], line 24\u001b[0m, in \u001b[0;36mGDN.__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m@nn\u001b[39m\u001b[39m.\u001b[39mcompact\n\u001b[1;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     16\u001b[0m              inputs,\n\u001b[1;32m     17\u001b[0m              ):\n\u001b[1;32m     18\u001b[0m     denom \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mConv(features\u001b[39m=\u001b[39minputs\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39m# Same output channels as input\u001b[39;00m\n\u001b[1;32m     19\u001b[0m                     kernel_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size, Sequence) \u001b[39melse\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size]\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m, \n\u001b[1;32m     20\u001b[0m                     strides\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrides, \n\u001b[1;32m     21\u001b[0m                     padding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding,\n\u001b[1;32m     22\u001b[0m                     feature_group_count\u001b[39m=\u001b[39minputs\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_independently \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m,\n\u001b[1;32m     23\u001b[0m                     kernel_init\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_init, \n\u001b[0;32m---> 24\u001b[0m                     bias_init\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_init)(inputs\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha)\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m inputs \u001b[39m/\u001b[39m (denom\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepsilon \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meps)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/numpy/array_methods.py:251\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 251\u001b[0m   \u001b[39mreturn\u001b[39;00m binary_op(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _rejected_binop_types):\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/numpy/ufuncs.py:344\u001b[0m, in \u001b[0;36mpower\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39minteger_pow(x1, x2)\n\u001b[0;32m--> 344\u001b[0m \u001b[39mreturn\u001b[39;00m _power(x1, x2)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/numpy/ufuncs.py:312\u001b[0m, in \u001b[0;36m_power\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dtypes\u001b[39m.\u001b[39missubdtype(dtype, np\u001b[39m.\u001b[39minteger):\n\u001b[0;32m--> 312\u001b[0m   \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39mpow(x1, x2)\n\u001b[1;32m    314\u001b[0m \u001b[39m# Integer power => use binary exponentiation.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \n\u001b[1;32m    316\u001b[0m \u001b[39m# TODO(phawkins): add integer pow support to XLA.\u001b[39;00m\n",
      "\u001b[0;31mJaxStackTraceBeforeTransformation\u001b[0m: FloatingPointError: invalid value (nan) encountered in jit(mul)\n\nThe preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n\n--------------------",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[182], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s \u001b[39m=\u001b[39m train_step(state, batch)\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/api.py:137\u001b[0m, in \u001b[0;36m_nan_check_posthook\u001b[0;34m(fun, args, kwargs, output)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39massert\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mor\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs\n\u001b[1;32m    135\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInvalid nan value encountered in the output of a C++-jit/pmap \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mfunction. Calling the de-optimized version.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 137\u001b[0m fun\u001b[39m.\u001b[39;49m_cache_miss(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)[\u001b[39m0\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 17 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/testing_gpu/lib/python3.8/site-packages/jax/_src/dispatch.py:441\u001b[0m, in \u001b[0;36m_check_special\u001b[0;34m(name, dtype, buf)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m dtypes\u001b[39m.\u001b[39missubdtype(dtype, np\u001b[39m.\u001b[39minexact):\n\u001b[1;32m    440\u001b[0m   \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misnan(np\u001b[39m.\u001b[39masarray(buf))):\n\u001b[0;32m--> 441\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid value (nan) encountered in \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m   \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39misinf(np\u001b[39m.\u001b[39masarray(buf))):\n\u001b[1;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid value (inf) encountered in \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(mul)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "s = train_step(state, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDN(nn.Module):\n",
    "    \"\"\"Generalized Divisive Normalization.\"\"\"\n",
    "    kernel_size: Union[int, Sequence[int]]\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    apply_independently: bool = False\n",
    "    # kernel_init: Callable = nn.initializers.lecun_normal()\n",
    "    kernel_init: Callable = mean()\n",
    "    bias_init: Callable = nn.initializers.ones_init()\n",
    "    alpha: float = 2.\n",
    "    epsilon: float = 1/2 # Exponential of the denominator\n",
    "    eps: float = 1e-6 # Numerical stability in the denominator\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 ):\n",
    "        denom = nn.Conv(features=inputs.shape[-1], # Same output channels as input\n",
    "                        kernel_size=self.kernel_size if isinstance(self.kernel_size, Sequence) else [self.kernel_size]*2, \n",
    "                        strides=self.strides, \n",
    "                        padding=self.padding,\n",
    "                        feature_group_count=inputs.shape[-1] if self.apply_independently else 1,\n",
    "                        kernel_init=self.kernel_init, \n",
    "                        bias_init=self.bias_init)(jnp.clip(inputs**self.alpha, a_min=1e-5))\n",
    "        return inputs / (denom**self.epsilon + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNet(nn.Module):\n",
    "    \"\"\"IQA model inspired by the visual system.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=True, alpha=2.0, epsilon=0.5)(inputs)\n",
    "        outputs = nn.Conv(features=3, kernel_size=(1,1), strides=1, padding=\"SAME\", use_bias=config.use_bias)(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False, alpha=2.0, epsilon=0.5)(outputs)\n",
    "        outputs = nn.Conv(features=6, kernel_size=(5,5), strides=1, padding=\"SAME\", use_bias=config.use_bias)(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False, alpha=2.0, epsilon=0.5)(outputs)\n",
    "        outputs = nn.Conv(features=128, kernel_size=(5,5), strides=1, padding=\"SAME\", use_bias=config.use_bias)(outputs)\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False, alpha=2.0, epsilon=0.5)(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNetClassifier(nn.Module):\n",
    "    \"\"\"Classifier with a PerceptNet backbone.\"\"\"\n",
    "\n",
    "    def setup(self):\n",
    "        self.perceptnet = PerceptNet()\n",
    "        self.cls = nn.Dense(N_CLASSES)\n",
    "\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 ):\n",
    "        outputs = self.perceptnet(inputs)\n",
    "        # outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = reduce(outputs, \"h w c -> c\", reduction=\"mean\") if config.GAP else rearrange(outputs, \"h w c -> (h w c)\")\n",
    "        outputs = self.cls(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_one_sample(params, img, label): \n",
    "    pred = PerceptNetClassifier().apply({\"params\": params}, img)\n",
    "    # loss = optax.softmax_cross_entropy_with_integer_labels(logits=pred, labels=label)\n",
    "    label = jnp.zeros_like(pred).at[label].set(1)\n",
    "    loss = optax.l2_loss(pred, label).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.89600277, dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_one_sample(state.params, batch[0][0], batch[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(batch[0])):\n",
    "    jax.value_and_grad(loss_one_sample, argnums=0)(state.params, batch[0][i], batch[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "print(i)\n",
    "img_prob, label_prob = batch[0][i], batch[1][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(batch[0][i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_pred, k = PerceptNetClassifier().apply({\"params\": state.params}, img_prob, capture_intermediates=True)\n",
    "img_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(6.519498e-07, dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = k[\"intermediates\"][\"perceptnet\"][\"GDN_3\"][\"Conv_0\"][\"__call__\"][0]**(3/2)\n",
    "r.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(1.0922486, dtype=float32),\n",
       " FrozenDict({\n",
       "     cls: {\n",
       "         bias: Array([-0.03998941, -0.05710946,  0.12049019,  0.17887305, -0.12339189,\n",
       "                 0.094022  , -0.25449842,  0.00121391, -0.2548282 , -0.11533251],      dtype=float32),\n",
       "         kernel: Array([[ 2.0190156e-03,  2.8833856e-03, -6.0834000e-03, ...,\n",
       "                 -6.1288869e-05,  1.2865960e-02,  5.8229947e-03],\n",
       "                [-2.8738151e-03, -4.1041374e-03,  8.6589558e-03, ...,\n",
       "                  8.7237007e-05, -1.8313078e-02, -8.2883015e-03],\n",
       "                [ 1.6879268e-02,  2.4105528e-02, -5.0858118e-02, ...,\n",
       "                 -5.1238394e-04,  1.0756131e-01,  4.8681092e-02],\n",
       "                ...,\n",
       "                [-5.7402956e-03, -8.1978003e-03,  1.7295811e-02, ...,\n",
       "                  1.7425136e-04, -3.6579415e-02, -1.6555449e-02],\n",
       "                [-2.3156214e-03, -3.3069728e-03,  6.9770887e-03, ...,\n",
       "                  7.0292575e-05, -1.4756048e-02, -6.6784285e-03],\n",
       "                [-1.0017490e-02, -1.4306124e-02,  3.0183224e-02, ...,\n",
       "                  3.0408910e-04, -6.3835375e-02, -2.8891204e-02]], dtype=float32),\n",
       "     },\n",
       "     perceptnet: {\n",
       "         Conv_0: {\n",
       "             kernel: Array([[[[-3.9708047 ,  0.24450126, -0.20851223],\n",
       "                      [-3.2339835 ,  0.17355953, -0.17309326],\n",
       "                      [-3.953967  ,  0.24350479, -0.20761594]]]], dtype=float32),\n",
       "         },\n",
       "         Conv_1: {\n",
       "             kernel: Array([[[[-9.54406410e-02,  1.27385676e-01, -1.00475354e-02,\n",
       "                        4.57126319e-01, -7.69311041e-02,  4.29054163e-02],\n",
       "                      [-1.36855507e+00,  1.21149218e+00, -2.76703715e-01,\n",
       "                        4.42722750e+00, -7.31292665e-01,  2.41578832e-01],\n",
       "                      [-1.10659432e+00,  9.12197351e-01, -2.38729745e-01,\n",
       "                        3.34609938e+00, -5.52050292e-01,  1.61581218e-01]],\n",
       "             \n",
       "                     [[-1.01681069e-01,  3.87773030e-02,  3.19377743e-02,\n",
       "                        3.82591546e-01, -1.35847982e-02, -1.09062806e-01],\n",
       "                      [-9.75904286e-01,  4.11322296e-01,  2.43040904e-01,\n",
       "                        5.27971363e+00, -3.37878734e-01, -1.21873486e+00],\n",
       "                      [-7.38409996e-01,  3.14278483e-01,  1.74732551e-01,\n",
       "                        4.24745035e+00, -2.82448769e-01, -9.40707028e-01]],\n",
       "             \n",
       "                     [[-8.91811997e-02,  5.48391230e-02,  6.22313768e-02,\n",
       "                        3.92763048e-01,  6.75671026e-02, -1.47603497e-01],\n",
       "                      [-7.62489200e-01,  5.67127407e-01,  7.37082541e-01,\n",
       "                        4.50283861e+00,  5.52851021e-01, -1.55839407e+00],\n",
       "                      [-5.64093232e-01,  4.36547339e-01,  5.78314245e-01,\n",
       "                        3.51485419e+00,  4.00871813e-01, -1.19419086e+00]],\n",
       "             \n",
       "                     [[-1.23539113e-01,  5.98147064e-02,  6.28299639e-02,\n",
       "                        3.47451776e-01,  7.34141022e-02, -1.72098458e-01],\n",
       "                      [-1.47336555e+00,  5.58249772e-01,  4.88435358e-01,\n",
       "                        3.23730731e+00,  7.92044461e-01, -2.12715673e+00],\n",
       "                      [-1.15569687e+00,  4.20573711e-01,  3.53370219e-01,\n",
       "                        2.44634891e+00,  6.11249924e-01, -1.67543316e+00]],\n",
       "             \n",
       "                     [[-1.45582497e-01,  7.31314123e-02,  6.97771236e-02,\n",
       "                        2.72423804e-01,  1.24697454e-01, -1.78458825e-01],\n",
       "                      [-1.64590824e+00,  7.91312993e-01,  7.26443946e-01,\n",
       "                        2.95184946e+00,  1.47320569e+00, -2.07501030e+00],\n",
       "                      [-1.27997565e+00,  6.09091818e-01,  5.55244148e-01,\n",
       "                        2.27267432e+00,  1.15448415e+00, -1.61554885e+00]]],\n",
       "             \n",
       "             \n",
       "                    [[[-1.16918236e-01,  1.12723753e-01, -3.48707028e-02,\n",
       "                        3.72923464e-01, -1.15636475e-01,  7.62001425e-02],\n",
       "                      [-1.33488750e+00,  1.05075967e+00, -5.46772480e-01,\n",
       "                        3.45664454e+00, -9.73178208e-01,  8.20521712e-01],\n",
       "                      [-1.04121411e+00,  7.91093111e-01, -4.43093091e-01,\n",
       "                        2.59641027e+00, -7.19534099e-01,  6.37895346e-01]],\n",
       "             \n",
       "                     [[-1.06164202e-01,  9.52068865e-02,  8.41110200e-03,\n",
       "                        4.82196420e-01, -6.39768019e-02,  2.74305958e-02],\n",
       "                      [-1.36319649e+00,  1.05524445e+00,  1.09280944e-01,\n",
       "                        5.10174465e+00, -4.85919833e-01,  3.39810520e-01],\n",
       "                      [-1.08418727e+00,  8.13950539e-01,  8.39214623e-02,\n",
       "                        3.91586637e+00, -3.51882517e-01,  2.64377594e-01]],\n",
       "             \n",
       "                     [[-1.20321058e-01,  5.57764322e-02,  4.08628210e-02,\n",
       "                        4.31594849e-01, -1.30498484e-02, -5.76380789e-02],\n",
       "                      [-1.18408382e+00,  4.90311742e-01,  6.92950189e-01,\n",
       "                        5.61895752e+00, -1.26149967e-01, -5.85200906e-01],\n",
       "                      [-9.02658761e-01,  3.62014592e-01,  5.65240741e-01,\n",
       "                        4.47435856e+00, -1.02043033e-01, -4.50799018e-01]],\n",
       "             \n",
       "                     [[-1.07662715e-01,  3.69707309e-02,  5.47013469e-02,\n",
       "                        4.28592443e-01,  4.70740944e-02, -1.72286972e-01],\n",
       "                      [-1.17423153e+00,  4.58394140e-01,  6.02338135e-01,\n",
       "                        4.59639978e+00,  6.99372411e-01, -1.76450336e+00],\n",
       "                      [-9.00079370e-01,  3.63626212e-01,  4.66894954e-01,\n",
       "                        3.53846288e+00,  5.69326878e-01, -1.34760654e+00]],\n",
       "             \n",
       "                     [[-1.24820538e-01,  8.63790810e-02,  5.41293360e-02,\n",
       "                        3.35174739e-01,  7.32863918e-02, -1.26958698e-01],\n",
       "                      [-1.37310553e+00,  7.47363985e-01,  4.90535975e-01,\n",
       "                        3.43450689e+00,  9.78448987e-01, -1.51459146e+00],\n",
       "                      [-1.07025373e+00,  5.54171979e-01,  3.67658556e-01,\n",
       "                        2.62532735e+00,  7.82272995e-01, -1.19102967e+00]]],\n",
       "             \n",
       "             \n",
       "                    [[[-1.25339657e-01,  2.15803340e-01, -6.84463382e-02,\n",
       "                        3.68712872e-01, -2.22713366e-01,  1.59206405e-01],\n",
       "                      [-1.22030699e+00,  2.35558724e+00, -7.96317816e-01,\n",
       "                        4.53598928e+00, -2.27712107e+00,  1.91400409e+00],\n",
       "                      [-9.25531089e-01,  1.82136774e+00, -6.23308182e-01,\n",
       "                        3.57981992e+00, -1.74405932e+00,  1.50914168e+00]],\n",
       "             \n",
       "                     [[-1.37081593e-01,  1.60389498e-01, -2.78790649e-02,\n",
       "                        4.07027960e-01, -8.81924331e-02,  1.18732892e-01],\n",
       "                      [-1.53936338e+00,  1.41063845e+00, -3.63499820e-01,\n",
       "                        3.83554721e+00, -7.72007585e-01,  1.25423574e+00],\n",
       "                      [-1.20353103e+00,  1.04829729e+00, -2.86644310e-01,\n",
       "                        2.88931537e+00, -5.73612034e-01,  9.64356720e-01]],\n",
       "             \n",
       "                     [[-1.30668432e-01,  5.70565537e-02,  6.30966341e-03,\n",
       "                        4.92439300e-01, -1.11135365e-02,  3.99702415e-02],\n",
       "                      [-1.42246449e+00,  5.10786057e-01,  2.66868800e-01,\n",
       "                        5.83137274e+00, -2.08870590e-01,  3.57740134e-01],\n",
       "                      [-1.09403539e+00,  3.80517483e-01,  2.36520246e-01,\n",
       "                        4.56685925e+00, -1.70012519e-01,  2.67309189e-01]],\n",
       "             \n",
       "                     [[-1.43548012e-01,  8.98323506e-02,  3.82066779e-02,\n",
       "                        4.72400963e-01,  4.02967632e-02, -2.41008569e-02],\n",
       "                      [-1.57417798e+00,  9.11977351e-01,  5.47788382e-01,\n",
       "                        5.62771654e+00,  3.60672474e-01, -8.92189965e-02],\n",
       "                      [-1.21527719e+00,  6.95060730e-01,  4.43626404e-01,\n",
       "                        4.41753483e+00,  2.66702294e-01, -5.11785857e-02]],\n",
       "             \n",
       "                     [[-7.63228089e-02,  2.08725277e-02,  4.88082282e-02,\n",
       "                        4.08428043e-01,  7.61281699e-02, -3.02991234e-02],\n",
       "                      [-9.18053389e-01,  1.85093850e-01,  4.75636214e-01,\n",
       "                        4.38961792e+00,  1.03526676e+00, -3.79262000e-01],\n",
       "                      [-7.18270779e-01,  1.38436556e-01,  3.61374527e-01,\n",
       "                        3.38326073e+00,  8.28616321e-01, -3.05882394e-01]]],\n",
       "             \n",
       "             \n",
       "                    [[[-9.69191119e-02,  2.11116105e-01, -1.20208964e-01,\n",
       "                        3.47721815e-01, -2.40874365e-01,  1.44255251e-01],\n",
       "                      [-1.09174502e+00,  2.27095246e+00, -1.17153323e+00,\n",
       "                        4.03592539e+00, -2.84189367e+00,  1.79045510e+00],\n",
       "                      [-8.47508430e-01,  1.75494742e+00, -8.85970414e-01,\n",
       "                        3.15819430e+00, -2.23272562e+00,  1.41769516e+00]],\n",
       "             \n",
       "                     [[-1.65346071e-01,  1.31630570e-01, -6.27611428e-02,\n",
       "                        3.83119166e-01, -2.17871413e-01,  1.17725268e-01],\n",
       "                      [-1.87464070e+00,  1.19397497e+00, -7.18188226e-01,\n",
       "                        4.07225275e+00, -2.12702012e+00,  1.43528748e+00],\n",
       "                      [-1.45853901e+00,  8.96792531e-01, -5.59367895e-01,\n",
       "                        3.13229275e+00, -1.61598897e+00,  1.12720585e+00]],\n",
       "             \n",
       "                     [[-1.65819347e-01,  1.51503846e-01, -2.17106361e-02,\n",
       "                        4.84460086e-01, -5.98582365e-02,  5.93450107e-02],\n",
       "                      [-1.98610020e+00,  1.52762294e+00, -1.12155735e-01,\n",
       "                        4.85753155e+00, -5.82181692e-01,  4.44701314e-01],\n",
       "                      [-1.56276059e+00,  1.15995598e+00, -6.88310936e-02,\n",
       "                        3.69834375e+00, -4.41033781e-01,  3.21836412e-01]],\n",
       "             \n",
       "                     [[-1.25930279e-01,  4.50624153e-02,  2.12268066e-02,\n",
       "                        5.26028574e-01,  4.15218854e-03,  2.74534915e-02],\n",
       "                      [-1.16240370e+00,  3.84094089e-01,  3.68362635e-01,\n",
       "                        5.78571606e+00, -3.72775309e-02,  3.38059962e-01],\n",
       "                      [-8.67773712e-01,  2.82778114e-01,  3.05873513e-01,\n",
       "                        4.48250437e+00, -3.99202146e-02,  2.63537169e-01]],\n",
       "             \n",
       "                     [[-7.54839480e-02,  2.42860895e-02,  5.73472958e-03,\n",
       "                        5.08244336e-01,  1.11599481e-02, -2.11829692e-03],\n",
       "                      [-8.06580722e-01,  1.44899398e-01,  2.17812732e-01,\n",
       "                        5.69440460e+00,  6.59266338e-02, -2.66101807e-02],\n",
       "                      [-6.19931102e-01,  9.64480266e-02,  1.88810483e-01,\n",
       "                        4.41984987e+00,  5.39524853e-02, -2.06903629e-02]]],\n",
       "             \n",
       "             \n",
       "                    [[[-1.40598342e-01,  1.41407818e-01, -8.44900981e-02,\n",
       "                        3.93415898e-01, -2.55279779e-01,  1.25139847e-01],\n",
       "                      [-1.39356256e+00,  1.52324247e+00, -7.16733396e-01,\n",
       "                        3.76977563e+00, -3.33479810e+00,  1.49886572e+00],\n",
       "                      [-1.05735886e+00,  1.17543018e+00, -5.30360937e-01,\n",
       "                        2.84108067e+00, -2.65947747e+00,  1.16976690e+00]],\n",
       "             \n",
       "                     [[-1.48842722e-01,  1.32404029e-01, -6.72435015e-02,\n",
       "                        4.20692116e-01, -2.44344234e-01,  1.21334635e-01],\n",
       "                      [-1.68535447e+00,  1.57305598e+00, -7.38598883e-01,\n",
       "                        4.87402058e+00, -2.56321764e+00,  1.86758757e+00],\n",
       "                      [-1.30945587e+00,  1.23372948e+00, -5.72846413e-01,\n",
       "                        3.80824447e+00, -1.97236335e+00,  1.51677692e+00]],\n",
       "             \n",
       "                     [[-1.52676553e-01,  1.28348693e-01, -4.23691832e-02,\n",
       "                        4.23704803e-01, -1.14838853e-01,  8.05817097e-02],\n",
       "                      [-1.88399720e+00,  1.30246854e+00, -4.30681676e-01,\n",
       "                        4.37218809e+00, -1.06229174e+00,  8.32952380e-01],\n",
       "                      [-1.48125303e+00,  9.93168652e-01, -3.32207888e-01,\n",
       "                        3.33547664e+00, -8.00339401e-01,  6.37015879e-01]],\n",
       "             \n",
       "                     [[-1.33602798e-01,  5.95222935e-02, -5.52106388e-02,\n",
       "                        3.87611359e-01, -9.51299220e-02,  3.39649245e-02],\n",
       "                      [-1.46762025e+00,  4.42189336e-01, -2.80799687e-01,\n",
       "                        4.23496819e+00, -8.99978936e-01,  3.98124218e-01],\n",
       "                      [-1.13116479e+00,  3.18482220e-01, -1.68059751e-01,\n",
       "                        3.27056646e+00, -6.73244774e-01,  3.10266435e-01]],\n",
       "             \n",
       "                     [[-9.59785357e-02,  9.43171903e-02,  2.38971133e-02,\n",
       "                        3.76198977e-01, -5.17875738e-02,  5.44679491e-03],\n",
       "                      [-8.00315380e-01,  9.42796171e-01,  1.67337701e-01,\n",
       "                        4.29070759e+00, -7.82282352e-01,  6.64737225e-02],\n",
       "                      [-5.90034842e-01,  7.13361263e-01,  1.19833224e-01,\n",
       "                        3.34335136e+00, -6.31324708e-01,  4.93273363e-02]]]],      dtype=float32),\n",
       "         },\n",
       "         Conv_2: {\n",
       "             kernel: Array([[[[ 2.40086485e-02,  1.37441196e-02, -4.67972681e-02, ...,\n",
       "                        3.49399587e-03, -1.20921489e-02, -6.10992871e-02],\n",
       "                      [ 2.29858905e-02, -1.11567341e-02, -1.69191118e-02, ...,\n",
       "                        1.06268674e-02, -2.78279353e-02, -3.11915670e-02],\n",
       "                      [ 7.88073242e-02,  6.95459452e-03, -6.46736622e-02, ...,\n",
       "                        1.20162982e-02, -7.39781111e-02, -1.17142513e-01],\n",
       "                      [ 2.36129817e-02,  2.37275939e-03, -2.73121689e-02, ...,\n",
       "                        1.39983203e-02, -2.51531769e-02, -2.72797439e-02],\n",
       "                      [-5.03954366e-02,  1.66149344e-02, -2.09940486e-02, ...,\n",
       "                        3.53662856e-02,  1.11021912e-02,  6.13947585e-02],\n",
       "                      [ 1.36363488e-02, -1.33732508e-03, -3.85042652e-02, ...,\n",
       "                        3.44922990e-02, -1.98545735e-02, -1.79995839e-02]],\n",
       "             \n",
       "                     [[ 4.81387489e-02, -1.71880573e-02, -8.57937429e-03, ...,\n",
       "                       -2.08144612e-03, -6.74752519e-02, -4.72037122e-02],\n",
       "                      [-3.48463305e-03, -1.50577389e-02, -2.67205257e-02, ...,\n",
       "                        2.39109322e-02, -3.12132705e-02, -1.90434251e-02],\n",
       "                      [ 3.66623588e-02, -2.15639547e-02, -5.55588938e-02, ...,\n",
       "                        4.70986366e-02, -1.17137313e-01, -1.12964496e-01],\n",
       "                      [ 1.75968967e-02, -6.40085060e-03, -1.97973587e-02, ...,\n",
       "                        2.91598327e-02, -5.03989421e-02, -2.70942766e-02],\n",
       "                      [ 4.61550057e-02,  2.71800011e-02, -7.18625635e-03, ...,\n",
       "                       -2.68527437e-02,  4.70635109e-02, -1.55049888e-02],\n",
       "                      [ 2.15309542e-02,  2.77493894e-03, -2.19406281e-02, ...,\n",
       "                        1.69977639e-02, -3.46655101e-02, -3.68801020e-02]],\n",
       "             \n",
       "                     [[ 1.02777127e-02, -1.55298933e-02, -2.65413504e-02, ...,\n",
       "                        4.65572327e-02, -9.06875134e-02, -5.55250607e-02],\n",
       "                      [ 2.49301083e-02, -2.97006629e-02, -2.30825394e-02, ...,\n",
       "                        1.43991085e-02, -3.61158401e-02, -3.64437327e-02],\n",
       "                      [ 1.68803278e-02, -2.54062489e-02, -4.24081609e-02, ...,\n",
       "                        8.29235688e-02, -1.64702073e-01, -7.85418823e-02],\n",
       "                      [ 8.64458457e-03, -5.57227340e-03, -1.74692478e-02, ...,\n",
       "                        2.05498915e-02, -6.17572851e-02, -4.00523022e-02],\n",
       "                      [ 2.39843540e-02,  3.29332030e-03, -8.70201085e-03, ...,\n",
       "                       -4.86379080e-02,  1.65502715e-03, -3.08723971e-02],\n",
       "                      [ 9.29284189e-03, -1.39136156e-02, -2.84701660e-02, ...,\n",
       "                        1.47655345e-02, -6.00211844e-02, -3.31930183e-02]],\n",
       "             \n",
       "                     [[ 4.25937073e-03, -1.05716716e-02, -3.26930434e-02, ...,\n",
       "                        1.84395909e-02, -6.71558827e-02, -5.53401001e-02],\n",
       "                      [ 3.89763527e-02, -4.03973721e-02, -1.61957629e-02, ...,\n",
       "                       -8.24639283e-05, -9.39612649e-03, -2.17508432e-02],\n",
       "                      [ 3.29743363e-02, -5.14566451e-02, -4.51376513e-02, ...,\n",
       "                        6.61995038e-02, -1.92583308e-01, -9.13799703e-02],\n",
       "                      [ 1.09336497e-02, -1.82714071e-02, -2.03249007e-02, ...,\n",
       "                        1.67501122e-02, -4.19576615e-02, -3.66331302e-02],\n",
       "                      [ 1.77806467e-02,  9.26037971e-03, -6.25817850e-03, ...,\n",
       "                        3.86201665e-02, -1.34831453e-02, -2.79312842e-02],\n",
       "                      [ 9.15308576e-03, -1.30622806e-02, -2.48352028e-02, ...,\n",
       "                        3.03003266e-02, -3.39463651e-02, -3.34955007e-02]],\n",
       "             \n",
       "                     [[ 2.66266316e-02, -2.59080790e-02, -2.31016912e-02, ...,\n",
       "                        1.89651772e-02, -5.80438785e-02, -3.29333246e-02],\n",
       "                      [ 1.26843050e-03, -7.54260272e-03, -2.05915291e-02, ...,\n",
       "                       -7.82153849e-03, -2.98699690e-03, -2.40669642e-02],\n",
       "                      [ 4.14568046e-03, -4.58661988e-02, -5.08018062e-02, ...,\n",
       "                        2.99126487e-02, -1.06636696e-01, -8.15815032e-02],\n",
       "                      [ 6.77549979e-03, -6.84913760e-03, -1.86690651e-02, ...,\n",
       "                        7.50521803e-03, -2.71499883e-02, -2.62817256e-02],\n",
       "                      [-2.53695585e-02,  2.19912361e-02, -1.97101645e-02, ...,\n",
       "                        2.47204360e-02, -7.30287582e-02, -2.00764500e-02],\n",
       "                      [ 1.18918400e-02, -1.23934513e-02, -1.43391173e-02, ...,\n",
       "                        8.41324590e-03, -2.60452460e-02, -2.03475803e-02]]],\n",
       "             \n",
       "             \n",
       "                    [[[-1.34897977e-02,  9.19676106e-03, -2.56469976e-02, ...,\n",
       "                        1.91101711e-02,  1.05347121e-02, -2.38255356e-02],\n",
       "                      [ 3.59862261e-02, -7.56039401e-04, -1.60572380e-02, ...,\n",
       "                        3.72697636e-02, -2.69601662e-02, -3.69059741e-02],\n",
       "                      [ 4.09618914e-02,  3.54089104e-02, -6.12058304e-02, ...,\n",
       "                        6.39255205e-03, -2.53700055e-02, -6.32317588e-02],\n",
       "                      [ 1.90166142e-02,  2.23933463e-03, -3.90703939e-02, ...,\n",
       "                        2.51181424e-02, -1.68982260e-02, -2.00958438e-02],\n",
       "                      [-5.77133633e-02, -8.00723862e-03, -4.12882380e-02, ...,\n",
       "                       -3.90530680e-04, -1.56318098e-02,  8.75766277e-02],\n",
       "                      [ 1.56071717e-02, -1.16598490e-03, -3.57485265e-02, ...,\n",
       "                        2.14576516e-02, -3.56709361e-02, -2.76341587e-02]],\n",
       "             \n",
       "                     [[ 4.19788621e-02,  1.61464885e-02,  4.89939144e-03, ...,\n",
       "                        3.19654867e-02, -5.10920398e-02, -3.35564315e-02],\n",
       "                      [ 1.15834817e-03,  1.14526236e-02, -1.64876897e-02, ...,\n",
       "                        3.13657820e-02, -3.94605249e-02, -2.30958760e-02],\n",
       "                      [ 7.29734674e-02,  1.56011954e-02, -2.27023922e-02, ...,\n",
       "                       -2.14552097e-02, -8.39606300e-02, -1.14975542e-01],\n",
       "                      [ 3.44016566e-03,  5.35970507e-03, -2.44191661e-02, ...,\n",
       "                        8.75227898e-03, -2.80730613e-02, -4.07216959e-02],\n",
       "                      [-4.74317446e-02,  1.27927484e-02, -1.84761062e-02, ...,\n",
       "                        4.12333803e-03,  7.80774355e-02,  3.00487131e-02],\n",
       "                      [-2.65785167e-03, -2.14194646e-03, -2.48033591e-02, ...,\n",
       "                        2.33731978e-02, -2.88991835e-02, -2.61611622e-02]],\n",
       "             \n",
       "                     [[ 1.10872220e-02, -2.36111158e-03,  1.50413457e-02, ...,\n",
       "                        2.96489131e-02, -7.81677887e-02, -5.64691350e-02],\n",
       "                      [ 1.32831689e-02, -3.51433735e-03, -1.83911528e-02, ...,\n",
       "                        1.67530775e-02, -5.50514050e-02, -2.46151444e-02],\n",
       "                      [ 2.57772505e-02, -2.40510479e-02, -2.28317082e-02, ...,\n",
       "                        3.89118791e-02, -1.54101312e-01, -1.00330770e-01],\n",
       "                      [ 3.15914787e-02, -2.17674021e-02, -2.12600734e-02, ...,\n",
       "                        2.06782557e-02, -5.32481968e-02, -3.89970914e-02],\n",
       "                      [ 7.07724169e-02,  2.84781419e-02,  3.79640833e-02, ...,\n",
       "                       -2.26041321e-02,  2.44176947e-02,  2.62271613e-03],\n",
       "                      [ 2.73999367e-02, -1.71110907e-03, -2.04752926e-02, ...,\n",
       "                        2.86628567e-02, -4.89471927e-02, -3.26549783e-02]],\n",
       "             \n",
       "                     [[ 1.28803980e-02, -1.39062591e-02, -1.35708610e-02, ...,\n",
       "                        1.11031672e-02, -6.74287155e-02, -5.70561998e-02],\n",
       "                      [ 1.52613968e-02,  9.83848469e-04, -2.38739327e-02, ...,\n",
       "                        3.55373602e-03, -4.24777418e-02, -1.70009043e-02],\n",
       "                      [ 5.09725185e-03, -1.57865472e-02, -5.13235852e-02, ...,\n",
       "                        8.06488469e-02, -1.95855618e-01, -9.95221734e-02],\n",
       "                      [ 1.09031657e-02, -2.49530599e-02, -2.79365070e-02, ...,\n",
       "                        2.04712730e-02, -6.36034533e-02, -4.96628918e-02],\n",
       "                      [ 1.43955145e-02,  1.84796914e-03,  2.75836512e-02, ...,\n",
       "                       -3.17528211e-02, -5.06204832e-03, -2.93005984e-02],\n",
       "                      [ 9.68280900e-03, -1.03511987e-02, -1.19180186e-02, ...,\n",
       "                        6.24608528e-03, -4.61736843e-02, -3.70201692e-02]],\n",
       "             \n",
       "                     [[ 1.68996807e-02, -1.21814944e-02, -2.83117834e-02, ...,\n",
       "                        2.24789865e-02, -7.16992170e-02, -4.32596058e-02],\n",
       "                      [-6.13289326e-03,  7.42375432e-03, -1.44018354e-02, ...,\n",
       "                        2.15182714e-02, -3.81729305e-02, -1.71415638e-02],\n",
       "                      [ 1.45873651e-02, -4.19413298e-02, -4.50221524e-02, ...,\n",
       "                        6.35531992e-02, -1.66545957e-01, -7.88076892e-02],\n",
       "                      [ 3.53314281e-02, -3.43661159e-02, -1.37209566e-02, ...,\n",
       "                        1.83287989e-02, -4.74516638e-02, -4.28817160e-02],\n",
       "                      [-1.12668965e-02,  1.90020259e-02,  3.42829473e-04, ...,\n",
       "                        1.02461483e-02, -2.49383487e-02, -5.58228083e-02],\n",
       "                      [ 1.17701599e-02, -5.76793822e-03, -1.76650379e-02, ...,\n",
       "                        5.59637905e-04, -3.49916629e-02, -2.88377851e-02]]],\n",
       "             \n",
       "             \n",
       "                    [[[ 1.13849379e-02,  7.00779632e-03, -5.23055345e-03, ...,\n",
       "                        1.69017166e-02,  1.43828047e-02, -4.30876529e-03],\n",
       "                      [ 1.74331143e-02,  1.28281247e-02,  1.26149422e-02, ...,\n",
       "                        3.30449292e-03,  8.01310781e-03, -3.89001593e-02],\n",
       "                      [-2.30130330e-02,  3.97183597e-02, -3.72449532e-02, ...,\n",
       "                        1.89220123e-02,  1.29507091e-02, -4.83050151e-03],\n",
       "                      [ 2.32940745e-02,  1.16762845e-02, -3.27503756e-02, ...,\n",
       "                        3.97312865e-02, -1.26740290e-02, -2.57523190e-02],\n",
       "                      [-6.07952923e-02, -6.21677004e-03, -3.40580344e-02, ...,\n",
       "                        4.30547558e-02, -5.37345298e-02,  8.89218971e-02],\n",
       "                      [ 7.35192094e-03, -1.99549086e-03, -1.53364101e-02, ...,\n",
       "                        2.60413643e-02, -1.73745546e-02, -9.84612294e-03]],\n",
       "             \n",
       "                     [[ 3.29286531e-02,  2.21126601e-02,  2.01691519e-02, ...,\n",
       "                        7.61357741e-03, -2.02121623e-02, -3.00340280e-02],\n",
       "                      [ 9.04340949e-03,  1.99941657e-02,  2.26576924e-02, ...,\n",
       "                       -4.42882022e-03, -4.30395454e-02, -2.83887424e-02],\n",
       "                      [ 7.41862580e-02,  5.05809188e-02,  2.05500387e-02, ...,\n",
       "                       -4.23144083e-03, -4.78259586e-02, -8.26294050e-02],\n",
       "                      [ 2.51569878e-02,  1.33083668e-02, -2.48954166e-02, ...,\n",
       "                        2.57615056e-02, -3.34623083e-02, -2.48352792e-02],\n",
       "                      [-7.37770498e-02, -3.77041125e-03, -5.45457341e-02, ...,\n",
       "                        4.01263684e-03,  5.28484583e-02,  7.39866197e-02],\n",
       "                      [-1.41274268e-02,  1.68763567e-03, -1.49921598e-02, ...,\n",
       "                        9.99720418e-04, -2.61171423e-02, -1.04329549e-02]],\n",
       "             \n",
       "                     [[ 9.99311917e-03,  1.49447601e-02,  2.85835974e-02, ...,\n",
       "                       -9.68592428e-03, -6.40465841e-02, -3.85298058e-02],\n",
       "                      [ 2.80312146e-04, -7.40408432e-04, -1.83978712e-03, ...,\n",
       "                        3.02909501e-02, -3.26976404e-02, -1.54114850e-02],\n",
       "                      [ 5.89010939e-02,  1.99183356e-02,  4.18490283e-02, ...,\n",
       "                        2.30063833e-02, -1.23268701e-01, -7.71129578e-02],\n",
       "                      [ 1.28188366e-02,  4.82409121e-03, -2.29920670e-02, ...,\n",
       "                        2.23029051e-02, -6.25884831e-02, -3.40819545e-02],\n",
       "                      [ 4.19196859e-02,  2.66294833e-02,  7.38063594e-04, ...,\n",
       "                       -5.59138507e-03,  5.69452904e-02,  9.96070728e-03],\n",
       "                      [ 1.84077565e-02,  6.31589629e-03, -1.81899685e-02, ...,\n",
       "                        2.51254681e-02, -4.62103188e-02, -4.16994467e-02]],\n",
       "             \n",
       "                     [[ 9.56495572e-03, -1.13138454e-02,  1.05637871e-02, ...,\n",
       "                       -1.03378261e-03, -5.40398322e-02, -3.28863189e-02],\n",
       "                      [-8.34707229e-04,  1.77878216e-02, -1.96079146e-02, ...,\n",
       "                        2.04013698e-02, -2.91255582e-02, -2.22792849e-02],\n",
       "                      [-3.90882976e-03, -7.55363144e-03, -8.59274901e-03, ...,\n",
       "                        5.79169057e-02, -1.49171650e-01, -9.78609547e-02],\n",
       "                      [ 8.35594162e-03,  4.66339337e-03, -2.45761629e-02, ...,\n",
       "                        1.23639582e-02, -7.17682764e-02, -3.49436253e-02],\n",
       "                      [ 2.76549011e-02,  2.72988733e-02,  7.35943168e-02, ...,\n",
       "                       -4.09535691e-02,  6.87299436e-03, -6.92775007e-03],\n",
       "                      [ 5.44325076e-03,  1.11843774e-03, -4.71377885e-03, ...,\n",
       "                        7.57730287e-03, -5.30034713e-02, -2.93518398e-02]],\n",
       "             \n",
       "                     [[ 2.83609610e-02, -1.17729763e-02, -1.45193283e-02, ...,\n",
       "                        1.36185428e-02, -6.72143698e-02, -4.43237945e-02],\n",
       "                      [-1.69972163e-02,  3.67531087e-03, -2.21914165e-02, ...,\n",
       "                        2.74243113e-02, -2.66975407e-02, -8.32367223e-03],\n",
       "                      [ 3.81850800e-03, -7.00760260e-03, -5.53973578e-02, ...,\n",
       "                        5.71559928e-02, -1.53941602e-01, -8.03757608e-02],\n",
       "                      [ 1.43391732e-02, -1.18397782e-02, -2.35379227e-02, ...,\n",
       "                        1.54284975e-02, -5.82363605e-02, -2.95221787e-02],\n",
       "                      [ 3.64199914e-02, -2.50319429e-02,  3.33527848e-02, ...,\n",
       "                       -2.20882986e-02,  5.73334703e-03, -1.55212833e-02],\n",
       "                      [ 1.52130844e-02, -1.22903101e-02, -1.58240516e-02, ...,\n",
       "                        1.55269019e-02, -4.10696231e-02, -2.95893960e-02]]],\n",
       "             \n",
       "             \n",
       "                    [[[-3.13423038e-03,  1.29933166e-03, -3.33928540e-02, ...,\n",
       "                        3.64602217e-03, -1.40984757e-02,  1.56263653e-02],\n",
       "                      [-4.12517693e-03, -1.43883575e-04, -8.81227478e-03, ...,\n",
       "                       -3.79437879e-02,  4.26754244e-02, -1.28535461e-02],\n",
       "                      [-4.48961854e-02,  1.56234801e-02, -4.88496609e-02, ...,\n",
       "                        1.35962367e-02, -3.07003525e-03,  8.07960853e-02],\n",
       "                      [-3.24459793e-03,  1.97626650e-02, -2.19305158e-02, ...,\n",
       "                        1.70258172e-02,  4.40888572e-03, -1.12583926e-02],\n",
       "                      [-9.11983475e-03,  2.05306634e-02, -4.56446745e-02, ...,\n",
       "                        3.56316119e-02, -5.86234890e-02, -4.50491393e-03],\n",
       "                      [ 8.67552403e-03,  6.40951563e-03, -2.12489329e-02, ...,\n",
       "                        2.75758398e-03, -2.05318239e-02, -9.03277192e-03]],\n",
       "             \n",
       "                     [[-2.09031207e-03,  8.63676984e-03, -1.91177689e-02, ...,\n",
       "                        1.36261142e-03,  4.33982909e-03, -1.32386703e-02],\n",
       "                      [ 5.32994792e-03, -4.06399230e-03,  1.65236741e-02, ...,\n",
       "                       -2.92818435e-02, -2.39412095e-02,  5.72413532e-03],\n",
       "                      [ 1.98662058e-02,  4.33783494e-02,  4.00450230e-02, ...,\n",
       "                       -3.18741947e-02,  3.41293737e-02, -1.99598018e-02],\n",
       "                      [ 1.50036151e-02,  4.15739696e-03, -2.54549365e-03, ...,\n",
       "                        7.89660867e-03, -3.64768878e-02, -2.30910145e-02],\n",
       "                      [-1.91961378e-02, -3.59268743e-03, -4.62158993e-02, ...,\n",
       "                        3.13064530e-02, -8.44692811e-03,  8.17982107e-02],\n",
       "                      [ 4.32197098e-03,  6.99164718e-03, -1.89315493e-03, ...,\n",
       "                       -4.23222827e-03, -2.63723414e-02, -4.89143480e-04]],\n",
       "             \n",
       "                     [[ 3.43428180e-03,  6.63290313e-03,  9.72260442e-03, ...,\n",
       "                       -1.47285257e-02, -5.08724153e-02,  9.45443008e-03],\n",
       "                      [ 6.79703383e-03, -8.77897348e-03, -3.21750040e-03, ...,\n",
       "                       -1.02036796e-03, -1.38565646e-02, -5.86116221e-04],\n",
       "                      [ 6.43202215e-02,  4.22853716e-02,  1.06277756e-01, ...,\n",
       "                       -1.53272646e-02, -8.04116875e-02, -5.22003584e-02],\n",
       "                      [ 2.04098355e-02,  9.50052682e-03,  1.29481545e-03, ...,\n",
       "                        1.13433748e-02, -5.36655597e-02, -2.19887476e-02],\n",
       "                      [-4.87874039e-02, -5.83428750e-03, -5.31655923e-02, ...,\n",
       "                        1.97070111e-02,  4.92435731e-02,  4.25208062e-02],\n",
       "                      [-2.50597415e-03, -1.67329318e-03, -4.13540890e-03, ...,\n",
       "                        1.23496447e-02, -2.05466095e-02, -1.41690401e-02]],\n",
       "             \n",
       "                     [[ 2.74024531e-03,  1.18258568e-02,  1.46413464e-02, ...,\n",
       "                        1.44301518e-03, -5.00915684e-02,  1.30033856e-02],\n",
       "                      [ 1.38718802e-02, -5.28313685e-03, -1.21668298e-02, ...,\n",
       "                        3.43170273e-03, -2.73073390e-02, -2.07867958e-02],\n",
       "                      [ 3.39581445e-02,  4.24161414e-03,  7.04521239e-02, ...,\n",
       "                        2.12169997e-02, -1.04273662e-01, -6.97561875e-02],\n",
       "                      [ 1.44431274e-02,  2.57524452e-03, -2.60858168e-03, ...,\n",
       "                        2.93465294e-02, -6.37946278e-02, -2.34249290e-02],\n",
       "                      [ 1.25051904e-02,  3.89098339e-02,  1.18680513e-02, ...,\n",
       "                       -3.92832011e-02,  2.39203330e-02,  3.83556001e-02],\n",
       "                      [ 8.56483728e-03,  5.65289147e-03, -5.98709099e-03, ...,\n",
       "                        2.38237111e-03, -3.90069000e-02, -9.62660462e-03]],\n",
       "             \n",
       "                     [[ 2.85010599e-02, -8.01779330e-03,  2.41009379e-03, ...,\n",
       "                        1.94009561e-02, -5.77782467e-02, -3.16341296e-02],\n",
       "                      [-4.50853677e-03, -2.18638638e-03, -1.47206271e-02, ...,\n",
       "                        1.25752287e-02, -3.62245925e-02, -2.00821590e-02],\n",
       "                      [ 7.18220510e-03, -7.28078280e-03,  9.30897892e-04, ...,\n",
       "                        4.42747995e-02, -1.38545662e-01, -8.73998702e-02],\n",
       "                      [-5.10491850e-03,  9.11546312e-03, -1.86069068e-02, ...,\n",
       "                        1.91608444e-02, -5.59358038e-02, -2.94268616e-02],\n",
       "                      [ 5.61133586e-03,  1.81397684e-02,  5.92991821e-02, ...,\n",
       "                       -4.33364548e-02, -2.17919657e-03,  1.72085539e-02],\n",
       "                      [ 1.51952747e-02,  3.42311850e-03,  3.09181167e-03, ...,\n",
       "                        8.91857594e-03, -4.21264842e-02, -1.22467810e-02]]],\n",
       "             \n",
       "             \n",
       "                    [[[-2.10359283e-02,  2.20635030e-02, -5.58424294e-02, ...,\n",
       "                       -5.18485066e-03, -5.47585264e-02,  1.74113791e-02],\n",
       "                      [-4.61722119e-03, -2.64449529e-02, -2.73103397e-02, ...,\n",
       "                       -1.27602536e-02,  1.23605747e-02,  3.37516591e-02],\n",
       "                      [-5.49287796e-02,  2.42308713e-02, -7.03973398e-02, ...,\n",
       "                        2.67826971e-02, -8.01146701e-02,  1.12634547e-01],\n",
       "                      [-1.99535154e-02,  5.29597374e-03, -3.62087972e-02, ...,\n",
       "                       -2.23383699e-02, -1.01263113e-02,  1.79365389e-02],\n",
       "                      [-3.28839533e-02,  3.53965946e-02, -1.23803765e-02, ...,\n",
       "                       -1.28045259e-02,  3.32824737e-02, -6.80934340e-02],\n",
       "                      [-1.38860177e-02,  1.26135787e-02, -1.76781453e-02, ...,\n",
       "                       -1.31611973e-02,  6.09828345e-03, -2.53532571e-03]],\n",
       "             \n",
       "                     [[-7.11054821e-03, -1.87532306e-02, -3.74002233e-02, ...,\n",
       "                       -1.07617909e-02, -3.51580530e-02,  1.45736174e-03],\n",
       "                      [ 4.07296419e-03,  3.05867684e-03, -9.42495931e-03, ...,\n",
       "                       -1.81078408e-02, -2.60786321e-02,  3.41535658e-02],\n",
       "                      [-1.48810139e-02,  1.39139621e-02, -1.82085633e-02, ...,\n",
       "                       -1.38036383e-03,  3.15473042e-02,  7.87004009e-02],\n",
       "                      [-1.62712634e-02, -8.48589407e-04, -1.01938490e-02, ...,\n",
       "                       -2.14355402e-02,  1.65544465e-04,  1.06857875e-02],\n",
       "                      [-3.82768586e-02,  1.33229038e-02, -6.18064366e-02, ...,\n",
       "                        3.53301354e-02, -9.40721259e-02,  3.94850038e-03],\n",
       "                      [-1.30355153e-02,  1.01212447e-03, -9.92381014e-03, ...,\n",
       "                       -1.02350637e-02, -4.16324995e-02,  1.79297309e-02]],\n",
       "             \n",
       "                     [[ 2.11690105e-02,  2.67389626e-03,  7.49844639e-03, ...,\n",
       "                       -4.74847446e-04, -4.03044000e-02,  2.55416408e-02],\n",
       "                      [-5.32261387e-04, -1.10264085e-02, -1.78336992e-03, ...,\n",
       "                        4.72836895e-03, -2.45044511e-02,  2.60691885e-02],\n",
       "                      [ 1.88230854e-02,  4.94957604e-02,  6.18071444e-02, ...,\n",
       "                       -3.37838158e-02,  2.15206412e-03,  7.32613821e-03],\n",
       "                      [ 1.33139119e-02,  4.21881065e-04,  1.03615914e-02, ...,\n",
       "                       -1.01275612e-02, -3.16122361e-02,  5.66168595e-03],\n",
       "                      [ 4.03769966e-03, -2.75245905e-02, -7.69281536e-02, ...,\n",
       "                        3.66971977e-02,  3.31219891e-03,  3.39400060e-02],\n",
       "                      [ 3.95636866e-03, -3.12354881e-03, -5.37412986e-03, ...,\n",
       "                       -2.99443291e-05, -2.80662309e-02,  5.35162399e-03]],\n",
       "             \n",
       "                     [[ 6.59332285e-03,  8.46709590e-03,  2.59935800e-02, ...,\n",
       "                        1.07579064e-02, -6.79624304e-02,  3.20804492e-02],\n",
       "                      [-1.47687020e-02, -8.68028030e-03, -1.14226351e-02, ...,\n",
       "                       -1.01113867e-03, -1.96525604e-02, -2.27430277e-03],\n",
       "                      [ 6.21778134e-04,  3.01018748e-02,  1.06337957e-01, ...,\n",
       "                       -4.82797064e-02, -5.49191572e-02, -2.39689630e-02],\n",
       "                      [ 7.82810897e-03, -1.26228442e-05,  7.04518380e-03, ...,\n",
       "                       -4.52854810e-03, -4.13193256e-02, -1.54203707e-02],\n",
       "                      [-2.21769288e-02,  6.58797892e-03, -3.94066945e-02, ...,\n",
       "                        1.13651259e-02, -1.83642039e-03,  5.86762875e-02],\n",
       "                      [ 2.60918401e-03, -8.56614206e-03, -7.10722670e-05, ...,\n",
       "                        7.38176843e-03, -3.34767662e-02,  8.30300152e-03]],\n",
       "             \n",
       "                     [[-1.19924853e-02,  8.82689317e-04,  5.59991272e-03, ...,\n",
       "                        3.93175613e-03, -3.56235430e-02, -2.65959725e-02],\n",
       "                      [ 9.04443767e-03, -7.25913607e-03, -2.40046508e-03, ...,\n",
       "                       -1.92288484e-03, -2.86059305e-02, -1.90410111e-02],\n",
       "                      [ 3.14602889e-02, -1.04839774e-02,  7.51231983e-02, ...,\n",
       "                       -1.17947171e-02, -6.71561658e-02, -5.41367754e-02],\n",
       "                      [ 1.49989268e-02,  3.19662760e-03,  1.29839974e-02, ...,\n",
       "                        3.10486602e-03, -4.79201823e-02, -2.66475212e-02],\n",
       "                      [-8.16471037e-03,  3.94370742e-02,  2.60442272e-02, ...,\n",
       "                       -1.25307208e-02, -1.19065410e-02,  5.06335162e-02],\n",
       "                      [-3.45474877e-03,  1.00340620e-02,  8.48315842e-03, ...,\n",
       "                        7.43013993e-03, -4.42442037e-02, -6.53251261e-03]]]],      dtype=float32),\n",
       "         },\n",
       "         GDN_0: {\n",
       "             Conv_0: {\n",
       "                 bias: Array([ 0.54218113, -0.61999565,  0.21937184], dtype=float32),\n",
       "                 kernel: Array([[[[ 0.4244105 , -0.38610113,  0.18590061]]]], dtype=float32),\n",
       "             },\n",
       "         },\n",
       "         GDN_1: {\n",
       "             Conv_0: {\n",
       "                 bias: Array([-0.21493903,  0.13626796, -0.12649758], dtype=float32),\n",
       "                 kernel: Array([[[[-0.00132226,  0.00218583, -0.00101497],\n",
       "                          [-0.22647151,  0.46604645, -0.18457264],\n",
       "                          [-0.13117787,  0.2713235 , -0.10667253]]]], dtype=float32),\n",
       "             },\n",
       "         },\n",
       "         GDN_2: {\n",
       "             Conv_0: {\n",
       "                 bias: Array([-0.39774576,  0.10436349, -0.11585095,  0.96252316, -0.6792717 ,\n",
       "                         0.09854216], dtype=float32),\n",
       "                 kernel: Array([[[[-0.10818238, -0.00826944,  0.09022062,  0.13871236,\n",
       "                           -0.13319325,  0.05297286],\n",
       "                          [-0.02815102, -0.00223234,  0.01760283,  0.04308255,\n",
       "                           -0.02042174,  0.01443571],\n",
       "                          [-0.21066403, -0.00372794,  0.10098276,  0.37485337,\n",
       "                            0.01873473,  0.08864412],\n",
       "                          [-0.01345949,  0.00397147, -0.02516493,  0.0858486 ,\n",
       "                           -0.00388587, -0.004392  ],\n",
       "                          [-0.13729733,  0.0454917 ,  0.14735924,  0.37447128,\n",
       "                           -0.11652569,  0.17272323],\n",
       "                          [-0.00780154,  0.00060352,  0.03091894,  0.03473066,\n",
       "                           -0.00969923,  0.02500463]]]], dtype=float32),\n",
       "             },\n",
       "         },\n",
       "         GDN_3: {\n",
       "             Conv_0: {\n",
       "                 bias: Array([ 7.0965296e-04, -4.7067171e-03,  7.6158601e-03, -6.6508679e-03,\n",
       "                         1.0076073e-03, -4.5431382e-03,  1.3322576e+00,  3.7670983e-03,\n",
       "                        -1.1563521e-02,  9.9847438e-03, -5.0128298e-03,  2.3901118e-03,\n",
       "                         1.2024946e-02,  6.0068588e-03,  7.8381253e-03, -1.1226946e-02,\n",
       "                        -1.3356328e-02, -1.1436724e-03, -6.8989340e-03,  1.2507116e-02,\n",
       "                         2.2276944e-02, -4.2237015e-03, -1.2743833e-02,  3.1157588e-03,\n",
       "                         1.6710270e-02, -4.7681723e-03, -1.3198085e-01, -1.3174656e-02,\n",
       "                        -5.7014003e-03, -7.3041812e-02,  2.3408723e-03,  4.5678481e-03,\n",
       "                        -4.7671027e-04, -3.0392285e-03, -2.3813725e-03, -9.7914543e-03,\n",
       "                         7.0294744e-01,  1.0562331e-03, -3.1624511e-02,  2.5104408e-03,\n",
       "                         5.4767202e-03,  5.3839316e-04, -4.7588451e-03,  9.7791024e-04,\n",
       "                         2.7082888e-03,  4.9104379e-03,  2.2913858e-02,  1.7386093e-03,\n",
       "                         4.1960926e+00, -8.2432327e-04,  4.9429186e-02, -3.8960576e-03,\n",
       "                        -1.3787117e-03,  9.6631860e-03,  2.4941512e-03, -3.7195184e-03,\n",
       "                        -2.3138307e-03,  5.1501803e-03, -1.7890215e-03, -3.6448347e-03,\n",
       "                         5.8872474e-04, -6.1172959e-03, -1.4131413e-03, -4.6451674e-03,\n",
       "                         5.8443449e-04,  4.5086672e-03,  2.0801495e-03,  3.1846729e-03,\n",
       "                        -1.0665557e-03,  1.8150931e-02, -6.5361825e-03, -5.6392713e-03,\n",
       "                        -4.9706390e-03,  9.8148687e-04, -2.2994485e-03, -2.2917408e-02,\n",
       "                         5.2352981e-03, -1.0587244e-02,  2.7796985e-03,  8.9332717e-04,\n",
       "                         1.9014735e-02, -2.1366535e-03,  1.0969112e-02, -7.5570242e-03,\n",
       "                         6.6895992e-03,  6.1167378e+00,  2.3655554e-03,  2.0447695e-03,\n",
       "                        -1.0175670e-02, -1.5168244e-02, -5.1087841e-02, -3.1707368e-03,\n",
       "                         3.7851743e-03,  1.6208218e-03,  5.3993724e-03, -5.3132348e-02,\n",
       "                        -1.0254854e-02,  7.5314799e-04,  4.4579380e-03,  1.0608714e-02,\n",
       "                         5.3906825e-04,  7.2087999e-04, -1.5311040e-02, -3.3865243e-01,\n",
       "                         5.6546915e-04, -8.8898903e-03, -7.7799745e-03, -2.7124272e-03,\n",
       "                         4.3898029e-04, -1.4778840e-02, -3.5951196e-03,  9.2729758e-03,\n",
       "                        -1.7067945e-03,  1.5852310e-01,  4.7307657e-03, -1.1601031e-02,\n",
       "                        -1.1649819e-03, -3.1018571e-04,  3.7320030e-03, -1.1148590e-03,\n",
       "                         1.6809644e-02,  2.3479527e-03, -1.1122207e-02,  6.5772431e-03,\n",
       "                        -8.9188851e-03, -1.1129088e-03, -2.8907087e-02, -2.3637387e-01],      dtype=float32),\n",
       "                 kernel: Array([[[[ 4.1427538e-05, -9.7390788e-05,  3.0119420e-04, ...,\n",
       "                           -4.3364786e-04, -5.3847244e-04, -3.2503254e-04],\n",
       "                          [ 1.2057218e-05, -1.4751808e-04,  4.8112907e-04, ...,\n",
       "                           -4.4148710e-05, -1.0729051e-03, -3.7405547e-04],\n",
       "                          [-6.0326744e-05, -1.1886083e-04,  4.1206144e-03, ...,\n",
       "                            2.6497524e-04, -1.2386767e-03,  9.9329907e-04],\n",
       "                          ...,\n",
       "                          [ 3.9618308e-04, -1.8704930e-04,  3.5069551e-04, ...,\n",
       "                            6.3323166e-04, -2.1973464e-03, -5.9519534e-04],\n",
       "                          [ 2.8884309e-04, -2.9532256e-04,  1.4734120e-02, ...,\n",
       "                            3.9482811e-03, -1.7814459e-02, -1.6325696e-03],\n",
       "                          [ 5.9837609e-04, -6.8292191e-04,  6.1501730e-03, ...,\n",
       "                           -1.3310737e-04, -8.3032046e-03,  9.3871553e-04]]]],      dtype=float32),\n",
       "             },\n",
       "         },\n",
       "     },\n",
       " }))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.value_and_grad(loss_one_sample, argnums=0)(state.params, img_prob, label_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbax_checkpointer.save(os.path.join(wandb.run.dir, \"model-final\"), state, save_args=save_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da5141a55de43f9a5c077a362efe5e2ae0cb795b0fc8676e62dbd4f64287ec27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
