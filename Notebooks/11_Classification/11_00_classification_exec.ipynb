{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os; os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from fastcore.xtras import Path\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "import scipy.stats as stats\n",
    "\n",
    "from perceptnet.networks import *\n",
    "from iqadatasets.datasets.tid2013 import TID2013\n",
    "\n",
    "from flayers.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluatePerceptuality(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Evaluates a perceptual model that is part of another model.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 dst, # Dataset to be evaluated.\n",
    "                 model, # Model to be evaluated.\n",
    "                 name=None, # Name to prepend to the logged metrics.\n",
    "                 ):\n",
    "        self.dst = dst\n",
    "        self.eval_model = model\n",
    "        self.name = \"\" if name is None else name+\"_\"\n",
    "        \n",
    "    def on_epoch_end(self,\n",
    "                     epoch, \n",
    "                     logs=None):\n",
    "        distances, moses = [], []\n",
    "        for i, data in enumerate(self.dst):\n",
    "            img, dist_img, mos = data\n",
    "            features_original = self.eval_model(img, training=False)\n",
    "            features_distorted = self.eval_model(dist_img, training=False)\n",
    "            l2 = (features_original-features_distorted)**2\n",
    "            l2 = tf.reduce_sum(l2, axis=[1,2,3])\n",
    "            l2 = tf.sqrt(l2)\n",
    "            distances.extend(l2)\n",
    "            moses.extend(mos)\n",
    "        pearson = stats.pearsonr(distances, moses)[0]\n",
    "        spearman = stats.spearmanr(distances, moses)[0]\n",
    "        wandb.log({f\"{self.name}Pearson\": pearson,\n",
    "                   f\"{self.name}Spearman\": spearman}, commit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'epochs':500,\n",
    "        'learning_rate':3e-4,\n",
    "        'batch_size':64,\n",
    "        'kernel_initializer':'ones',\n",
    "        'gdn_kernel_size':1,\n",
    "        'learnable_undersampling':False,\n",
    "        'verbose': 0,\n",
    "        'dataset': 'cifar10', # imagenet / imagenette / cifar10 / cifar100,\n",
    "        'validation_split': 0.2,\n",
    "        'seed': 42\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: jorgvt. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/lhome/ext/uv075/uv0752/perceptnet/Notebooks/11_Classification/wandb/run-20230714_100722-l4ui4dlk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jorgvt/PerceptNetClassification/runs/l4ui4dlk\" target=\"_blank\">Baseline</a></strong> to <a href=\"https://wandb.ai/jorgvt/PerceptNetClassification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/jorgvt/PerceptNetClassification\" target=\"_blank\">https://wandb.ai/jorgvt/PerceptNetClassification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/jorgvt/PerceptNetClassification/runs/l4ui4dlk\" target=\"_blank\">https://wandb.ai/jorgvt/PerceptNetClassification/runs/l4ui4dlk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='PerceptNetClassification',\n",
    "            notes=\"\",\n",
    "            tags=[],\n",
    "            name = 'Baseline',\n",
    "            config=config,\n",
    "            job_type=\"training\",\n",
    "            mode=\"online\",\n",
    "            )\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet():\n",
    "    path_data = Path(\"/lustre/ific.uv.es/ml/uv075/Databases/imagenet_images/\")\n",
    "    dst_train = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"training\",\n",
    "                seed=config.seed,\n",
    "                shuffle=True,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    dst_val = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"validation\",\n",
    "                seed=config.seed,\n",
    "                shuffle=False,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    return dst_train, dst_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenette():\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    dst_train, info = tfds.load(\"imagenette/320px-v2\", split=f\"train[:{config.validation_split*100:.0f}%]\", with_info=True, shuffle_files=True)\n",
    "    dst_val = tfds.load(\"imagenette/320px-v2\", split=f\"train[{config.validation_split*100:.0f}%:]\", with_info=False, shuffle_files=False)\n",
    "    def prepare_tfds(item):\n",
    "        x, y = item[\"image\"], item[\"label\"]\n",
    "        x = tf.image.resize_with_crop_or_pad(x, 256, 256)\n",
    "        return x, y\n",
    "    dst_train = dst_train.map(prepare_tfds)\n",
    "    dst_val = dst_val.map(prepare_tfds)\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size), info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10():\n",
    "    from tensorflow.keras.datasets import cifar10\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config.validation_split, random_state=config.seed)\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100():\n",
    "    from tensorflow.keras.datasets import cifar100\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config.validation_split, random_state=config.seed)\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cifar10 with 10 classes.\n"
     ]
    }
   ],
   "source": [
    "if config.dataset == \"imagenet\":\n",
    "    dst_train, dst_val = load_imagenet()\n",
    "    N_CLASSES = len(dst_train.class_names)\n",
    "elif config.dataset == \"cifar10\":\n",
    "    dst_train, dst_val = load_cifar10()\n",
    "    N_CLASSES = 10\n",
    "elif config.dataset == \"cifar100\":\n",
    "    dst_train, dst_val = load_cifar100()\n",
    "    N_CLASSES = 100\n",
    "elif config.dataset == \"imagenette\":\n",
    "    dst_train, dst_val, N_CLASSES = load_imagenette()\n",
    "else:\n",
    "    raise ValueError(\"Dataset parameter not allowed.\")\n",
    "print(f\"Training on {config.dataset} with {N_CLASSES} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dst_train))\n",
    "input_shape = x[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'AttributeError'>",
     "evalue": "'TensorShape' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39msummary[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN_CLASSES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m N_CLASSES\n\u001b[0;32m----> 2\u001b[0m wandb\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39msummary[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput_Shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m input_shape\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_summary.py:50\u001b[0m, in \u001b[0;36mSummaryDict.__setitem__\u001b[0;34m(self, key, val)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, val):\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_summary.py:72\u001b[0m, in \u001b[0;36mSummaryDict.update\u001b[0;34m(self, d)\u001b[0m\n\u001b[1;32m     69\u001b[0m     item\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m     70\u001b[0m     record\u001b[38;5;241m.\u001b[39mupdate\u001b[38;5;241m.\u001b[39mappend(item)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_summary.py:127\u001b[0m, in \u001b[0;36mSummary._update\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: SummaryRecord):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_callback:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:1295\u001b[0m, in \u001b[0;36mRun._summary_update_callback\u001b[0;34m(self, summary_record)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_summary_update_callback\u001b[39m(\u001b[38;5;28mself\u001b[39m, summary_record: SummaryRecord) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39minterface:\n\u001b[0;32m-> 1295\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_record\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/interface/interface.py:332\u001b[0m, in \u001b[0;36mInterfaceBase.publish_summary\u001b[0;34m(self, summary_record)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_summary\u001b[39m(\u001b[38;5;28mself\u001b[39m, summary_record: sr\u001b[38;5;241m.\u001b[39mSummaryRecord) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     pb_summary_record \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_summary(pb_summary_record)\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/interface/interface.py:310\u001b[0m, in \u001b[0;36mInterfaceBase._make_summary\u001b[0;34m(self, summary_record)\u001b[0m\n\u001b[1;32m    307\u001b[0m     pb_summary_item\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mkey[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    309\u001b[0m path_from_root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(item\u001b[38;5;241m.\u001b[39mkey)\n\u001b[0;32m--> 310\u001b[0m json_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_summary_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_from_root\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m json_value, _ \u001b[38;5;241m=\u001b[39m json_friendly(json_value)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    313\u001b[0m pb_summary_item\u001b[38;5;241m.\u001b[39mvalue_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(\n\u001b[1;32m    314\u001b[0m     json_value,\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39mWandBJSONEncoderOld,\n\u001b[1;32m    316\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/interface/interface.py:282\u001b[0m, in \u001b[0;36mInterfaceBase._summary_encode\u001b[0;34m(self, value, path_from_root)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_value\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     friendly_value, converted \u001b[38;5;241m=\u001b[39m \u001b[43mjson_friendly\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_from_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msummary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     json_value, compressed \u001b[38;5;241m=\u001b[39m maybe_compress_summary(\n\u001b[1;32m    286\u001b[0m         friendly_value, get_h5_typename(value)\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compressed:\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;66;03m# TODO(jhr): impleement me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/util.py:717\u001b[0m, in \u001b[0;36mjson_friendly\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_tf_tensor_typename(typename):\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorShape' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "wandb.run.summary[\"N_CLASSES\"] = N_CLASSES\n",
    "wandb.run.summary[\"Input_Shape\"] = input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_tid2013 = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/TID/TID2013\", exclude_imgs=[25]).dataset.batch(config.batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train = dst_train.map(lambda x,y: (normalization_layer(x), y))\n",
    "dst_val = dst_val.map(lambda x,y: (normalization_layer(x), y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "dst_train = dst_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "dst_val = dst_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PerceptNetExpGDNGaussian(kernel_initializer=config.kernel_initializer, gdn_kernel_size=config.gdn_kernel_size)\n",
    "# model = PerceptNetExpGaborLast(kernel_initializer=config.kernel_initializer, gdn_kernel_size=config.gdn_kernel_size)\n",
    "feature_extractor = PerceptNet(kernel_initializer=config.kernel_initializer, gdn_kernel_size=config.gdn_kernel_size, learnable_undersampling=config.learnable_undersampling)\n",
    "model = tf.keras.Sequential([\n",
    "    feature_extractor,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(N_CLASSES, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=config.learning_rate),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log the number of trainable weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset == \"imagenet\" or config.dataset == \"imagenette\":\n",
    "    model.build((None,256,256,3))\n",
    "elif config.dataset == \"cifar10\" or config.dataset == \"cifar100\":\n",
    "    model.build((None,32,32,3))\n",
    "else: #Â If it isn't a known dataset, just call the model on a batch of data to build the weights.\n",
    "    pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable: 37658 | Vars: 37666\n"
     ]
    }
   ],
   "source": [
    "num_trainable_vars = np.sum([np.prod(v.shape) for v in model.trainable_variables])\n",
    "wandb.run.summary[\"trainable_parameters\"] = num_trainable_vars\n",
    "num_vars = np.sum([np.prod(v.shape) for v in model.weights])\n",
    "wandb.run.summary[\"parameters\"] = int(num_vars)\n",
    "print(f\"Trainable: {num_trainable_vars} | Vars: {num_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING When using `save_best_only`, ensure that the `filepath` argument contains formatting placeholders like `{epoch:02d}` or `{batch:02d}`. This ensures correct interpretation of the logged artifacts.\n",
      "wandb: WARNING A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dst_train, \n",
    "                    epochs=config.epochs, \n",
    "                    validation_data=dst_val,\n",
    "                    callbacks=[EvaluatePerceptuality(dst=dst_tid2013, model=feature_extractor, name=\"TID2013\"),\n",
    "                               WandbMetricsLogger(log_freq=\"epoch\"),\n",
    "                               WandbModelCheckpoint(filepath=os.path.join(wandb.run.dir, \"model-best\"),\n",
    "                                                    monitor=\"val_loss\",\n",
    "                                                    save_best_only=True,\n",
    "                                                    save_weights_only=True,\n",
    "                                                    mode=\"min\")\n",
    "                               ],\n",
    "                    verbose=config.verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "<class 'TypeError'>",
     "evalue": "get_range() missing 1 required positional argument: 'session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:3671\u001b[0m, in \u001b[0;36mfinish\u001b[0;34m(exit_code, quiet)\u001b[0m\n\u001b[1;32m   3661\u001b[0m \u001b[38;5;124;03m\"\"\"Marks a run as finished, and finishes uploading all data.\u001b[39;00m\n\u001b[1;32m   3662\u001b[0m \n\u001b[1;32m   3663\u001b[0m \u001b[38;5;124;03mThis is used when creating multiple runs in the same process.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3668\u001b[0m \u001b[38;5;124;03m    quiet: Set to true to minimize log output\u001b[39;00m\n\u001b[1;32m   3669\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mrun:\n\u001b[0;32m-> 3671\u001b[0m     \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexit_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:370\u001b[0m, in \u001b[0;36m_run_decorator._noop.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mtermwarn(message, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mDummy()\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:333\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:1835\u001b[0m, in \u001b[0;36mRun.finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[38;5;129m@_run_decorator\u001b[39m\u001b[38;5;241m.\u001b[39m_noop\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;129m@_run_decorator\u001b[39m\u001b[38;5;241m.\u001b[39m_attach\n\u001b[1;32m   1823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinish\u001b[39m(\n\u001b[1;32m   1824\u001b[0m     \u001b[38;5;28mself\u001b[39m, exit_code: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, quiet: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1825\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1826\u001b[0m     \u001b[38;5;124;03m\"\"\"Marks a run as finished, and finishes uploading all data.\u001b[39;00m\n\u001b[1;32m   1827\u001b[0m \n\u001b[1;32m   1828\u001b[0m \u001b[38;5;124;03m    This is used when creating multiple runs in the same process. We automatically\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m \u001b[38;5;124;03m        quiet: Set to true to minimize log output\u001b[39;00m\n\u001b[1;32m   1834\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py:1848\u001b[0m, in \u001b[0;36mRun._finish\u001b[0;34m(self, exit_code, quiet)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown_hooks:\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m==\u001b[39m TeardownStage\u001b[38;5;241m.\u001b[39mEARLY:\n\u001b[0;32m-> 1848\u001b[0m         \u001b[43mhook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_atexit_cleanup(exit_code\u001b[38;5;241m=\u001b[39mexit_code)\n\u001b[1;32m   1851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl\u001b[38;5;241m.\u001b[39m_global_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:406\u001b[0m, in \u001b[0;36m_WandbInit._jupyter_teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m\"\"\"Teardown hooks and display saving, called with wandb.finish.\"\"\"\u001b[39;00m\n\u001b[1;32m    405\u001b[0m ipython \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook\u001b[38;5;241m.\u001b[39mshell\n\u001b[0;32m--> 406\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotebook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook\u001b[38;5;241m.\u001b[39msave_ipynb():\n\u001b[1;32m    408\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mlog_code(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.8/site-packages/wandb/jupyter.py:447\u001b[0m, in \u001b[0;36mNotebook.save_history\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    446\u001b[0m cells \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 447\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(hist) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39msave_code:\n\u001b[1;32m    449\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot saving jupyter history\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_range() missing 1 required positional argument: 'session'"
     ]
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da5141a55de43f9a5c077a362efe5e2ae0cb795b0fc8676e62dbd4f64287ec27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
