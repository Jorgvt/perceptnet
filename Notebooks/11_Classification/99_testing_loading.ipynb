{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from fastcore.xtras import Path\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "import scipy.stats as stats\n",
    "\n",
    "from perceptnet.networks import *\n",
    "from iqadatasets.datasets.tid2013 import TID2013\n",
    "\n",
    "from flayers.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluatePerceptuality(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Evaluates a perceptual model that is part of another model.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 dst, # Dataset to be evaluated.\n",
    "                 model, # Model to be evaluated.\n",
    "                 name=None, # Name to prepend to the logged metrics.\n",
    "                 ):\n",
    "        self.dst = dst\n",
    "        self.eval_model = model\n",
    "        self.name = \"\" if name is None else name+\"_\"\n",
    "        \n",
    "    def on_epoch_end(self,\n",
    "                     epoch, \n",
    "                     logs=None):\n",
    "        distances, moses = [], []\n",
    "        for i, data in enumerate(self.dst):\n",
    "            img, dist_img, mos = data\n",
    "            features_original = self.eval_model(img, training=False)\n",
    "            features_distorted = self.eval_model(dist_img, training=False)\n",
    "            l2 = (features_original-features_distorted)**2\n",
    "            l2 = tf.reduce_sum(l2, axis=[1,2,3])\n",
    "            l2 = tf.sqrt(l2)\n",
    "            distances.extend(l2)\n",
    "            moses.extend(mos)\n",
    "        pearson = stats.pearsonr(distances, moses)[0]\n",
    "        spearman = stats.spearmanr(distances, moses)[0]\n",
    "        wandb.log({f\"{self.name}Pearson\": pearson,\n",
    "                   f\"{self.name}Spearman\": spearman}, commit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id = \"7cakiknt\" # imagenet\n",
    "# id = \"psmk04za\" # cifar10\n",
    "# id = \"0cnhyn1v\" # cifar100\n",
    "id = \"iupl77hz\" # imagenette\n",
    "# MORE_EPOCHS = 500\n",
    "MORE_EPOCHS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjorgvt\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/lhome/ext/uv075/uv0752/perceptnet/Notebooks/11_Classification/wandb/run-20230714_095958-iupl77hz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/jorgvt/PerceptNetClassification/runs/iupl77hz\" target=\"_blank\">Baseline</a></strong> to <a href=\"https://wandb.ai/jorgvt/PerceptNetClassification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/jorgvt/PerceptNetClassification\" target=\"_blank\">https://wandb.ai/jorgvt/PerceptNetClassification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/jorgvt/PerceptNetClassification/runs/iupl77hz\" target=\"_blank\">https://wandb.ai/jorgvt/PerceptNetClassification/runs/iupl77hz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'seed': 42, 'epochs': 1500, 'dataset': 'imagenette', 'verbose': 0, 'batch_size': 64, 'learning_rate': 0.0003, 'gdn_kernel_size': 1, 'validation_split': 0.2, 'kernel_initializer': 'ones', 'learnable_undersampling': False}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='PerceptNetClassification',\n",
    "            id=id,\n",
    "            mode=\"online\",\n",
    "            resume=\"allow\",\n",
    "            )\n",
    "config = wandb.config\n",
    "# config.epochs += MORE_EPOCHS\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(f\"jorgvt/PerceptNetClassification/{id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run.history()\n",
    "df.sort_values(by=\"epoch/epoch\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n",
      "0.6018000245094299\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df[\"epoch/epoch\"], df[\"epoch/val_accuracy\"])\n",
    "print(df[\"epoch/val_accuracy\"].argmax())\n",
    "print(df[\"epoch/val_accuracy\"].max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run_psmk04za_model:v0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(run.logged_artifacts())[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "artifact = api.artifact(f'PerceptNetClassification/run_{id}_model:v{df[\"epoch/val_accuracy\"].argmax()}')\n",
    "path = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./artifacts/run_psmk04za_model:v263'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'epochs': 1000,\n",
       " 'dataset': 'cifar10',\n",
       " 'verbose': 0,\n",
       " 'batch_size': 64,\n",
       " 'learning_rate': 0.0003,\n",
       " 'gdn_kernel_size': 1,\n",
       " 'validation_split': 0.2,\n",
       " 'kernel_initializer': 'ones',\n",
       " 'learnable_undersampling': False}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = run.config\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet():\n",
    "    path_data = Path(\"/lustre/ific.uv.es/ml/uv075/Databases/imagenet_images/\")\n",
    "    dst_train = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"training\",\n",
    "                seed=config.seed,\n",
    "                shuffle=True,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    dst_val = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"validation\",\n",
    "                seed=config.seed,\n",
    "                shuffle=False,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    return dst_train, dst_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenette():\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    dst_train, info = tfds.load(\"imagenette/320px-v2\", split=f\"train[:{config.validation_split*100:.0f}%]\", with_info=True, shuffle_files=True)\n",
    "    dst_val = tfds.load(\"imagenette/320px-v2\", split=f\"train[{config.validation_split*100:.0f}%:]\", with_info=False, shuffle_files=False)\n",
    "    def prepare_tfds(item):\n",
    "        x, y = item[\"image\"], item[\"label\"]\n",
    "        x = tf.image.resize_with_crop_or_pad(x, 256, 256)\n",
    "        return x, y\n",
    "    dst_train = dst_train.map(prepare_tfds)\n",
    "    dst_val = dst_val.map(prepare_tfds)\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size), info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10():\n",
    "    from tensorflow.keras.datasets import cifar10\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config[\"validation_split\"], random_state=config[\"seed\"])\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config[\"batch_size\"]), dst_val.batch(config[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100():\n",
    "    from tensorflow.keras.datasets import cifar100\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config.validation_split, random_state=config.seed)\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on imagenette with 10 classes.\n"
     ]
    }
   ],
   "source": [
    "if config.dataset == \"imagenet\":\n",
    "    dst_train, dst_val = load_imagenet()\n",
    "    N_CLASSES = len(dst_train.class_names)\n",
    "elif config.dataset == \"cifar10\":\n",
    "    dst_train, dst_val = load_cifar10()\n",
    "    N_CLASSES = 10\n",
    "elif config.dataset == \"cifar100\":\n",
    "    dst_train, dst_val = load_cifar100()\n",
    "    N_CLASSES = 100\n",
    "elif config.dataset == \"imagenette\":\n",
    "    dst_train, dst_val, N_CLASSES = load_imagenette()\n",
    "else:\n",
    "    raise ValueError(\"Dataset parameter not allowed.\")\n",
    "print(f\"Training on {config.dataset} with {N_CLASSES} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([256, 256, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dst_train))\n",
    "input_shape = x[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_tid2013 = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/TID/TID2013\", exclude_imgs=[25]).dataset.batch(config.batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train = dst_train.map(lambda x,y: (normalization_layer(x), y))\n",
    "dst_val = dst_val.map(lambda x,y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([256, 256, 3]),\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dst_train))\n",
    "input_shape = x[0].shape\n",
    "input_shape, tf.reduce_max(x), tf.reduce_min(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "dst_train = dst_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "dst_val = dst_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = PerceptNet(kernel_initializer=config[\"kernel_initializer\"], gdn_kernel_size=config[\"gdn_kernel_size\"], learnable_undersampling=config[\"learnable_undersampling\"])\n",
    "model = tf.keras.Sequential([\n",
    "    feature_extractor,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(N_CLASSES, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=config[\"learning_rate\"]),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset == \"imagenet\" or config.dataset == \"imagenette\":\n",
    "    model.build((None,256,256,3))\n",
    "elif config.dataset == \"cifar10\" or config.dataset == \"cifar100\":\n",
    "    model.build((None,32,32,3))\n",
    "else: # If it isn't a known dataset, just call the model on a batch of data to build the weights.\n",
    "    pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "best_model = wandb.run.use_artifact(f\"run_{wandb.run.id}_model:latest\", type=\"model\")\n",
    "best_model_dir = best_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'percept_net_1/gdn_4/kernel:0' shape=(1, 1, 1, 3) dtype=float32, numpy=array([[[[1., 1., 1.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f52444b4fa0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(f\"{best_model_dir}/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'percept_net_1/gdn_4/kernel:0' shape=(1, 1, 1, 3) dtype=float32, numpy=array([[[[0.33880746, 0.9243364 , 0.47865188]]]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 6s 186ms/step - loss: 0.7042 - accuracy: 0.7730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7041791677474976, 0.7729672789573669]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dst_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499, 499)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = wandb.run.summary._as_dict()\n",
    "summary[\"epoch/epoch\"], summary[\"_step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 12:48:28.836862: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2023-03-05 12:48:31.860608: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dst_train, \n",
    "                    epochs=config.epochs, \n",
    "                    initial_epoch=summary[\"epoch/epoch\"]+1,\n",
    "                    validation_data=dst_val,\n",
    "                    callbacks=[EvaluatePerceptuality(dst=dst_tid2013, model=feature_extractor, name=\"TID2013\"),\n",
    "                               WandbMetricsLogger(log_freq=\"epoch\", initial_global_step=summary[\"_step\"]+1),\n",
    "                               WandbModelCheckpoint(filepath=\"model-best\",\n",
    "                                                    monitor=\"val_loss\",\n",
    "                                                    save_best_only=True,\n",
    "                                                    save_weights_only=True,\n",
    "                                                    mode=\"min\")\n",
    "                               ],\n",
    "                    verbose=config.verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>N_CLASSES</td><td>10</td></tr><tr><td>TID2013_Pearson</td><td>-0.55598</td></tr><tr><td>TID2013_Spearman</td><td>-0.59613</td></tr><tr><td>epoch/accuracy</td><td>0.78775</td></tr><tr><td>epoch/epoch</td><td>1499</td></tr><tr><td>epoch/learning_rate</td><td>0.0003</td></tr><tr><td>epoch/loss</td><td>0.66256</td></tr><tr><td>epoch/val_accuracy</td><td>0.6404</td></tr><tr><td>epoch/val_loss</td><td>1.17904</td></tr><tr><td>parameters</td><td>37666</td></tr><tr><td>trainable_parameters</td><td>37658</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Baseline</strong> at: <a href=\"https://wandb.ai/jorgvt/PerceptNetClassification/runs/iupl77hz\" target=\"_blank\">https://wandb.ai/jorgvt/PerceptNetClassification/runs/iupl77hz</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_095958-iupl77hz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da5141a55de43f9a5c077a362efe5e2ae0cb795b0fc8676e62dbd4f64287ec27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
