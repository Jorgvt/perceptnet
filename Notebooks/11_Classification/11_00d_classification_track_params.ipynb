{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os; os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jax.config import config\n",
    "# config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 11:58:09.781270: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-26 11:58:11.918338: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 11:58:20.336644: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:1: failed initializing StreamExecutor for CUDA device ordinal 1: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "2023-09-26 11:58:20.337522: W external/xla/xla/service/platform_util.cc:198] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: INTERNAL: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_DEVICE_UNAVAILABLE: CUDA-capable device(s) is/are busy or unavailable\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from typing import Any, Callable, Sequence, Union\n",
    "import numpy as np\n",
    "from fastcore.xtras import Path\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import jax\n",
    "from jax import lax, random, numpy as jnp\n",
    "from flax.core import freeze, unfreeze, FrozenDict\n",
    "from flax import linen as nn\n",
    "from flax import struct\n",
    "from flax.training import train_state\n",
    "from flax.training import orbax_utils\n",
    "\n",
    "import optax\n",
    "import orbax.checkpoint\n",
    "\n",
    "from clu import metrics\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "from einops import reduce, rearrange\n",
    "import wandb\n",
    "from iqadatasets.datasets import *\n",
    "from fxlayers.layers import *\n",
    "from fxlayers.initializers import mean\n",
    "from JaxPlayground.utils.constraints import *\n",
    "from JaxPlayground.utils.wandb import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'epochs':500,\n",
    "        'learning_rate':3e-4,\n",
    "        'batch_size':64,\n",
    "        'kernel_initializer':'ones',\n",
    "        'gdn_kernel_size':1,\n",
    "        'learnable_undersampling':False,\n",
    "        'verbose': 0,\n",
    "        'dataset': 'cifar10', # imagenet / imagenette / cifar10 / cifar100,\n",
    "        'validation_split': 0.2,\n",
    "        'seed': 42,\n",
    "        'GAP': False,\n",
    "        'use_bias': True,\n",
    "        \"dropout_rate\": 0.0,\n",
    "        \"l1\": False,\n",
    "        \"LAMBDA\": 0.0005,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: jorgvt. Use `wandb login --relogin` to force relogin\n",
      "wandb: wandb version 0.15.11 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "wandb: Tracking run with wandb version 0.15.1\n",
      "wandb: Run data is saved locally in /lhome/ext/uv075/uv0752/perceptnet/Notebooks/11_Classification/wandb/run-20230926_121005-nov7tin5\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run Baseline-Flatten\n",
      "wandb:  View project at https://wandb.ai/jorgvt/PerceptNetClassification_JaX\n",
      "wandb:  View run at https://wandb.ai/jorgvt/PerceptNetClassification_JaX/runs/nov7tin5\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project='PerceptNetClassification_JaX',\n",
    "            notes=\"\",\n",
    "            tags=[],\n",
    "            name = 'Baseline-Flatten',\n",
    "            config=config,\n",
    "            job_type=\"training\",\n",
    "            mode=\"online\",\n",
    "            )\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet():\n",
    "    path_data = Path(\"/lustre/ific.uv.es/ml/uv075/Databases/imagenet_images/\")\n",
    "    dst_train = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"training\",\n",
    "                seed=config.seed,\n",
    "                shuffle=True,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    dst_val = tf.keras.utils.image_dataset_from_directory(\n",
    "                path_data,\n",
    "                validation_split=config.validation_split,\n",
    "                subset=\"validation\",\n",
    "                seed=config.seed,\n",
    "                shuffle=False,\n",
    "                # image_size=(img_height, img_width),\n",
    "                batch_size=config.batch_size)\n",
    "    return dst_train, dst_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenette():\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    dst_train, info = tfds.load(\"imagenette/320px-v2\", split=f\"train[:{(1-config.validation_split)*100:.0f}%]\", with_info=True, shuffle_files=True)\n",
    "    dst_val = tfds.load(\"imagenette/320px-v2\", split=f\"train[{(1-config.validation_split)*100:.0f}%:]\", with_info=False, shuffle_files=False)\n",
    "    def prepare_tfds(item):\n",
    "        x, y = item[\"image\"], item[\"label\"]\n",
    "        x = tf.image.resize_with_crop_or_pad(x, 256, 256)\n",
    "        return x, y\n",
    "    dst_train = dst_train.map(prepare_tfds)\n",
    "    dst_val = dst_val.map(prepare_tfds)\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size), info.features[\"label\"].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10():\n",
    "    from tensorflow.keras.datasets import cifar10\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config.validation_split, random_state=config.seed)\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar100():\n",
    "    from tensorflow.keras.datasets import cifar100\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=config.validation_split, random_state=config.seed)\n",
    "    dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "    dst_val = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "\n",
    "    return dst_train.batch(config.batch_size), dst_val.batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cifar10 with 10 classes.\n"
     ]
    }
   ],
   "source": [
    "if config.dataset == \"imagenet\":\n",
    "    dst_train, dst_val = load_imagenet()\n",
    "    N_CLASSES = len(dst_train.class_names)\n",
    "elif config.dataset == \"cifar10\":\n",
    "    dst_train, dst_val = load_cifar10()\n",
    "    N_CLASSES = 10\n",
    "elif config.dataset == \"cifar100\":\n",
    "    dst_train, dst_val = load_cifar100()\n",
    "    N_CLASSES = 100\n",
    "elif config.dataset == \"imagenette\":\n",
    "    dst_train, dst_val, N_CLASSES = load_imagenette()\n",
    "else:\n",
    "    raise ValueError(\"Dataset parameter not allowed.\")\n",
    "print(f\"Training on {config.dataset} with {N_CLASSES} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 3])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dst_train))\n",
    "input_shape = x[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.summary[\"N_CLASSES\"] = N_CLASSES\n",
    "wandb.run.summary[\"Input_Shape\"] = tuple(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_tid2013 = TID2013(\"/lustre/ific.uv.es/ml/uv075/Databases/IQA/TID/TID2013\").dataset\\\n",
    "                                                                              .batch(config.batch_size)\\\n",
    "                                                                              .prefetch(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(y.shape) != 1:\n",
    "    dst_train = dst_train.map(lambda x,y: (tf.cast(x, tf.float32)/255.0, y[:,0]))\n",
    "    dst_val = dst_val.map(lambda x,y: (tf.cast(x, tf.float32)/255.0, y[:,0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "dst_train_rdy = dst_train.cache().prefetch(buffer_size=1)\n",
    "dst_val_rdy = dst_val.cache().prefetch(buffer_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDN(nn.Module):\n",
    "    \"\"\"Generalized Divisive Normalization.\"\"\"\n",
    "    kernel_size: Union[int, Sequence[int]]\n",
    "    strides: int = 1\n",
    "    padding: str = \"SAME\"\n",
    "    apply_independently: bool = False\n",
    "    # kernel_init: Callable = nn.initializers.lecun_normal()\n",
    "    kernel_init: Callable = mean()\n",
    "    bias_init: Callable = nn.initializers.ones_init()\n",
    "    alpha: float = 2.\n",
    "    epsilon: float = 1/2 # Exponential of the denominator\n",
    "    eps: float = 1e-6 # Numerical stability in the denominator\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 ):\n",
    "        denom = nn.Conv(features=inputs.shape[-1], # Same output channels as input\n",
    "                        kernel_size=self.kernel_size if isinstance(self.kernel_size, Sequence) else [self.kernel_size]*2, \n",
    "                        strides=self.strides, \n",
    "                        padding=self.padding,\n",
    "                        feature_group_count=inputs.shape[-1] if self.apply_independently else 1,\n",
    "                        kernel_init=self.kernel_init, \n",
    "                        bias_init=self.bias_init)(inputs**self.alpha)\n",
    "        return inputs / (jnp.clip(denom, a_min=1e-5)**self.epsilon + self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNet(nn.Module):\n",
    "    \"\"\"IQA model inspired by the visual system.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=True)(inputs)\n",
    "        outputs = nn.Conv(features=3, kernel_size=(1,1), strides=1, padding=\"SAME\", use_bias=config.use_bias)(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        outputs = nn.Conv(features=6, kernel_size=(5,5), strides=1, padding=\"SAME\", use_bias=config.use_bias)(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        outputs = nn.Conv(features=128, kernel_size=(5,5), strides=1, padding=\"SAME\", use_bias=config.use_bias)(outputs)\n",
    "        outputs = GDN(kernel_size=1, strides=1, padding=\"SAME\", apply_independently=False)(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    N_CLASSES: int\n",
    "    GAP: bool = False\n",
    "    dropout_rate: float = 0.5\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 train=False,\n",
    "                 ):\n",
    "        outputs = reduce(inputs, \"b h w c -> b c\", reduction=\"mean\") if self.GAP else rearrange(inputs, \"b h w c -> b (h w c)\")\n",
    "        outputs = nn.Dropout(rate=self.dropout_rate, deterministic=not train)(outputs) if self.dropout_rate > 0.0 else outputs\n",
    "        outputs = nn.Dense(self.N_CLASSES)(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptNetClassifier(nn.Module):\n",
    "    \"\"\"Classifier with a PerceptNet backbone.\"\"\"\n",
    "\n",
    "    def setup(self):\n",
    "        self.perceptnet = PerceptNet()\n",
    "        self.cls = Classifier(N_CLASSES=N_CLASSES, GAP=config.GAP, dropout_rate=config.dropout_rate)\n",
    "\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 train=False,\n",
    "                 ):\n",
    "        outputs = self.perceptnet(inputs, train=train)\n",
    "        outputs = self.cls(outputs, train=train)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    \"\"\"Collection of metrics to be tracked during training.\"\"\"\n",
    "    accuracy: metrics.Accuracy\n",
    "    loss: metrics.Average.from_output(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "    state: FrozenDict\n",
    "    key: jax.Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, key, tx, input_shape):\n",
    "    \"\"\"Creates the initial `TrainState`.\"\"\"\n",
    "    variables = module.init(key, jnp.ones(input_shape), train=False)\n",
    "    _, dropout_key = random.split(random.PRNGKey(42))\n",
    "    state, params = variables.pop('params')\n",
    "    return TrainState.create(\n",
    "        apply_fn=module.apply,\n",
    "        params=params,\n",
    "        state=state,\n",
    "        key=dropout_key,\n",
    "        tx=tx,\n",
    "        metrics=Metrics.empty()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(PerceptNetClassifier(), random.PRNGKey(config.seed), optax.adam(config.learning_rate), input_shape=(1,*(x.shape[1:])))\n",
    "state = state.replace(params=clip_layer(state.params, \"GDN\", a_min=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log the number of trainable weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118298"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_count = sum(x.size for x in jax.tree_util.tree_leaves(state.params))\n",
    "param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.summary[\"trainable_parameters\"] = param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()\n",
    "save_args = orbax_utils.save_args_from_target(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    dropout_train_key = random.fold_in(key=state.key, data=state.step)\n",
    "    img, label = batch\n",
    "    def loss_fn(params):\n",
    "        ## Forward pass through the model\n",
    "        img_pred = state.apply_fn({\"params\": params, **state.state}, img, train=True, rngs={\"dropout\": dropout_train_key})\n",
    "\n",
    "        ## Calculate crossentropy\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(img_pred, label).mean()\n",
    "\n",
    "        ## Add L1 regularization\n",
    "        if config.l1: loss += config.LAMBDA*jnp.abs(state.params[\"cls\"][\"Dense_0\"][\"kernel\"]).mean()\n",
    "        \n",
    "        return loss, img_pred\n",
    "    \n",
    "    (loss, dist_diff), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics_updates = state.metrics.single_from_model_output(loss=loss, logits=dist_diff, labels=jnp.round(label).astype(int))\n",
    "    metrics = state.metrics.merge(metrics_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def val_step(state, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    img, label = batch\n",
    "    def loss_fn(params):\n",
    "        ## Forward pass through the model\n",
    "        img_pred = state.apply_fn({\"params\": params, **state.state}, img, train=False)\n",
    "\n",
    "        ## Calculate crossentropy\n",
    "        return optax.softmax_cross_entropy_with_integer_labels(img_pred, label).mean(), img_pred\n",
    "    \n",
    "    loss, dist_diff = loss_fn(state.params)\n",
    "    metrics_updates = state.metrics.single_from_model_output(loss=loss, logits=dist_diff, labels=jnp.round(label).astype(int))\n",
    "    metrics = state.metrics.merge(metrics_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(state, img):\n",
    "    img_pred = PerceptNet().apply({\"params\": state.params[\"perceptnet\"]}, img)\n",
    "    return img_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(a, b): return jnp.sqrt(jnp.sum((a-b)**2, axis=(1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def obtain_distances(state, batch):\n",
    "    ref, dist, mos = batch\n",
    "    pred_ref = forward_pass(state, ref)\n",
    "    pred_dist = forward_pass(state, dist)\n",
    "    distance = rmse(pred_ref, pred_dist)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_correlation(state, dst):\n",
    "    distances, moses = [], []\n",
    "    for batch in dst:\n",
    "        distance = obtain_distances(state, batch)\n",
    "        distances.extend(distance)\n",
    "        moses.extend(batch[2])\n",
    "        # break\n",
    "    return stats.pearsonr(distances, moses)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_accuracy\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_accuracy\": [],\n",
    "    \"correlation\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -> [Train] Loss: 1.800 Acc: 0.366 [Val] Loss: 1.642 Acc: 0.430 || Corr: -0.533\n",
      "Epoch 1 -> [Train] Loss: 1.613 Acc: 0.439 [Val] Loss: 1.572 Acc: 0.450 || Corr: -0.539\n",
      "Epoch 2 -> [Train] Loss: 1.547 Acc: 0.461 [Val] Loss: 1.519 Acc: 0.467 || Corr: -0.552\n",
      "Epoch 3 -> [Train] Loss: 1.500 Acc: 0.477 [Val] Loss: 1.487 Acc: 0.474 || Corr: -0.563\n",
      "Epoch 4 -> [Train] Loss: 1.466 Acc: 0.489 [Val] Loss: 1.463 Acc: 0.483 || Corr: -0.571\n",
      "Epoch 5 -> [Train] Loss: 1.440 Acc: 0.499 [Val] Loss: 1.441 Acc: 0.487 || Corr: -0.577\n",
      "Epoch 6 -> [Train] Loss: 1.417 Acc: 0.506 [Val] Loss: 1.421 Acc: 0.495 || Corr: -0.582\n",
      "Epoch 7 -> [Train] Loss: 1.397 Acc: 0.512 [Val] Loss: 1.403 Acc: 0.502 || Corr: -0.586\n",
      "Epoch 8 -> [Train] Loss: 1.378 Acc: 0.517 [Val] Loss: 1.387 Acc: 0.507 || Corr: -0.590\n",
      "Epoch 9 -> [Train] Loss: 1.363 Acc: 0.522 [Val] Loss: 1.374 Acc: 0.512 || Corr: -0.593\n",
      "Epoch 10 -> [Train] Loss: 1.349 Acc: 0.527 [Val] Loss: 1.364 Acc: 0.517 || Corr: -0.596\n",
      "Epoch 11 -> [Train] Loss: 1.337 Acc: 0.530 [Val] Loss: 1.355 Acc: 0.521 || Corr: -0.598\n",
      "Epoch 12 -> [Train] Loss: 1.326 Acc: 0.534 [Val] Loss: 1.347 Acc: 0.524 || Corr: -0.600\n",
      "Epoch 13 -> [Train] Loss: 1.316 Acc: 0.538 [Val] Loss: 1.339 Acc: 0.528 || Corr: -0.601\n",
      "Epoch 14 -> [Train] Loss: 1.306 Acc: 0.541 [Val] Loss: 1.332 Acc: 0.528 || Corr: -0.601\n",
      "Epoch 15 -> [Train] Loss: 1.296 Acc: 0.544 [Val] Loss: 1.325 Acc: 0.530 || Corr: -0.601\n",
      "Epoch 16 -> [Train] Loss: 1.287 Acc: 0.547 [Val] Loss: 1.319 Acc: 0.533 || Corr: -0.600\n",
      "Epoch 17 -> [Train] Loss: 1.278 Acc: 0.550 [Val] Loss: 1.312 Acc: 0.537 || Corr: -0.600\n",
      "Epoch 18 -> [Train] Loss: 1.269 Acc: 0.553 [Val] Loss: 1.305 Acc: 0.537 || Corr: -0.599\n",
      "Epoch 19 -> [Train] Loss: 1.259 Acc: 0.556 [Val] Loss: 1.298 Acc: 0.539 || Corr: -0.599\n",
      "Epoch 20 -> [Train] Loss: 1.249 Acc: 0.559 [Val] Loss: 1.291 Acc: 0.540 || Corr: -0.599\n",
      "Epoch 21 -> [Train] Loss: 1.239 Acc: 0.563 [Val] Loss: 1.283 Acc: 0.542 || Corr: -0.600\n",
      "Epoch 22 -> [Train] Loss: 1.228 Acc: 0.566 [Val] Loss: 1.276 Acc: 0.545 || Corr: -0.601\n",
      "Epoch 23 -> [Train] Loss: 1.217 Acc: 0.569 [Val] Loss: 1.268 Acc: 0.547 || Corr: -0.603\n",
      "Epoch 24 -> [Train] Loss: 1.206 Acc: 0.574 [Val] Loss: 1.260 Acc: 0.550 || Corr: -0.605\n",
      "Epoch 25 -> [Train] Loss: 1.194 Acc: 0.578 [Val] Loss: 1.252 Acc: 0.555 || Corr: -0.608\n",
      "Epoch 26 -> [Train] Loss: 1.183 Acc: 0.581 [Val] Loss: 1.244 Acc: 0.558 || Corr: -0.611\n",
      "Epoch 27 -> [Train] Loss: 1.170 Acc: 0.586 [Val] Loss: 1.236 Acc: 0.561 || Corr: -0.614\n",
      "Epoch 28 -> [Train] Loss: 1.158 Acc: 0.591 [Val] Loss: 1.228 Acc: 0.562 || Corr: -0.618\n",
      "Epoch 29 -> [Train] Loss: 1.146 Acc: 0.595 [Val] Loss: 1.221 Acc: 0.566 || Corr: -0.621\n",
      "Epoch 30 -> [Train] Loss: 1.134 Acc: 0.600 [Val] Loss: 1.214 Acc: 0.569 || Corr: -0.625\n",
      "Epoch 31 -> [Train] Loss: 1.121 Acc: 0.605 [Val] Loss: 1.207 Acc: 0.571 || Corr: -0.629\n",
      "Epoch 32 -> [Train] Loss: 1.109 Acc: 0.609 [Val] Loss: 1.201 Acc: 0.572 || Corr: -0.633\n",
      "Epoch 33 -> [Train] Loss: 1.097 Acc: 0.613 [Val] Loss: 1.195 Acc: 0.573 || Corr: -0.637\n",
      "Epoch 34 -> [Train] Loss: 1.086 Acc: 0.617 [Val] Loss: 1.189 Acc: 0.576 || Corr: -0.641\n",
      "Epoch 35 -> [Train] Loss: 1.074 Acc: 0.622 [Val] Loss: 1.184 Acc: 0.579 || Corr: -0.644\n",
      "Epoch 36 -> [Train] Loss: 1.062 Acc: 0.628 [Val] Loss: 1.180 Acc: 0.582 || Corr: -0.648\n",
      "Epoch 37 -> [Train] Loss: 1.050 Acc: 0.633 [Val] Loss: 1.175 Acc: 0.584 || Corr: -0.652\n",
      "Epoch 38 -> [Train] Loss: 1.038 Acc: 0.637 [Val] Loss: 1.171 Acc: 0.585 || Corr: -0.656\n",
      "Epoch 39 -> [Train] Loss: 1.026 Acc: 0.642 [Val] Loss: 1.168 Acc: 0.587 || Corr: -0.659\n",
      "Epoch 40 -> [Train] Loss: 1.014 Acc: 0.646 [Val] Loss: 1.165 Acc: 0.588 || Corr: -0.663\n",
      "Epoch 41 -> [Train] Loss: 1.001 Acc: 0.651 [Val] Loss: 1.163 Acc: 0.589 || Corr: -0.666\n",
      "Epoch 42 -> [Train] Loss: 0.989 Acc: 0.655 [Val] Loss: 1.161 Acc: 0.590 || Corr: -0.669\n",
      "Epoch 43 -> [Train] Loss: 0.977 Acc: 0.659 [Val] Loss: 1.160 Acc: 0.592 || Corr: -0.672\n",
      "Epoch 44 -> [Train] Loss: 0.964 Acc: 0.663 [Val] Loss: 1.159 Acc: 0.592 || Corr: -0.674\n",
      "Epoch 45 -> [Train] Loss: 0.951 Acc: 0.667 [Val] Loss: 1.159 Acc: 0.593 || Corr: -0.677\n",
      "Epoch 46 -> [Train] Loss: 0.939 Acc: 0.672 [Val] Loss: 1.160 Acc: 0.594 || Corr: -0.679\n",
      "Epoch 47 -> [Train] Loss: 0.926 Acc: 0.676 [Val] Loss: 1.161 Acc: 0.595 || Corr: -0.680\n",
      "Epoch 48 -> [Train] Loss: 0.913 Acc: 0.681 [Val] Loss: 1.163 Acc: 0.595 || Corr: -0.682\n",
      "Epoch 49 -> [Train] Loss: 0.901 Acc: 0.686 [Val] Loss: 1.165 Acc: 0.596 || Corr: -0.683\n",
      "Epoch 50 -> [Train] Loss: 0.888 Acc: 0.691 [Val] Loss: 1.168 Acc: 0.595 || Corr: -0.684\n",
      "Epoch 51 -> [Train] Loss: 0.875 Acc: 0.696 [Val] Loss: 1.172 Acc: 0.595 || Corr: -0.686\n",
      "Epoch 52 -> [Train] Loss: 0.862 Acc: 0.700 [Val] Loss: 1.176 Acc: 0.596 || Corr: -0.687\n",
      "Epoch 53 -> [Train] Loss: 0.849 Acc: 0.705 [Val] Loss: 1.181 Acc: 0.594 || Corr: -0.687\n",
      "Epoch 54 -> [Train] Loss: 0.836 Acc: 0.709 [Val] Loss: 1.186 Acc: 0.593 || Corr: -0.688\n",
      "Epoch 55 -> [Train] Loss: 0.823 Acc: 0.714 [Val] Loss: 1.192 Acc: 0.594 || Corr: -0.689\n",
      "Epoch 56 -> [Train] Loss: 0.810 Acc: 0.719 [Val] Loss: 1.198 Acc: 0.592 || Corr: -0.690\n",
      "Epoch 57 -> [Train] Loss: 0.797 Acc: 0.724 [Val] Loss: 1.205 Acc: 0.590 || Corr: -0.690\n",
      "Epoch 58 -> [Train] Loss: 0.784 Acc: 0.728 [Val] Loss: 1.213 Acc: 0.590 || Corr: -0.691\n",
      "Epoch 59 -> [Train] Loss: 0.771 Acc: 0.732 [Val] Loss: 1.221 Acc: 0.590 || Corr: -0.691\n",
      "Epoch 60 -> [Train] Loss: 0.758 Acc: 0.738 [Val] Loss: 1.230 Acc: 0.589 || Corr: -0.692\n",
      "Epoch 61 -> [Train] Loss: 0.745 Acc: 0.743 [Val] Loss: 1.240 Acc: 0.586 || Corr: -0.692\n",
      "Epoch 62 -> [Train] Loss: 0.732 Acc: 0.747 [Val] Loss: 1.250 Acc: 0.584 || Corr: -0.692\n",
      "Epoch 63 -> [Train] Loss: 0.719 Acc: 0.752 [Val] Loss: 1.260 Acc: 0.583 || Corr: -0.692\n",
      "Epoch 64 -> [Train] Loss: 0.706 Acc: 0.758 [Val] Loss: 1.271 Acc: 0.582 || Corr: -0.692\n",
      "Epoch 65 -> [Train] Loss: 0.693 Acc: 0.763 [Val] Loss: 1.282 Acc: 0.582 || Corr: -0.692\n",
      "Epoch 66 -> [Train] Loss: 0.681 Acc: 0.768 [Val] Loss: 1.294 Acc: 0.580 || Corr: -0.693\n",
      "Epoch 67 -> [Train] Loss: 0.668 Acc: 0.773 [Val] Loss: 1.306 Acc: 0.578 || Corr: -0.693\n",
      "Epoch 68 -> [Train] Loss: 0.655 Acc: 0.778 [Val] Loss: 1.319 Acc: 0.577 || Corr: -0.693\n",
      "Epoch 69 -> [Train] Loss: 0.643 Acc: 0.783 [Val] Loss: 1.332 Acc: 0.575 || Corr: -0.694\n",
      "Epoch 70 -> [Train] Loss: 0.630 Acc: 0.788 [Val] Loss: 1.345 Acc: 0.574 || Corr: -0.694\n",
      "Epoch 71 -> [Train] Loss: 0.618 Acc: 0.793 [Val] Loss: 1.359 Acc: 0.574 || Corr: -0.694\n",
      "Epoch 72 -> [Train] Loss: 0.605 Acc: 0.797 [Val] Loss: 1.373 Acc: 0.574 || Corr: -0.694\n",
      "Epoch 73 -> [Train] Loss: 0.593 Acc: 0.803 [Val] Loss: 1.389 Acc: 0.574 || Corr: -0.695\n",
      "Epoch 74 -> [Train] Loss: 0.581 Acc: 0.807 [Val] Loss: 1.405 Acc: 0.572 || Corr: -0.695\n",
      "Epoch 75 -> [Train] Loss: 0.569 Acc: 0.812 [Val] Loss: 1.422 Acc: 0.570 || Corr: -0.695\n",
      "Epoch 76 -> [Train] Loss: 0.557 Acc: 0.817 [Val] Loss: 1.440 Acc: 0.569 || Corr: -0.695\n",
      "Epoch 77 -> [Train] Loss: 0.544 Acc: 0.821 [Val] Loss: 1.459 Acc: 0.567 || Corr: -0.695\n",
      "Epoch 78 -> [Train] Loss: 0.533 Acc: 0.827 [Val] Loss: 1.478 Acc: 0.567 || Corr: -0.695\n",
      "Epoch 79 -> [Train] Loss: 0.521 Acc: 0.831 [Val] Loss: 1.498 Acc: 0.566 || Corr: -0.695\n",
      "Epoch 80 -> [Train] Loss: 0.509 Acc: 0.835 [Val] Loss: 1.518 Acc: 0.566 || Corr: -0.695\n",
      "Epoch 81 -> [Train] Loss: 0.497 Acc: 0.840 [Val] Loss: 1.540 Acc: 0.565 || Corr: -0.695\n",
      "Epoch 82 -> [Train] Loss: 0.486 Acc: 0.845 [Val] Loss: 1.562 Acc: 0.563 || Corr: -0.695\n",
      "Epoch 83 -> [Train] Loss: 0.474 Acc: 0.849 [Val] Loss: 1.584 Acc: 0.561 || Corr: -0.695\n",
      "Epoch 84 -> [Train] Loss: 0.465 Acc: 0.853 [Val] Loss: 1.598 Acc: 0.562 || Corr: -0.697\n",
      "Epoch 85 -> [Train] Loss: 0.454 Acc: 0.858 [Val] Loss: 1.628 Acc: 0.559 || Corr: -0.696\n",
      "Epoch 86 -> [Train] Loss: 0.441 Acc: 0.863 [Val] Loss: 1.654 Acc: 0.559 || Corr: -0.696\n",
      "Epoch 87 -> [Train] Loss: 0.431 Acc: 0.867 [Val] Loss: 1.682 Acc: 0.558 || Corr: -0.696\n",
      "Epoch 88 -> [Train] Loss: 0.418 Acc: 0.872 [Val] Loss: 1.710 Acc: 0.557 || Corr: -0.696\n",
      "Epoch 89 -> [Train] Loss: 0.409 Acc: 0.875 [Val] Loss: 1.731 Acc: 0.557 || Corr: -0.696\n",
      "Epoch 90 -> [Train] Loss: 0.397 Acc: 0.880 [Val] Loss: 1.762 Acc: 0.555 || Corr: -0.696\n",
      "Epoch 91 -> [Train] Loss: 0.386 Acc: 0.884 [Val] Loss: 1.792 Acc: 0.552 || Corr: -0.696\n",
      "Epoch 92 -> [Train] Loss: 0.374 Acc: 0.889 [Val] Loss: 1.821 Acc: 0.551 || Corr: -0.696\n",
      "Epoch 93 -> [Train] Loss: 0.365 Acc: 0.893 [Val] Loss: 1.851 Acc: 0.550 || Corr: -0.696\n",
      "Epoch 94 -> [Train] Loss: 0.359 Acc: 0.894 [Val] Loss: 1.863 Acc: 0.549 || Corr: -0.697\n",
      "Epoch 95 -> [Train] Loss: 0.346 Acc: 0.900 [Val] Loss: 1.893 Acc: 0.547 || Corr: -0.697\n",
      "Epoch 96 -> [Train] Loss: 0.335 Acc: 0.904 [Val] Loss: 1.925 Acc: 0.546 || Corr: -0.697\n",
      "Epoch 97 -> [Train] Loss: 0.323 Acc: 0.908 [Val] Loss: 1.964 Acc: 0.544 || Corr: -0.697\n",
      "Epoch 98 -> [Train] Loss: 0.313 Acc: 0.913 [Val] Loss: 1.985 Acc: 0.544 || Corr: -0.697\n",
      "Epoch 99 -> [Train] Loss: 0.303 Acc: 0.917 [Val] Loss: 2.037 Acc: 0.541 || Corr: -0.696\n",
      "Epoch 100 -> [Train] Loss: 0.293 Acc: 0.922 [Val] Loss: 2.075 Acc: 0.541 || Corr: -0.696\n",
      "Epoch 101 -> [Train] Loss: 0.284 Acc: 0.924 [Val] Loss: 2.101 Acc: 0.542 || Corr: -0.698\n",
      "Epoch 102 -> [Train] Loss: 0.275 Acc: 0.928 [Val] Loss: 2.154 Acc: 0.540 || Corr: -0.697\n",
      "Epoch 103 -> [Train] Loss: 0.265 Acc: 0.932 [Val] Loss: 2.193 Acc: 0.538 || Corr: -0.697\n",
      "Epoch 104 -> [Train] Loss: 0.256 Acc: 0.935 [Val] Loss: 2.235 Acc: 0.537 || Corr: -0.697\n",
      "Epoch 105 -> [Train] Loss: 0.248 Acc: 0.937 [Val] Loss: 2.273 Acc: 0.535 || Corr: -0.697\n",
      "Epoch 106 -> [Train] Loss: 0.240 Acc: 0.940 [Val] Loss: 2.312 Acc: 0.536 || Corr: -0.697\n",
      "Epoch 107 -> [Train] Loss: 0.233 Acc: 0.942 [Val] Loss: 2.351 Acc: 0.535 || Corr: -0.697\n",
      "Epoch 108 -> [Train] Loss: 0.224 Acc: 0.945 [Val] Loss: 2.390 Acc: 0.535 || Corr: -0.697\n",
      "Epoch 109 -> [Train] Loss: 0.218 Acc: 0.948 [Val] Loss: 2.432 Acc: 0.534 || Corr: -0.698\n",
      "Epoch 110 -> [Train] Loss: 0.211 Acc: 0.951 [Val] Loss: 2.465 Acc: 0.534 || Corr: -0.698\n",
      "Epoch 111 -> [Train] Loss: 0.205 Acc: 0.953 [Val] Loss: 2.500 Acc: 0.530 || Corr: -0.698\n",
      "Epoch 112 -> [Train] Loss: 0.199 Acc: 0.955 [Val] Loss: 2.540 Acc: 0.528 || Corr: -0.698\n",
      "Epoch 113 -> [Train] Loss: 0.193 Acc: 0.958 [Val] Loss: 2.575 Acc: 0.528 || Corr: -0.698\n",
      "Epoch 114 -> [Train] Loss: 0.190 Acc: 0.958 [Val] Loss: 2.581 Acc: 0.531 || Corr: -0.699\n",
      "Epoch 115 -> [Train] Loss: 0.188 Acc: 0.957 [Val] Loss: 2.596 Acc: 0.531 || Corr: -0.700\n",
      "Epoch 116 -> [Train] Loss: 0.185 Acc: 0.958 [Val] Loss: 2.636 Acc: 0.533 || Corr: -0.700\n",
      "Epoch 117 -> [Train] Loss: 0.181 Acc: 0.960 [Val] Loss: 2.681 Acc: 0.531 || Corr: -0.700\n",
      "Epoch 118 -> [Train] Loss: 0.179 Acc: 0.960 [Val] Loss: 2.708 Acc: 0.528 || Corr: -0.700\n",
      "Epoch 119 -> [Train] Loss: 0.176 Acc: 0.960 [Val] Loss: 2.716 Acc: 0.530 || Corr: -0.701\n",
      "Epoch 120 -> [Train] Loss: 0.171 Acc: 0.961 [Val] Loss: 2.725 Acc: 0.528 || Corr: -0.701\n",
      "Epoch 121 -> [Train] Loss: 0.167 Acc: 0.962 [Val] Loss: 2.677 Acc: 0.533 || Corr: -0.704\n",
      "Epoch 122 -> [Train] Loss: 0.173 Acc: 0.959 [Val] Loss: 2.675 Acc: 0.531 || Corr: -0.703\n",
      "Epoch 123 -> [Train] Loss: 0.159 Acc: 0.965 [Val] Loss: 2.719 Acc: 0.531 || Corr: -0.699\n",
      "Epoch 124 -> [Train] Loss: 0.155 Acc: 0.966 [Val] Loss: 2.728 Acc: 0.530 || Corr: -0.700\n",
      "Epoch 125 -> [Train] Loss: 0.144 Acc: 0.972 [Val] Loss: 2.758 Acc: 0.532 || Corr: -0.700\n",
      "Epoch 126 -> [Train] Loss: 0.140 Acc: 0.974 [Val] Loss: 2.789 Acc: 0.532 || Corr: -0.700\n",
      "Epoch 127 -> [Train] Loss: 0.135 Acc: 0.976 [Val] Loss: 2.828 Acc: 0.528 || Corr: -0.699\n",
      "Epoch 128 -> [Train] Loss: 0.130 Acc: 0.978 [Val] Loss: 2.874 Acc: 0.531 || Corr: -0.700\n",
      "Epoch 129 -> [Train] Loss: 0.126 Acc: 0.980 [Val] Loss: 2.915 Acc: 0.528 || Corr: -0.700\n",
      "Epoch 130 -> [Train] Loss: 0.122 Acc: 0.980 [Val] Loss: 2.998 Acc: 0.521 || Corr: -0.700\n",
      "Epoch 131 -> [Train] Loss: 0.120 Acc: 0.980 [Val] Loss: 2.996 Acc: 0.525 || Corr: -0.701\n",
      "Epoch 132 -> [Train] Loss: 0.117 Acc: 0.981 [Val] Loss: 3.019 Acc: 0.525 || Corr: -0.702\n",
      "Epoch 133 -> [Train] Loss: 0.128 Acc: 0.974 [Val] Loss: 2.942 Acc: 0.525 || Corr: -0.703\n",
      "Epoch 134 -> [Train] Loss: 0.123 Acc: 0.975 [Val] Loss: 2.945 Acc: 0.528 || Corr: -0.704\n",
      "Epoch 135 -> [Train] Loss: 0.113 Acc: 0.979 [Val] Loss: 2.943 Acc: 0.529 || Corr: -0.704\n",
      "Epoch 136 -> [Train] Loss: 0.111 Acc: 0.980 [Val] Loss: 2.943 Acc: 0.533 || Corr: -0.705\n",
      "Epoch 137 -> [Train] Loss: 0.107 Acc: 0.981 [Val] Loss: 2.932 Acc: 0.535 || Corr: -0.705\n",
      "Epoch 138 -> [Train] Loss: 0.108 Acc: 0.981 [Val] Loss: 2.947 Acc: 0.538 || Corr: -0.702\n",
      "Epoch 139 -> [Train] Loss: 0.108 Acc: 0.980 [Val] Loss: 2.961 Acc: 0.535 || Corr: -0.704\n",
      "Epoch 140 -> [Train] Loss: 0.115 Acc: 0.976 [Val] Loss: 2.961 Acc: 0.536 || Corr: -0.704\n",
      "Epoch 141 -> [Train] Loss: 0.108 Acc: 0.978 [Val] Loss: 3.017 Acc: 0.533 || Corr: -0.703\n",
      "Epoch 142 -> [Train] Loss: 0.105 Acc: 0.980 [Val] Loss: 3.084 Acc: 0.530 || Corr: -0.701\n",
      "Epoch 143 -> [Train] Loss: 0.104 Acc: 0.980 [Val] Loss: 3.133 Acc: 0.524 || Corr: -0.702\n",
      "Epoch 144 -> [Train] Loss: 0.099 Acc: 0.982 [Val] Loss: 3.115 Acc: 0.527 || Corr: -0.701\n",
      "Epoch 145 -> [Train] Loss: 0.097 Acc: 0.983 [Val] Loss: 3.166 Acc: 0.528 || Corr: -0.698\n",
      "Epoch 146 -> [Train] Loss: 0.094 Acc: 0.984 [Val] Loss: 3.148 Acc: 0.534 || Corr: -0.700\n",
      "Epoch 147 -> [Train] Loss: 0.090 Acc: 0.985 [Val] Loss: 3.141 Acc: 0.534 || Corr: -0.698\n",
      "Epoch 148 -> [Train] Loss: 0.088 Acc: 0.985 [Val] Loss: 3.144 Acc: 0.534 || Corr: -0.700\n",
      "Epoch 149 -> [Train] Loss: 0.103 Acc: 0.978 [Val] Loss: 3.069 Acc: 0.536 || Corr: -0.702\n",
      "Epoch 150 -> [Train] Loss: 0.090 Acc: 0.984 [Val] Loss: 3.206 Acc: 0.527 || Corr: -0.698\n",
      "Epoch 151 -> [Train] Loss: 0.084 Acc: 0.986 [Val] Loss: 3.202 Acc: 0.530 || Corr: -0.699\n",
      "Epoch 152 -> [Train] Loss: 0.086 Acc: 0.985 [Val] Loss: 3.228 Acc: 0.527 || Corr: -0.698\n",
      "Epoch 153 -> [Train] Loss: 0.082 Acc: 0.987 [Val] Loss: 3.262 Acc: 0.531 || Corr: -0.698\n",
      "Epoch 154 -> [Train] Loss: 0.080 Acc: 0.988 [Val] Loss: 3.259 Acc: 0.532 || Corr: -0.698\n",
      "Epoch 155 -> [Train] Loss: 0.079 Acc: 0.987 [Val] Loss: 3.322 Acc: 0.527 || Corr: -0.697\n",
      "Epoch 156 -> [Train] Loss: 0.078 Acc: 0.987 [Val] Loss: 3.274 Acc: 0.529 || Corr: -0.698\n",
      "Epoch 157 -> [Train] Loss: 0.076 Acc: 0.988 [Val] Loss: 3.316 Acc: 0.532 || Corr: -0.698\n",
      "Epoch 158 -> [Train] Loss: 0.072 Acc: 0.989 [Val] Loss: 3.310 Acc: 0.533 || Corr: -0.699\n",
      "Epoch 159 -> [Train] Loss: 0.073 Acc: 0.989 [Val] Loss: 3.333 Acc: 0.533 || Corr: -0.698\n",
      "Epoch 160 -> [Train] Loss: 0.071 Acc: 0.988 [Val] Loss: 3.365 Acc: 0.531 || Corr: -0.699\n",
      "Epoch 161 -> [Train] Loss: 0.069 Acc: 0.990 [Val] Loss: 3.340 Acc: 0.534 || Corr: -0.697\n",
      "Epoch 162 -> [Train] Loss: 0.069 Acc: 0.989 [Val] Loss: 3.370 Acc: 0.532 || Corr: -0.698\n",
      "Epoch 163 -> [Train] Loss: 0.068 Acc: 0.989 [Val] Loss: 3.394 Acc: 0.527 || Corr: -0.697\n",
      "Epoch 164 -> [Train] Loss: 0.067 Acc: 0.990 [Val] Loss: 3.359 Acc: 0.529 || Corr: -0.700\n",
      "Epoch 165 -> [Train] Loss: 0.065 Acc: 0.990 [Val] Loss: 3.362 Acc: 0.529 || Corr: -0.697\n",
      "Epoch 166 -> [Train] Loss: 0.066 Acc: 0.990 [Val] Loss: 3.363 Acc: 0.533 || Corr: -0.699\n",
      "Epoch 167 -> [Train] Loss: 0.063 Acc: 0.990 [Val] Loss: 3.356 Acc: 0.533 || Corr: -0.698\n",
      "Epoch 168 -> [Train] Loss: 0.062 Acc: 0.991 [Val] Loss: 3.368 Acc: 0.534 || Corr: -0.697\n",
      "Epoch 169 -> [Train] Loss: 0.061 Acc: 0.990 [Val] Loss: 3.455 Acc: 0.527 || Corr: -0.696\n",
      "Epoch 170 -> [Train] Loss: 0.061 Acc: 0.990 [Val] Loss: 3.376 Acc: 0.535 || Corr: -0.697\n",
      "Epoch 171 -> [Train] Loss: 0.062 Acc: 0.989 [Val] Loss: 3.382 Acc: 0.531 || Corr: -0.695\n",
      "Epoch 172 -> [Train] Loss: 0.060 Acc: 0.990 [Val] Loss: 3.365 Acc: 0.536 || Corr: -0.697\n",
      "Epoch 173 -> [Train] Loss: 0.061 Acc: 0.990 [Val] Loss: 3.450 Acc: 0.534 || Corr: -0.696\n",
      "Epoch 174 -> [Train] Loss: 0.058 Acc: 0.991 [Val] Loss: 3.396 Acc: 0.534 || Corr: -0.696\n",
      "Epoch 175 -> [Train] Loss: 0.057 Acc: 0.991 [Val] Loss: 3.369 Acc: 0.538 || Corr: -0.698\n",
      "Epoch 176 -> [Train] Loss: 0.057 Acc: 0.991 [Val] Loss: 3.425 Acc: 0.538 || Corr: -0.697\n",
      "Epoch 177 -> [Train] Loss: 0.057 Acc: 0.991 [Val] Loss: 3.415 Acc: 0.537 || Corr: -0.697\n",
      "Epoch 178 -> [Train] Loss: 0.054 Acc: 0.992 [Val] Loss: 3.437 Acc: 0.533 || Corr: -0.695\n",
      "Epoch 179 -> [Train] Loss: 0.051 Acc: 0.993 [Val] Loss: 3.454 Acc: 0.537 || Corr: -0.693\n",
      "Epoch 180 -> [Train] Loss: 0.051 Acc: 0.993 [Val] Loss: 3.456 Acc: 0.536 || Corr: -0.696\n",
      "Epoch 181 -> [Train] Loss: 0.049 Acc: 0.994 [Val] Loss: 3.430 Acc: 0.541 || Corr: -0.695\n",
      "Epoch 182 -> [Train] Loss: 0.050 Acc: 0.993 [Val] Loss: 3.442 Acc: 0.539 || Corr: -0.695\n",
      "Epoch 183 -> [Train] Loss: 0.052 Acc: 0.992 [Val] Loss: 3.398 Acc: 0.545 || Corr: -0.696\n",
      "Epoch 184 -> [Train] Loss: 0.049 Acc: 0.993 [Val] Loss: 3.437 Acc: 0.538 || Corr: -0.695\n",
      "Epoch 185 -> [Train] Loss: 0.046 Acc: 0.994 [Val] Loss: 3.460 Acc: 0.541 || Corr: -0.694\n",
      "Epoch 186 -> [Train] Loss: 0.048 Acc: 0.993 [Val] Loss: 3.427 Acc: 0.541 || Corr: -0.695\n",
      "Epoch 187 -> [Train] Loss: 0.051 Acc: 0.992 [Val] Loss: 3.367 Acc: 0.541 || Corr: -0.697\n",
      "Epoch 188 -> [Train] Loss: 0.050 Acc: 0.992 [Val] Loss: 3.395 Acc: 0.544 || Corr: -0.697\n",
      "Epoch 189 -> [Train] Loss: 0.048 Acc: 0.993 [Val] Loss: 3.458 Acc: 0.542 || Corr: -0.698\n",
      "Epoch 190 -> [Train] Loss: 0.043 Acc: 0.994 [Val] Loss: 3.464 Acc: 0.540 || Corr: -0.697\n",
      "Epoch 191 -> [Train] Loss: 0.043 Acc: 0.995 [Val] Loss: 3.478 Acc: 0.542 || Corr: -0.697\n",
      "Epoch 192 -> [Train] Loss: 0.043 Acc: 0.994 [Val] Loss: 3.499 Acc: 0.542 || Corr: -0.696\n",
      "Epoch 193 -> [Train] Loss: 0.046 Acc: 0.993 [Val] Loss: 3.495 Acc: 0.539 || Corr: -0.698\n",
      "Epoch 194 -> [Train] Loss: 0.039 Acc: 0.996 [Val] Loss: 3.514 Acc: 0.539 || Corr: -0.700\n",
      "Epoch 195 -> [Train] Loss: 0.040 Acc: 0.995 [Val] Loss: 3.479 Acc: 0.544 || Corr: -0.698\n",
      "Epoch 196 -> [Train] Loss: 0.042 Acc: 0.994 [Val] Loss: 3.512 Acc: 0.536 || Corr: -0.696\n",
      "Epoch 197 -> [Train] Loss: 0.037 Acc: 0.996 [Val] Loss: 3.539 Acc: 0.542 || Corr: -0.699\n",
      "Epoch 198 -> [Train] Loss: 0.040 Acc: 0.995 [Val] Loss: 3.450 Acc: 0.543 || Corr: -0.697\n",
      "Epoch 199 -> [Train] Loss: 0.044 Acc: 0.993 [Val] Loss: 3.542 Acc: 0.540 || Corr: -0.697\n",
      "Epoch 200 -> [Train] Loss: 0.039 Acc: 0.995 [Val] Loss: 3.557 Acc: 0.541 || Corr: -0.698\n",
      "Epoch 201 -> [Train] Loss: 0.038 Acc: 0.995 [Val] Loss: 3.484 Acc: 0.548 || Corr: -0.697\n",
      "Epoch 202 -> [Train] Loss: 0.037 Acc: 0.995 [Val] Loss: 3.575 Acc: 0.541 || Corr: -0.698\n",
      "Epoch 203 -> [Train] Loss: 0.036 Acc: 0.995 [Val] Loss: 3.533 Acc: 0.544 || Corr: -0.698\n",
      "Epoch 204 -> [Train] Loss: 0.035 Acc: 0.996 [Val] Loss: 3.607 Acc: 0.540 || Corr: -0.697\n",
      "Epoch 205 -> [Train] Loss: 0.034 Acc: 0.995 [Val] Loss: 3.538 Acc: 0.546 || Corr: -0.697\n",
      "Epoch 206 -> [Train] Loss: 0.033 Acc: 0.996 [Val] Loss: 3.563 Acc: 0.548 || Corr: -0.697\n",
      "Epoch 207 -> [Train] Loss: 0.033 Acc: 0.996 [Val] Loss: 3.600 Acc: 0.544 || Corr: -0.698\n",
      "Epoch 208 -> [Train] Loss: 0.038 Acc: 0.994 [Val] Loss: 3.519 Acc: 0.545 || Corr: -0.697\n",
      "Epoch 209 -> [Train] Loss: 0.034 Acc: 0.995 [Val] Loss: 3.515 Acc: 0.550 || Corr: -0.697\n",
      "Epoch 210 -> [Train] Loss: 0.035 Acc: 0.995 [Val] Loss: 3.572 Acc: 0.546 || Corr: -0.697\n",
      "Epoch 211 -> [Train] Loss: 0.032 Acc: 0.996 [Val] Loss: 3.570 Acc: 0.548 || Corr: -0.696\n",
      "Epoch 212 -> [Train] Loss: 0.031 Acc: 0.996 [Val] Loss: 3.489 Acc: 0.548 || Corr: -0.697\n",
      "Epoch 213 -> [Train] Loss: 0.033 Acc: 0.995 [Val] Loss: 3.545 Acc: 0.550 || Corr: -0.696\n",
      "Epoch 214 -> [Train] Loss: 0.029 Acc: 0.996 [Val] Loss: 3.525 Acc: 0.548 || Corr: -0.695\n",
      "Epoch 215 -> [Train] Loss: 0.037 Acc: 0.994 [Val] Loss: 3.481 Acc: 0.547 || Corr: -0.696\n",
      "Epoch 216 -> [Train] Loss: 0.032 Acc: 0.996 [Val] Loss: 3.551 Acc: 0.546 || Corr: -0.695\n",
      "Epoch 217 -> [Train] Loss: 0.032 Acc: 0.995 [Val] Loss: 3.502 Acc: 0.549 || Corr: -0.695\n",
      "Epoch 218 -> [Train] Loss: 0.030 Acc: 0.996 [Val] Loss: 3.559 Acc: 0.547 || Corr: -0.696\n",
      "Epoch 219 -> [Train] Loss: 0.028 Acc: 0.997 [Val] Loss: 3.587 Acc: 0.548 || Corr: -0.697\n",
      "Epoch 220 -> [Train] Loss: 0.030 Acc: 0.996 [Val] Loss: 3.535 Acc: 0.548 || Corr: -0.697\n",
      "Epoch 221 -> [Train] Loss: 0.032 Acc: 0.995 [Val] Loss: 3.564 Acc: 0.545 || Corr: -0.696\n",
      "Epoch 222 -> [Train] Loss: 0.026 Acc: 0.997 [Val] Loss: 3.630 Acc: 0.543 || Corr: -0.695\n",
      "Epoch 223 -> [Train] Loss: 0.033 Acc: 0.995 [Val] Loss: 3.569 Acc: 0.546 || Corr: -0.696\n",
      "Epoch 224 -> [Train] Loss: 0.022 Acc: 0.998 [Val] Loss: 3.626 Acc: 0.550 || Corr: -0.693\n",
      "Epoch 225 -> [Train] Loss: 0.030 Acc: 0.996 [Val] Loss: 3.545 Acc: 0.548 || Corr: -0.694\n",
      "Epoch 226 -> [Train] Loss: 0.027 Acc: 0.997 [Val] Loss: 3.625 Acc: 0.549 || Corr: -0.695\n",
      "Epoch 227 -> [Train] Loss: 0.022 Acc: 0.998 [Val] Loss: 3.598 Acc: 0.549 || Corr: -0.693\n",
      "Epoch 228 -> [Train] Loss: 0.024 Acc: 0.998 [Val] Loss: 3.634 Acc: 0.549 || Corr: -0.693\n",
      "Epoch 229 -> [Train] Loss: 0.050 Acc: 0.988 [Val] Loss: 3.564 Acc: 0.549 || Corr: -0.693\n",
      "Epoch 230 -> [Train] Loss: 0.020 Acc: 0.999 [Val] Loss: 3.689 Acc: 0.551 || Corr: -0.693\n",
      "Epoch 231 -> [Train] Loss: 0.018 Acc: 0.999 [Val] Loss: 3.734 Acc: 0.547 || Corr: -0.692\n",
      "Epoch 232 -> [Train] Loss: 0.021 Acc: 0.998 [Val] Loss: 3.686 Acc: 0.550 || Corr: -0.693\n",
      "Epoch 233 -> [Train] Loss: 0.041 Acc: 0.991 [Val] Loss: 3.507 Acc: 0.551 || Corr: -0.695\n",
      "Epoch 234 -> [Train] Loss: 0.027 Acc: 0.996 [Val] Loss: 3.677 Acc: 0.548 || Corr: -0.694\n",
      "Epoch 235 -> [Train] Loss: 0.020 Acc: 0.998 [Val] Loss: 3.638 Acc: 0.550 || Corr: -0.694\n",
      "Epoch 236 -> [Train] Loss: 0.023 Acc: 0.997 [Val] Loss: 3.603 Acc: 0.552 || Corr: -0.695\n",
      "Epoch 237 -> [Train] Loss: 0.028 Acc: 0.996 [Val] Loss: 3.636 Acc: 0.548 || Corr: -0.693\n",
      "Epoch 238 -> [Train] Loss: 0.020 Acc: 0.998 [Val] Loss: 3.561 Acc: 0.556 || Corr: -0.694\n",
      "Epoch 239 -> [Train] Loss: 0.026 Acc: 0.996 [Val] Loss: 3.551 Acc: 0.547 || Corr: -0.693\n",
      "Epoch 240 -> [Train] Loss: 0.029 Acc: 0.995 [Val] Loss: 3.544 Acc: 0.552 || Corr: -0.693\n",
      "Epoch 241 -> [Train] Loss: 0.024 Acc: 0.997 [Val] Loss: 3.614 Acc: 0.555 || Corr: -0.694\n",
      "Epoch 242 -> [Train] Loss: 0.019 Acc: 0.998 [Val] Loss: 3.688 Acc: 0.546 || Corr: -0.692\n",
      "Epoch 243 -> [Train] Loss: 0.022 Acc: 0.997 [Val] Loss: 3.646 Acc: 0.547 || Corr: -0.692\n",
      "Epoch 244 -> [Train] Loss: 0.029 Acc: 0.995 [Val] Loss: 3.649 Acc: 0.554 || Corr: -0.692\n",
      "Epoch 245 -> [Train] Loss: 0.019 Acc: 0.998 [Val] Loss: 3.642 Acc: 0.551 || Corr: -0.692\n",
      "Epoch 246 -> [Train] Loss: 0.018 Acc: 0.998 [Val] Loss: 3.594 Acc: 0.552 || Corr: -0.693\n",
      "Epoch 247 -> [Train] Loss: 0.021 Acc: 0.998 [Val] Loss: 3.571 Acc: 0.551 || Corr: -0.694\n",
      "Epoch 248 -> [Train] Loss: 0.029 Acc: 0.996 [Val] Loss: 3.537 Acc: 0.558 || Corr: -0.694\n",
      "Epoch 249 -> [Train] Loss: 0.022 Acc: 0.997 [Val] Loss: 3.624 Acc: 0.556 || Corr: -0.690\n",
      "Epoch 250 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.727 Acc: 0.554 || Corr: -0.690\n",
      "Epoch 251 -> [Train] Loss: 0.033 Acc: 0.994 [Val] Loss: 3.615 Acc: 0.553 || Corr: -0.691\n",
      "Epoch 252 -> [Train] Loss: 0.017 Acc: 0.999 [Val] Loss: 3.689 Acc: 0.555 || Corr: -0.691\n",
      "Epoch 253 -> [Train] Loss: 0.012 Acc: 1.000 [Val] Loss: 3.710 Acc: 0.553 || Corr: -0.694\n",
      "Epoch 254 -> [Train] Loss: 0.028 Acc: 0.994 [Val] Loss: 3.539 Acc: 0.543 || Corr: -0.693\n",
      "Epoch 255 -> [Train] Loss: 0.043 Acc: 0.989 [Val] Loss: 3.614 Acc: 0.554 || Corr: -0.691\n",
      "Epoch 256 -> [Train] Loss: 0.015 Acc: 0.999 [Val] Loss: 3.710 Acc: 0.553 || Corr: -0.690\n",
      "Epoch 257 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.743 Acc: 0.554 || Corr: -0.693\n",
      "Epoch 258 -> [Train] Loss: 0.049 Acc: 0.986 [Val] Loss: 3.427 Acc: 0.551 || Corr: -0.691\n",
      "Epoch 259 -> [Train] Loss: 0.023 Acc: 0.997 [Val] Loss: 3.706 Acc: 0.551 || Corr: -0.689\n",
      "Epoch 260 -> [Train] Loss: 0.012 Acc: 1.000 [Val] Loss: 3.753 Acc: 0.550 || Corr: -0.690\n",
      "Epoch 261 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.708 Acc: 0.552 || Corr: -0.691\n",
      "Epoch 262 -> [Train] Loss: 0.029 Acc: 0.992 [Val] Loss: 3.521 Acc: 0.542 || Corr: -0.691\n",
      "Epoch 263 -> [Train] Loss: 0.037 Acc: 0.992 [Val] Loss: 3.665 Acc: 0.555 || Corr: -0.691\n",
      "Epoch 264 -> [Train] Loss: 0.011 Acc: 1.000 [Val] Loss: 3.716 Acc: 0.556 || Corr: -0.690\n",
      "Epoch 265 -> [Train] Loss: 0.009 Acc: 1.000 [Val] Loss: 3.753 Acc: 0.552 || Corr: -0.691\n",
      "Epoch 266 -> [Train] Loss: 0.045 Acc: 0.987 [Val] Loss: 3.494 Acc: 0.553 || Corr: -0.692\n",
      "Epoch 267 -> [Train] Loss: 0.022 Acc: 0.997 [Val] Loss: 3.628 Acc: 0.556 || Corr: -0.692\n",
      "Epoch 268 -> [Train] Loss: 0.010 Acc: 1.000 [Val] Loss: 3.751 Acc: 0.553 || Corr: -0.692\n",
      "Epoch 269 -> [Train] Loss: 0.008 Acc: 1.000 [Val] Loss: 3.843 Acc: 0.554 || Corr: -0.691\n",
      "Epoch 270 -> [Train] Loss: 0.007 Acc: 1.000 [Val] Loss: 3.693 Acc: 0.555 || Corr: -0.692\n",
      "Epoch 271 -> [Train] Loss: 0.074 Acc: 0.976 [Val] Loss: 3.589 Acc: 0.553 || Corr: -0.691\n",
      "Epoch 272 -> [Train] Loss: 0.012 Acc: 0.999 [Val] Loss: 3.798 Acc: 0.551 || Corr: -0.689\n",
      "Epoch 273 -> [Train] Loss: 0.008 Acc: 1.000 [Val] Loss: 3.915 Acc: 0.553 || Corr: -0.689\n",
      "Epoch 274 -> [Train] Loss: 0.006 Acc: 1.000 [Val] Loss: 3.901 Acc: 0.553 || Corr: -0.690\n",
      "Epoch 275 -> [Train] Loss: 0.013 Acc: 0.997 [Val] Loss: 3.556 Acc: 0.550 || Corr: -0.696\n",
      "Epoch 276 -> [Train] Loss: 0.077 Acc: 0.976 [Val] Loss: 3.596 Acc: 0.554 || Corr: -0.689\n",
      "Epoch 277 -> [Train] Loss: 0.011 Acc: 1.000 [Val] Loss: 3.723 Acc: 0.555 || Corr: -0.692\n",
      "Epoch 278 -> [Train] Loss: 0.007 Acc: 1.000 [Val] Loss: 3.864 Acc: 0.549 || Corr: -0.689\n",
      "Epoch 279 -> [Train] Loss: 0.005 Acc: 1.000 [Val] Loss: 4.023 Acc: 0.548 || Corr: -0.688\n",
      "Epoch 280 -> [Train] Loss: 0.004 Acc: 1.000 [Val] Loss: 4.042 Acc: 0.549 || Corr: -0.689\n",
      "Epoch 281 -> [Train] Loss: 0.003 Acc: 1.000 [Val] Loss: 4.166 Acc: 0.547 || Corr: -0.688\n",
      "Epoch 282 -> [Train] Loss: 0.003 Acc: 1.000 [Val] Loss: 4.191 Acc: 0.549 || Corr: -0.688\n",
      "Epoch 283 -> [Train] Loss: 0.121 Acc: 0.962 [Val] Loss: 3.481 Acc: 0.557 || Corr: -0.691\n",
      "Epoch 284 -> [Train] Loss: 0.014 Acc: 0.999 [Val] Loss: 3.807 Acc: 0.552 || Corr: -0.688\n",
      "Epoch 285 -> [Train] Loss: 0.007 Acc: 1.000 [Val] Loss: 3.904 Acc: 0.549 || Corr: -0.688\n",
      "Epoch 286 -> [Train] Loss: 0.005 Acc: 1.000 [Val] Loss: 4.015 Acc: 0.552 || Corr: -0.689\n",
      "Epoch 287 -> [Train] Loss: 0.003 Acc: 1.000 [Val] Loss: 4.113 Acc: 0.552 || Corr: -0.688\n",
      "Epoch 288 -> [Train] Loss: 0.003 Acc: 1.000 [Val] Loss: 4.203 Acc: 0.553 || Corr: -0.687\n",
      "Epoch 289 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.280 Acc: 0.553 || Corr: -0.687\n",
      "Epoch 290 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.160 Acc: 0.557 || Corr: -0.688\n",
      "Epoch 291 -> [Train] Loss: 0.117 Acc: 0.964 [Val] Loss: 3.634 Acc: 0.550 || Corr: -0.690\n",
      "Epoch 292 -> [Train] Loss: 0.009 Acc: 1.000 [Val] Loss: 3.887 Acc: 0.551 || Corr: -0.689\n",
      "Epoch 293 -> [Train] Loss: 0.005 Acc: 1.000 [Val] Loss: 4.003 Acc: 0.551 || Corr: -0.688\n",
      "Epoch 294 -> [Train] Loss: 0.003 Acc: 1.000 [Val] Loss: 4.144 Acc: 0.551 || Corr: -0.687\n",
      "Epoch 295 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.241 Acc: 0.553 || Corr: -0.686\n",
      "Epoch 296 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.303 Acc: 0.554 || Corr: -0.687\n",
      "Epoch 297 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.371 Acc: 0.554 || Corr: -0.686\n",
      "Epoch 298 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.438 Acc: 0.554 || Corr: -0.687\n",
      "Epoch 299 -> [Train] Loss: 0.117 Acc: 0.962 [Val] Loss: 3.378 Acc: 0.552 || Corr: -0.690\n",
      "Epoch 300 -> [Train] Loss: 0.022 Acc: 0.996 [Val] Loss: 3.730 Acc: 0.553 || Corr: -0.689\n",
      "Epoch 301 -> [Train] Loss: 0.006 Acc: 1.000 [Val] Loss: 3.922 Acc: 0.556 || Corr: -0.688\n",
      "Epoch 302 -> [Train] Loss: 0.003 Acc: 1.000 [Val] Loss: 4.088 Acc: 0.556 || Corr: -0.687\n",
      "Epoch 303 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.200 Acc: 0.557 || Corr: -0.687\n",
      "Epoch 304 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.293 Acc: 0.556 || Corr: -0.687\n",
      "Epoch 305 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.368 Acc: 0.556 || Corr: -0.686\n",
      "Epoch 306 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.431 Acc: 0.556 || Corr: -0.686\n",
      "Epoch 307 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.485 Acc: 0.556 || Corr: -0.686\n",
      "Epoch 308 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.526 Acc: 0.555 || Corr: -0.687\n",
      "Epoch 309 -> [Train] Loss: 0.011 Acc: 0.997 [Val] Loss: 3.932 Acc: 0.531 || Corr: -0.698\n",
      "Epoch 310 -> [Train] Loss: 0.122 Acc: 0.962 [Val] Loss: 3.667 Acc: 0.554 || Corr: -0.690\n",
      "Epoch 311 -> [Train] Loss: 0.008 Acc: 1.000 [Val] Loss: 3.917 Acc: 0.556 || Corr: -0.688\n",
      "Epoch 312 -> [Train] Loss: 0.004 Acc: 1.000 [Val] Loss: 4.109 Acc: 0.554 || Corr: -0.687\n",
      "Epoch 313 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.239 Acc: 0.555 || Corr: -0.686\n",
      "Epoch 314 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.332 Acc: 0.554 || Corr: -0.686\n",
      "Epoch 315 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.413 Acc: 0.554 || Corr: -0.686\n",
      "Epoch 316 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.495 Acc: 0.554 || Corr: -0.686\n",
      "Epoch 317 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.552 Acc: 0.554 || Corr: -0.686\n",
      "Epoch 318 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.608 Acc: 0.553 || Corr: -0.686\n",
      "Epoch 319 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.634 Acc: 0.553 || Corr: -0.686\n",
      "Epoch 320 -> [Train] Loss: 0.122 Acc: 0.963 [Val] Loss: 3.577 Acc: 0.554 || Corr: -0.689\n",
      "Epoch 321 -> [Train] Loss: 0.014 Acc: 0.998 [Val] Loss: 3.879 Acc: 0.554 || Corr: -0.688\n",
      "Epoch 322 -> [Train] Loss: 0.004 Acc: 1.000 [Val] Loss: 4.095 Acc: 0.556 || Corr: -0.687\n",
      "Epoch 323 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.230 Acc: 0.554 || Corr: -0.687\n",
      "Epoch 324 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.349 Acc: 0.553 || Corr: -0.686\n",
      "Epoch 325 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.420 Acc: 0.553 || Corr: -0.686\n",
      "Epoch 326 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.506 Acc: 0.553 || Corr: -0.686\n",
      "Epoch 327 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.568 Acc: 0.552 || Corr: -0.685\n",
      "Epoch 328 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.625 Acc: 0.552 || Corr: -0.685\n",
      "Epoch 329 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.674 Acc: 0.552 || Corr: -0.686\n",
      "Epoch 330 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.687 Acc: 0.554 || Corr: -0.686\n",
      "Epoch 331 -> [Train] Loss: 0.130 Acc: 0.959 [Val] Loss: 3.634 Acc: 0.555 || Corr: -0.690\n",
      "Epoch 332 -> [Train] Loss: 0.010 Acc: 0.999 [Val] Loss: 3.967 Acc: 0.554 || Corr: -0.688\n",
      "Epoch 333 -> [Train] Loss: 0.003 Acc: 1.000 [Val] Loss: 4.192 Acc: 0.554 || Corr: -0.686\n",
      "Epoch 334 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.327 Acc: 0.554 || Corr: -0.686\n",
      "Epoch 335 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.426 Acc: 0.554 || Corr: -0.686\n",
      "Epoch 336 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.509 Acc: 0.552 || Corr: -0.685\n",
      "Epoch 337 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.570 Acc: 0.553 || Corr: -0.685\n",
      "Epoch 338 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.638 Acc: 0.553 || Corr: -0.684\n",
      "Epoch 339 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.623 Acc: 0.554 || Corr: -0.685\n",
      "Epoch 340 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.649 Acc: 0.553 || Corr: -0.685\n",
      "Epoch 341 -> [Train] Loss: 0.111 Acc: 0.964 [Val] Loss: 3.549 Acc: 0.553 || Corr: -0.689\n",
      "Epoch 342 -> [Train] Loss: 0.016 Acc: 0.997 [Val] Loss: 3.848 Acc: 0.558 || Corr: -0.688\n",
      "Epoch 343 -> [Train] Loss: 0.004 Acc: 1.000 [Val] Loss: 4.095 Acc: 0.555 || Corr: -0.687\n",
      "Epoch 344 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.274 Acc: 0.556 || Corr: -0.686\n",
      "Epoch 345 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.401 Acc: 0.555 || Corr: -0.686\n",
      "Epoch 346 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.493 Acc: 0.555 || Corr: -0.685\n",
      "Epoch 347 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.568 Acc: 0.555 || Corr: -0.685\n",
      "Epoch 348 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.634 Acc: 0.554 || Corr: -0.685\n",
      "Epoch 349 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.685 Acc: 0.555 || Corr: -0.685\n",
      "Epoch 350 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.732 Acc: 0.554 || Corr: -0.685\n",
      "Epoch 351 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.761 Acc: 0.553 || Corr: -0.685\n",
      "Epoch 352 -> [Train] Loss: 0.093 Acc: 0.974 [Val] Loss: 3.280 Acc: 0.552 || Corr: -0.699\n",
      "Epoch 353 -> [Train] Loss: 0.056 Acc: 0.983 [Val] Loss: 3.687 Acc: 0.556 || Corr: -0.689\n",
      "Epoch 354 -> [Train] Loss: 0.005 Acc: 1.000 [Val] Loss: 3.991 Acc: 0.560 || Corr: -0.688\n",
      "Epoch 355 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.200 Acc: 0.558 || Corr: -0.687\n",
      "Epoch 356 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.334 Acc: 0.556 || Corr: -0.686\n",
      "Epoch 357 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.435 Acc: 0.556 || Corr: -0.686\n",
      "Epoch 358 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.519 Acc: 0.555 || Corr: -0.685\n",
      "Epoch 359 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.593 Acc: 0.555 || Corr: -0.685\n",
      "Epoch 360 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.660 Acc: 0.555 || Corr: -0.685\n",
      "Epoch 361 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.715 Acc: 0.556 || Corr: -0.685\n",
      "Epoch 362 -> [Train] Loss: 0.110 Acc: 0.965 [Val] Loss: 3.522 Acc: 0.556 || Corr: -0.691\n",
      "Epoch 363 -> [Train] Loss: 0.020 Acc: 0.996 [Val] Loss: 3.867 Acc: 0.556 || Corr: -0.688\n",
      "Epoch 364 -> [Train] Loss: 0.003 Acc: 1.000 [Val] Loss: 4.115 Acc: 0.557 || Corr: -0.687\n",
      "Epoch 365 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.289 Acc: 0.555 || Corr: -0.686\n",
      "Epoch 366 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.393 Acc: 0.555 || Corr: -0.686\n",
      "Epoch 367 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.477 Acc: 0.555 || Corr: -0.685\n",
      "Epoch 368 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.546 Acc: 0.555 || Corr: -0.685\n",
      "Epoch 369 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.606 Acc: 0.555 || Corr: -0.685\n",
      "Epoch 370 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.652 Acc: 0.555 || Corr: -0.685\n",
      "Epoch 371 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.695 Acc: 0.555 || Corr: -0.685\n",
      "Epoch 372 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.736 Acc: 0.556 || Corr: -0.684\n",
      "Epoch 373 -> [Train] Loss: 0.091 Acc: 0.972 [Val] Loss: 3.418 Acc: 0.548 || Corr: -0.694\n",
      "Epoch 374 -> [Train] Loss: 0.042 Acc: 0.988 [Val] Loss: 3.763 Acc: 0.556 || Corr: -0.687\n",
      "Epoch 375 -> [Train] Loss: 0.005 Acc: 1.000 [Val] Loss: 4.047 Acc: 0.558 || Corr: -0.687\n",
      "Epoch 376 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.231 Acc: 0.556 || Corr: -0.686\n",
      "Epoch 377 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.364 Acc: 0.555 || Corr: -0.686\n",
      "Epoch 378 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.464 Acc: 0.556 || Corr: -0.685\n",
      "Epoch 379 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.545 Acc: 0.555 || Corr: -0.685\n",
      "Epoch 380 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.615 Acc: 0.554 || Corr: -0.684\n",
      "Epoch 381 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.679 Acc: 0.555 || Corr: -0.684\n",
      "Epoch 382 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.730 Acc: 0.555 || Corr: -0.684\n",
      "Epoch 383 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.780 Acc: 0.555 || Corr: -0.684\n",
      "Epoch 384 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.810 Acc: 0.555 || Corr: -0.684\n",
      "Epoch 385 -> [Train] Loss: 0.096 Acc: 0.971 [Val] Loss: 3.445 Acc: 0.553 || Corr: -0.691\n",
      "Epoch 386 -> [Train] Loss: 0.030 Acc: 0.992 [Val] Loss: 3.847 Acc: 0.558 || Corr: -0.688\n",
      "Epoch 387 -> [Train] Loss: 0.004 Acc: 1.000 [Val] Loss: 4.121 Acc: 0.555 || Corr: -0.686\n",
      "Epoch 388 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.304 Acc: 0.554 || Corr: -0.686\n",
      "Epoch 389 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.436 Acc: 0.553 || Corr: -0.685\n",
      "Epoch 390 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.531 Acc: 0.553 || Corr: -0.685\n",
      "Epoch 391 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.611 Acc: 0.554 || Corr: -0.684\n",
      "Epoch 392 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.679 Acc: 0.554 || Corr: -0.684\n",
      "Epoch 393 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.744 Acc: 0.554 || Corr: -0.684\n",
      "Epoch 394 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.798 Acc: 0.555 || Corr: -0.684\n",
      "Epoch 395 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.840 Acc: 0.554 || Corr: -0.684\n",
      "Epoch 396 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.861 Acc: 0.554 || Corr: -0.684\n",
      "Epoch 397 -> [Train] Loss: 0.086 Acc: 0.972 [Val] Loss: 3.503 Acc: 0.554 || Corr: -0.690\n",
      "Epoch 398 -> [Train] Loss: 0.031 Acc: 0.992 [Val] Loss: 3.860 Acc: 0.556 || Corr: -0.687\n",
      "Epoch 399 -> [Train] Loss: 0.004 Acc: 1.000 [Val] Loss: 4.153 Acc: 0.553 || Corr: -0.687\n",
      "Epoch 400 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.331 Acc: 0.551 || Corr: -0.686\n",
      "Epoch 401 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.470 Acc: 0.553 || Corr: -0.685\n",
      "Epoch 402 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.569 Acc: 0.552 || Corr: -0.684\n",
      "Epoch 403 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.646 Acc: 0.552 || Corr: -0.684\n",
      "Epoch 404 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.713 Acc: 0.551 || Corr: -0.684\n",
      "Epoch 405 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.775 Acc: 0.552 || Corr: -0.684\n",
      "Epoch 406 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.832 Acc: 0.553 || Corr: -0.683\n",
      "Epoch 407 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.880 Acc: 0.553 || Corr: -0.683\n",
      "Epoch 408 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.918 Acc: 0.553 || Corr: -0.684\n",
      "Epoch 409 -> [Train] Loss: 0.087 Acc: 0.972 [Val] Loss: 3.582 Acc: 0.557 || Corr: -0.691\n",
      "Epoch 410 -> [Train] Loss: 0.026 Acc: 0.993 [Val] Loss: 3.894 Acc: 0.554 || Corr: -0.688\n",
      "Epoch 411 -> [Train] Loss: 0.004 Acc: 1.000 [Val] Loss: 4.131 Acc: 0.557 || Corr: -0.687\n",
      "Epoch 412 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.344 Acc: 0.555 || Corr: -0.685\n",
      "Epoch 413 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.483 Acc: 0.553 || Corr: -0.685\n",
      "Epoch 414 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.580 Acc: 0.553 || Corr: -0.684\n",
      "Epoch 415 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.657 Acc: 0.552 || Corr: -0.684\n",
      "Epoch 416 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.724 Acc: 0.552 || Corr: -0.683\n",
      "Epoch 417 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.782 Acc: 0.553 || Corr: -0.683\n",
      "Epoch 418 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.835 Acc: 0.553 || Corr: -0.683\n",
      "Epoch 419 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.885 Acc: 0.553 || Corr: -0.683\n",
      "Epoch 420 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.933 Acc: 0.554 || Corr: -0.682\n",
      "Epoch 421 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.969 Acc: 0.554 || Corr: -0.682\n",
      "Epoch 422 -> [Train] Loss: 0.107 Acc: 0.967 [Val] Loss: 3.650 Acc: 0.558 || Corr: -0.688\n",
      "Epoch 423 -> [Train] Loss: 0.018 Acc: 0.996 [Val] Loss: 3.945 Acc: 0.556 || Corr: -0.687\n",
      "Epoch 424 -> [Train] Loss: 0.003 Acc: 1.000 [Val] Loss: 4.207 Acc: 0.553 || Corr: -0.686\n",
      "Epoch 425 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.390 Acc: 0.556 || Corr: -0.685\n",
      "Epoch 426 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.519 Acc: 0.555 || Corr: -0.684\n",
      "Epoch 427 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.613 Acc: 0.556 || Corr: -0.684\n",
      "Epoch 428 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.690 Acc: 0.555 || Corr: -0.683\n",
      "Epoch 429 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.755 Acc: 0.555 || Corr: -0.683\n",
      "Epoch 430 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.807 Acc: 0.555 || Corr: -0.683\n",
      "Epoch 431 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.860 Acc: 0.556 || Corr: -0.683\n",
      "Epoch 432 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.905 Acc: 0.555 || Corr: -0.683\n",
      "Epoch 433 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.938 Acc: 0.555 || Corr: -0.683\n",
      "Epoch 434 -> [Train] Loss: 0.102 Acc: 0.969 [Val] Loss: 3.662 Acc: 0.562 || Corr: -0.686\n",
      "Epoch 435 -> [Train] Loss: 0.017 Acc: 0.996 [Val] Loss: 3.933 Acc: 0.557 || Corr: -0.686\n",
      "Epoch 436 -> [Train] Loss: 0.003 Acc: 1.000 [Val] Loss: 4.227 Acc: 0.555 || Corr: -0.684\n",
      "Epoch 437 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.403 Acc: 0.555 || Corr: -0.683\n",
      "Epoch 438 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.522 Acc: 0.556 || Corr: -0.683\n",
      "Epoch 439 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.614 Acc: 0.555 || Corr: -0.682\n",
      "Epoch 440 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.691 Acc: 0.554 || Corr: -0.682\n",
      "Epoch 441 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.759 Acc: 0.553 || Corr: -0.682\n",
      "Epoch 442 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.817 Acc: 0.554 || Corr: -0.682\n",
      "Epoch 443 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.873 Acc: 0.554 || Corr: -0.682\n",
      "Epoch 444 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.919 Acc: 0.553 || Corr: -0.682\n",
      "Epoch 445 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.959 Acc: 0.553 || Corr: -0.682\n",
      "Epoch 446 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.982 Acc: 0.553 || Corr: -0.682\n",
      "Epoch 447 -> [Train] Loss: 0.117 Acc: 0.964 [Val] Loss: 3.782 Acc: 0.558 || Corr: -0.688\n",
      "Epoch 448 -> [Train] Loss: 0.007 Acc: 0.999 [Val] Loss: 4.073 Acc: 0.555 || Corr: -0.686\n",
      "Epoch 449 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.311 Acc: 0.553 || Corr: -0.685\n",
      "Epoch 450 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.476 Acc: 0.553 || Corr: -0.684\n",
      "Epoch 451 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.591 Acc: 0.552 || Corr: -0.683\n",
      "Epoch 452 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.679 Acc: 0.553 || Corr: -0.682\n",
      "Epoch 453 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.753 Acc: 0.553 || Corr: -0.682\n",
      "Epoch 454 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.818 Acc: 0.553 || Corr: -0.682\n",
      "Epoch 455 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.877 Acc: 0.553 || Corr: -0.682\n",
      "Epoch 456 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.928 Acc: 0.553 || Corr: -0.681\n",
      "Epoch 457 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.969 Acc: 0.552 || Corr: -0.681\n",
      "Epoch 458 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.977 Acc: 0.554 || Corr: -0.682\n",
      "Epoch 459 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 5.010 Acc: 0.554 || Corr: -0.682\n",
      "Epoch 460 -> [Train] Loss: 0.098 Acc: 0.969 [Val] Loss: 3.687 Acc: 0.561 || Corr: -0.684\n",
      "Epoch 461 -> [Train] Loss: 0.013 Acc: 0.998 [Val] Loss: 4.077 Acc: 0.554 || Corr: -0.683\n",
      "Epoch 462 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.319 Acc: 0.553 || Corr: -0.683\n",
      "Epoch 463 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.493 Acc: 0.553 || Corr: -0.682\n",
      "Epoch 464 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.620 Acc: 0.552 || Corr: -0.681\n",
      "Epoch 465 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.717 Acc: 0.552 || Corr: -0.681\n",
      "Epoch 466 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.795 Acc: 0.552 || Corr: -0.680\n",
      "Epoch 467 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.864 Acc: 0.551 || Corr: -0.680\n",
      "Epoch 468 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.923 Acc: 0.552 || Corr: -0.680\n",
      "Epoch 469 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.974 Acc: 0.551 || Corr: -0.680\n",
      "Epoch 470 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 5.007 Acc: 0.552 || Corr: -0.680\n",
      "Epoch 471 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 5.045 Acc: 0.553 || Corr: -0.680\n",
      "Epoch 472 -> [Train] Loss: 0.082 Acc: 0.973 [Val] Loss: 3.631 Acc: 0.555 || Corr: -0.690\n",
      "Epoch 473 -> [Train] Loss: 0.027 Acc: 0.993 [Val] Loss: 3.899 Acc: 0.558 || Corr: -0.687\n",
      "Epoch 474 -> [Train] Loss: 0.003 Acc: 1.000 [Val] Loss: 4.176 Acc: 0.556 || Corr: -0.686\n",
      "Epoch 475 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.394 Acc: 0.553 || Corr: -0.685\n",
      "Epoch 476 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.535 Acc: 0.551 || Corr: -0.684\n",
      "Epoch 477 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.639 Acc: 0.552 || Corr: -0.683\n",
      "Epoch 478 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.727 Acc: 0.550 || Corr: -0.682\n",
      "Epoch 479 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.803 Acc: 0.551 || Corr: -0.682\n",
      "Epoch 480 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.868 Acc: 0.550 || Corr: -0.681\n",
      "Epoch 481 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.929 Acc: 0.551 || Corr: -0.681\n",
      "Epoch 482 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.986 Acc: 0.552 || Corr: -0.681\n",
      "Epoch 483 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 5.032 Acc: 0.553 || Corr: -0.681\n",
      "Epoch 484 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 5.057 Acc: 0.553 || Corr: -0.681\n",
      "Epoch 485 -> [Train] Loss: 0.115 Acc: 0.965 [Val] Loss: 3.693 Acc: 0.558 || Corr: -0.687\n",
      "Epoch 486 -> [Train] Loss: 0.009 Acc: 0.999 [Val] Loss: 4.016 Acc: 0.556 || Corr: -0.685\n",
      "Epoch 487 -> [Train] Loss: 0.002 Acc: 1.000 [Val] Loss: 4.312 Acc: 0.554 || Corr: -0.683\n",
      "Epoch 488 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.483 Acc: 0.552 || Corr: -0.683\n",
      "Epoch 489 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.605 Acc: 0.552 || Corr: -0.682\n",
      "Epoch 490 -> [Train] Loss: 0.001 Acc: 1.000 [Val] Loss: 4.700 Acc: 0.552 || Corr: -0.681\n",
      "Epoch 491 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.782 Acc: 0.552 || Corr: -0.681\n",
      "Epoch 492 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.856 Acc: 0.552 || Corr: -0.680\n",
      "Epoch 493 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.922 Acc: 0.552 || Corr: -0.680\n",
      "Epoch 494 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 4.977 Acc: 0.553 || Corr: -0.680\n",
      "Epoch 495 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 5.023 Acc: 0.553 || Corr: -0.680\n",
      "Epoch 496 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 5.045 Acc: 0.553 || Corr: -0.680\n",
      "Epoch 497 -> [Train] Loss: 0.000 Acc: 1.000 [Val] Loss: 5.062 Acc: 0.554 || Corr: -0.680\n",
      "Epoch 498 -> [Train] Loss: 0.107 Acc: 0.968 [Val] Loss: 3.769 Acc: 0.559 || Corr: -0.687\n",
      "Epoch 499 -> [Train] Loss: 0.010 Acc: 0.998 [Val] Loss: 4.046 Acc: 0.559 || Corr: -0.686\n",
      "CPU times: user 5h 1min 30s, sys: 53min 12s, total: 5h 54min 43s\n",
      "Wall time: 1h 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(config.epochs):\n",
    "    ## Training\n",
    "    for batch in dst_train_rdy.as_numpy_iterator():\n",
    "        new_state = train_step(state, batch)\n",
    "        new_state = new_state.replace(params=clip_layer(new_state.params, \"GDN\", a_min=0))\n",
    "        params_diff = jax.tree_map(lambda x, y: jnp.mean((x-y)**2), state.params, new_state.params)\n",
    "        state = new_state\n",
    "        wandb.log(unfreeze(params_diff), commit=False)\n",
    "        # state = compute_metrics(state=state, batch=batch)\n",
    "        # break\n",
    "\n",
    "    ## Log the metrics\n",
    "    for name, value in state.metrics.compute().items():\n",
    "        metrics_history[f\"train_{name}\"].append(value)\n",
    "    \n",
    "    ## Empty the metrics\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "\n",
    "    ## Evaluation (Classification)\n",
    "    for batch in dst_val_rdy.as_numpy_iterator():\n",
    "        state = val_step(state=state, batch=batch)\n",
    "        # break\n",
    "    for name, value in state.metrics.compute().items():\n",
    "        metrics_history[f\"val_{name}\"].append(value)\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "\n",
    "    ## Evaluation (Correlation)\n",
    "    correlation = obtain_correlation(state, dst_tid2013.as_numpy_iterator())\n",
    "    metrics_history[\"correlation\"].append(correlation)\n",
    "    \n",
    "    ## Checkpointing\n",
    "    if metrics_history[\"val_loss\"][-1] <= min(metrics_history[\"val_loss\"]):\n",
    "        orbax_checkpointer.save(os.path.join(wandb.run.dir, \"model-best\"), state, save_args=save_args, force=True) # force=True means allow overwritting.\n",
    "\n",
    "    wandb.log({f\"{k}\": wandb.Histogram(v) for k, v in flatten_params(state.params).items()}, commit=False)\n",
    "    wandb.log({\"epoch\": epoch+1, **{name:values[-1] for name, values in metrics_history.items()}})\n",
    "    print(f'Epoch {epoch} -> [Train] Loss: {metrics_history[\"train_loss\"][-1]:.3f} Acc: {metrics_history[\"train_accuracy\"][-1]:.3f} [Val] Loss: {metrics_history[\"val_loss\"][-1]:.3f} Acc: {metrics_history[\"val_accuracy\"][-1]:.3f} || Corr: {metrics_history[\"correlation\"][-1]:.3f}')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbax_checkpointer.save(os.path.join(wandb.run.dir, \"model-final\"), state, save_args=save_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da5141a55de43f9a5c077a362efe5e2ae0cb795b0fc8676e62dbd4f64287ec27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
